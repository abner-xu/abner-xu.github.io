{"meta":{"title":"XuChen的博客","subtitle":"XuChen的博客","description":"XuChen的技术博客，专注Web技术发展","author":"abner","url":"http://xuchen.youtuc.cn"},"pages":[{"title":"categories","date":"2019-02-25T20:47:55.000Z","updated":"2020-05-18T05:44:56.000Z","comments":true,"path":"categories/index.html","permalink":"http://xuchen.youtuc.cn/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"go语言编程模式","slug":"Go/go语言编程模式","date":"2021-05-06T02:45:37.000Z","updated":"2021-05-18T15:28:12.000Z","comments":true,"path":"2021/05/06/Go/go语言编程模式/","link":"","permalink":"http://xuchen.youtuc.cn/2021/05/06/Go/go语言编程模式/","excerpt":"","text":"性能提示 如果需要把数字转换成字符串，使用 strconv.Itoa() 比 fmt.Sprintf() 要快一倍左右。 尽可能避免把String转成[]Byte ，这个转换会导致性能下降。 如果在 for-loop 里对某个 Slice 使用 append()，请先把 Slice 的容量扩充到位，这样可以避免内存重新分配以及系统自动按 2 的 N 次方幂进行扩展但又用不到的情况，从而避免浪费内存。 使用StringBuffer 或是StringBuild 来拼接字符串，性能会比使用 + 或 +=高三到四个数量级。 尽可能使用并发的 goroutine，然后使用 sync.WaitGroup 来同步分片操作。 避免在热代码中进行内存分配，这样会导致 gc 很忙。尽可能使用 sync.Pool 来重用对象。 使用 lock-free 的操作，避免使用 mutex，尽可能使用 sync/Atomic包 使用 I/O 缓冲，I/O 是个非常非常慢的操作，使用 bufio.NewWrite() 和 bufio.NewReader() 可以带来更高的性能。 对于在 for-loop 里的固定的正则表达式，一定要使用 regexp.Compile() 编译正则表达式。性能会提升两个数量级。 如果你需要更高性能的协议，就要考虑使用 protobuf 或 msgp 而不是 JSON，因为 JSON 的序列化和反序列化里使用了反射。 你在使用 Map 的时候，使用整型的 key 会比字符串的要快，因为整型比较比字符串比较要快。 接口编程1234567891011121314151617181920212223type Country struct &#123; Name string&#125;type City struct &#123; Name string&#125;type Printable interface &#123; PrintStr()&#125;func (c Country) PrintStr() &#123; fmt.Println(c.Name)&#125;func (c City) PrintStr() &#123; fmt.Println(c.Name)&#125;c1 := Country &#123;\"China\"&#125;c2 := City &#123;\"Beijing\"&#125;c1.PrintStr()c2.PrintStr() 可以看到，这段代码中使用了一个 Printable 的接口，而 Country 和 City 都实现了接口方法 PrintStr() 把自己输出。然而，这些代码都是一样的，能不能省掉呢？其实，我们可以使用“结构体嵌入”的方式来完成这个事，如下所示： 12345678910111213141516171819202122232425type WithName struct &#123; Name string&#125;type Country struct &#123; WithName&#125;type City struct &#123; WithName&#125;type Printable interface &#123; PrintStr()&#125;func (w WithName) PrintStr() &#123; fmt.Println(w.Name)&#125;c1 := Country &#123;WithName&#123; \"China\"&#125;&#125;c2 := City &#123; WithName&#123;\"Beijing\"&#125;&#125;c1.PrintStr()c2.PrintStr() 引入一个叫 WithName的结构体，但是这会带来一个问题：在初始化的时候变得有点乱。那么，有没有更好的方法呢？再来看另外一个解。 123456789101112131415161718192021222324252627type Country struct &#123; Name string&#125;type City struct &#123; Name string&#125;type Stringable interface &#123; ToString() string&#125;func (c Country) ToString() string &#123; return \"Country = \" + c.Name&#125;func (c City) ToString() string&#123; return \"City = \" + c.Name&#125;func PrintStr(p Stringable) &#123; fmt.Println(p.ToString())&#125;d1 := Country &#123;\"USA\"&#125;d2 := City&#123;\"Los Angeles\"&#125;PrintStr(d1)PrintStr(d2) 在这段代码中，我们可以看到，我们使用了一个叫Stringable 的接口，我们用这个接口把“业务类型” Country 和 City 和“控制逻辑” Print() 给解耦了。于是，只要实现了Stringable 接口，都可以传给 PrintStr() 来使用。 接口完整性检查123456789101112131415type Shape interface &#123; Sides() int Area() int&#125;type Square struct &#123; len int&#125;func (s* Square) Sides() int &#123; return 4&#125;func main() &#123; s := Square&#123;len: 5&#125; fmt.Printf(\"%d\\n\",s.Sides())&#125; 可以看到，Square 并没有实现 Shape 接口的所有方法，程序虽然可以跑通，但是这样的编程方式并不严谨，如果我们需要强制实现接口的所有方法，那该怎么办呢？ 1var _ Shape = (*Square)(nil) 声明一个 _ 变量（没人用）会把一个 nil 的空指针从 Square 转成 Shape，这样，如果没有实现完相关的接口方法，编译器就会报错： cannot use (*Square)(nil) (type *Square) as type Shape in assignment: *Square does not implement Shape (missing Area method) Functional Options 编程模式12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758package mainimport ( \"crypto/tls\" \"fmt\" \"time\")type Option func(*Server)type Server struct &#123; Addr string Port int Protocol string Timeout time.Duration MaxConns int TLS *tls.Config&#125;func Protocol(p string) Option &#123; return func(s *Server) &#123; s.Protocol = p &#125;&#125;func Timeout(timeout time.Duration) Option &#123; return func(s *Server) &#123; s.Timeout = timeout &#125;&#125;func MaxConns(maxconns int) Option &#123; return func(s *Server) &#123; s.MaxConns = maxconns &#125;&#125;func TLS(tls *tls.Config) Option &#123; return func(s *Server) &#123; s.TLS = tls &#125;&#125;func NewService(addr string, port int, options ...func(*Server)) (*Server, error) &#123; srv := Server&#123; Addr: addr, Port: port, Protocol: \"tcp\", Timeout: 30 * time.Second, MaxConns: 1000, TLS: nil, &#125; for _, option := range options &#123; option(&amp;srv) &#125; //... return &amp;srv, nil&#125;func main() &#123; server, _ := NewService(\"localhost\", 80, Protocol(\"ftp\"),Timeout(5*10)) fmt.Println(server)&#125;","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Golang","slug":"后端/Golang","permalink":"http://xuchen.youtuc.cn/categories/后端/Golang/"}],"tags":[],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Golang","slug":"后端/Golang","permalink":"http://xuchen.youtuc.cn/categories/后端/Golang/"}]},{"title":"gin_validator","slug":"Go/gin_validator","date":"2021-04-12T15:06:03.000Z","updated":"2021-05-04T08:26:08.000Z","comments":true,"path":"2021/04/12/Go/gin_validator/","link":"","permalink":"http://xuchen.youtuc.cn/2021/04/12/Go/gin_validator/","excerpt":"","text":"概述在接口开发经常会遇到一个问题是后端需要写大量的繁琐代码进行数据校验，所以就想着有没有像前端校验一样写规则进行匹配校验，然后就发现了validator包，一个比较强大的校验工具包下面是一些学习总结，详细内容可以查看validator包下载：go get github.com/go-playground/validator/v10 操作符说明 标记 标记说明 , 多操作符分割 &#124; 或操作符 - 跳过验证字段 常用标记说明 标记 标记说明 例 required 必填 Field或Struct validate:”required”,如果int,0作为特殊可通过*int判断 omitempty 空时忽略 Field或Struct validate:”omitempty” len 长度 Field validate:”len=0” eq 等于 Field validate:”eq=0” gt 大于 Field validate:”gt=0” gte 大于等于 Field validate:”gte=0” lt 小于 Field validate:”lt=0” lte 小于等于 Field validate:”lte=0” eqfield 同一结构体字段相等 Field validate:”eqfield=Field2” nefield 同一结构体字段不相等 Field validate:”nefield=Field2” gtfield 大于同一结构体字段 Field validate:”gtfield=Field2” gtefield 大于等于同一结构体字段 Field validate:”gtefield=Field2” ltfield 小于同一结构体字段 Field validate:”ltfield=Field2” ltefield 小于等于同一结构体字段 Field validate:”ltefield=Field2” eqcsfield 跨不同结构体字段相等 Struct1.Field validate:”eqcsfield=Struct2.Field2” necsfield 跨不同结构体字段不相等 Struct1.Field validate:”necsfield=Struct2.Field2” gtcsfield 大于跨不同结构体字段 Struct1.Field validate:”gtcsfield=Struct2.Field2” gtecsfield 大于等于跨不同结构体字段 Struct1.Field validate:”gtecsfield=Struct2.Field2” ltcsfield 小于跨不同结构体字段 Struct1.Field validate:”ltcsfield=Struct2.Field2” ltecsfield 小于等于跨不同结构体字段 Struct1.Field validate:”ltecsfield=Struct2.Field2” min 最大值 Field validate:”min=1” max 最小值 Field validate:”max=2” structonly 仅验证结构体，不验证任何结构体字段 Struct validate:”structonly” nostructlevel 不运行任何结构级别的验证 Struct validate:”nostructlevel” dive 向下延伸验证，多层向下需要多个dive标记 [][]string validate:”gt=0,dive,len=1,dive,required” dive Keys &amp; EndKeys 与dive同时使用，用于对map对象的键的和值的验证，keys为键，endkeys为值 map[string]string validate:”gt=0,dive,keys,eq=1|eq=2,endkeys,required” required_with 其他字段其中一个不为空且当前字段不为空 Field validate:”required_with=Field1 Field2” required_with_all 其他所有字段不为空且当前字段不为空 Field validate:”required_with_all=Field1 Field2” required_without 其他字段其中一个为空且当前字段不为空 Field `validate:”required_without=Field1 Field2” required_without_all 其他所有字段为空且当前字段不为空 Field validate:”required_without_all=Field1 Field2” isdefault 是默认值 Field validate:”isdefault=0” oneof 其中之一 Field validate:”oneof=5 7 9” containsfield 字段包含另一个字段 Field validate:”containsfield=Field2” excludesfield 字段不包含另一个字段 Field validate:”excludesfield=Field2” unique 是否唯一，通常用于切片或结构体 Field validate:”unique” alphanum 字符串值是否只包含 ASCII 字母数字字符 Field validate:”alphanum” alphaunicode 字符串值是否只包含 unicode 字符 Field validate:”alphaunicode” alphanumunicode 字符串值是否只包含 unicode 字母数字字符 Field validate:”alphanumunicode” numeric 字符串值是否包含基本的数值 Field validate:”numeric” hexadecimal 字符串值是否包含有效的十六进制 Field validate:”hexadecimal” hexcolor 字符串值是否包含有效的十六进制颜色 Field validate:”hexcolor” lowercase 符串值是否只包含小写字符 Field validate:”lowercase” uppercase 符串值是否只包含大写字符 Field validate:”uppercase” email 字符串值包含一个有效的电子邮件 Field validate:”email” json 字符串值是否为有效的 JSON Field validate:”json” file 符串值是否包含有效的文件路径，以及该文件是否存在于计算机上 Field validate:”file” url 符串值是否包含有效的 url Field validate:”url” uri 符串值是否包含有效的 uri Field validate:”uri” base64 字符串值是否包含有效的 base64值 Field validate:”base64” contains 字符串值包含子字符串值 Field validate:”contains=@” containsany 字符串值包含子字符串值中的任何字符 Field validate:”containsany=abc” containsrune 字符串值包含提供的特殊符号值 Field validate:”containsrune=☢” excludes 字符串值不包含子字符串值 Field validate:”excludes=@” excludesall 字符串值不包含任何子字符串值 Field validate:”excludesall=abc” excludesrune 字符串值不包含提供的特殊符号值 Field validate:”containsrune=☢” startswith 字符串以提供的字符串值开始 Field validate:”startswith=abc” endswith 字符串以提供的字符串值结束 Field validate:”endswith=abc” ip 字符串值是否包含有效的 IP 地址 Field validate:”ip” ipv4 字符串值是否包含有效的 ipv4地址 Field validate:”ipv4” datetime 字符串值是否包含有效的 日期 Field validate:”datetime” 使用示例使用注意 当搜索条件与特殊标记冲突时,如：逗号（,），或操作（|），中横线（-）等则需要使用 UTF-8十六进制表示形式 1234type Test struct &#123; Field1 string `validate:\"excludesall=|\"` // 错误 Field2 string `validate:\"excludesall=0x7C\"` // 正确.&#125; 可通过validationErrors := errs.(validator.ValidationErrors)获取错误对象自定义返回响应错误 自定义校验结果翻译 123456789101112131415// 初始化翻译器func validateInit() &#123; zh_ch := zh.New() uni := ut.New(zh_ch) // 万能翻译器，保存所有的语言环境和翻译数据 Trans, _ = uni.GetTranslator(\"zh\") // 翻译器 Validate = validator.New() _ = zh_translations.RegisterDefaultTranslations(Validate, Trans) // 添加额外翻译 _ = Validate.RegisterTranslation(\"required_without\", Trans, func(ut ut.Translator) error &#123; return ut.Add(\"required_without\", \"&#123;0&#125; 为必填字段!\", true) &#125;, func(ut ut.Translator, fe validator.FieldError) string &#123; t, _ := ut.T(\"required_without\", fe.Field()) return t &#125;)&#125; 使用示例123456789101112131415161718192021222324package mainimport ( \"fmt\" \"github.com/go-playground/validator/v10\")// 实例化验证对象var validate = validator.New()func main() &#123; // 结构体验证 type Inner struct &#123; String string `validate:\"contains=111\"` &#125; inner := &amp;Inner&#123;String: \"11@\"&#125; errs := validate.Struct(inner) if errs != nil &#123; fmt.Println(errs.Error()) &#125; // 变量验证 m := map[string]string&#123;\"\": \"\", \"val3\": \"val3\"&#125; errs = validate.Var(m, \"required,dive,keys,required,endkeys,required\") if errs != nil &#123; fmt.Println(errs.Error()) &#125;&#125; gin框架中使用验证器定义错误翻译器123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124package xcoreimport ( \"fmt\" \"github.com/gin-gonic/gin/binding\" \"reflect\" \"strings\" //gin表单验证 \"github.com/go-playground/locales/en\" \"github.com/go-playground/locales/zh\" \"github.com/go-playground/universal-translator\" \"github.com/go-playground/validator/v10\" enTranslations \"github.com/go-playground/validator/v10/translations/en\" zhTranslations \"github.com/go-playground/validator/v10/translations/zh\")// 定义一个全局翻译器var trans ut.Translator// InitTrans 初始化翻译器func InitTrans(locale string) (err error) &#123; //修改gin框架中的Validator属性，实现自定制 if v, ok := binding.Validator.Engine().(*validator.Validate); ok &#123; // 注册一个获取json tag的自定义方法 v.RegisterTagNameFunc(func(fld reflect.StructField) string &#123; name := strings.SplitN(fld.Tag.Get(\"json\"), \",\", 2)[0] if name == \"-\" &#123; return \"\" &#125; return name &#125;) zhT := zh.New() //中文翻译器 enT := en.New() //英文翻译器 // 第一个参数是备用（fallback）的语言环境 // 后面的参数是应该支持的语言环境（支持多个） // uni := ut.New(zhT, zhT) 也是可以的 uni := ut.New(enT, zhT, enT) // locale 通常取决于 http 请求头的 'Accept-Language' var ok bool // 也可以使用 uni.FindTranslator(...) 传入多个locale进行查找 trans, ok = uni.GetTranslator(locale) if !ok &#123; return fmt.Errorf(\"uni.GetTranslator(%s) failed\", locale) &#125; // 添加额外翻译 _ = v.RegisterTranslation(\"required_with\", trans, func(ut ut.Translator) error &#123; return ut.Add(\"required_with\", \"&#123;0&#125; 为必填字段!\", true) &#125;, func(ut ut.Translator, fe validator.FieldError) string &#123; t, _ := ut.T(\"required_with\", fe.Field()) return t &#125;) _ = v.RegisterTranslation(\"required_without\", trans, func(ut ut.Translator) error &#123; return ut.Add(\"required_without\", \"&#123;0&#125; 为必填字段!\", true) &#125;, func(ut ut.Translator, fe validator.FieldError) string &#123; t, _ := ut.T(\"required_without\", fe.Field()) return t &#125;) _ = v.RegisterTranslation(\"required_without_all\", trans, func(ut ut.Translator) error &#123; return ut.Add(\"required_without_all\", \"&#123;0&#125; 为必填字段!\", true) &#125;, func(ut ut.Translator, fe validator.FieldError) string &#123; t, _ := ut.T(\"required_without_all\", fe.Field()) return t &#125;) // 注册翻译器 switch locale &#123; case \"en\": err = enTranslations.RegisterDefaultTranslations(v, trans) case \"zh\": err = zhTranslations.RegisterDefaultTranslations(v, trans) default: err = enTranslations.RegisterDefaultTranslations(v, trans) &#125; return &#125; return&#125;func addValueToMap(fields map[string]string) map[string]interface&#123;&#125; &#123; res := make(map[string]interface&#123;&#125;) for field, err := range fields &#123; fieldArr := strings.SplitN(field, \".\", 2) if len(fieldArr) &gt; 1 &#123; NewFields := map[string]string&#123;fieldArr[1]: err&#125; returnMap := addValueToMap(NewFields) if res[fieldArr[0]] != nil &#123; for k, v := range returnMap &#123; res[fieldArr[0]].(map[string]interface&#123;&#125;)[k] = v &#125; &#125; else &#123; res[fieldArr[0]] = returnMap &#125; continue &#125; else &#123; res[field] = err continue &#125; &#125; return res&#125;// 去掉结构体名称前缀func removeTopStruct(fields map[string]string) map[string]interface&#123;&#125; &#123; lowerMap := map[string]string&#123;&#125; for field, err := range fields &#123; fieldArr := strings.SplitN(field, \".\", 2) lowerMap[fieldArr[1]] = err &#125; res := addValueToMap(lowerMap) return res&#125;//handler中调用的错误翻译方法func ValidatorError(err error) map[string]interface&#123;&#125; &#123; errs, ok := err.(validator.ValidationErrors) if ok &#123; return removeTopStruct(errs.Translate(trans)) &#125; return nil&#125; 使用12345678func (c *IndexController) Validator(ctx *gin.Context) &#123; req := requests.AdminReq&#123;&#125; if err := ctx.ShouldBindJSON(&amp;req); err != nil &#123; ctx.JSON(http.StatusBadRequest, gin.H&#123;\"error\": xcore.ValidatorError(err)&#125;) return &#125; ctx.JSON(http.StatusNotFound, \"ok\")&#125;","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Golang","slug":"后端/Golang","permalink":"http://xuchen.youtuc.cn/categories/后端/Golang/"}],"tags":[],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Golang","slug":"后端/Golang","permalink":"http://xuchen.youtuc.cn/categories/后端/Golang/"}]},{"title":"TCP和UDP","slug":"网络/TCP和UDP","date":"2020-05-24T02:28:12.000Z","updated":"2021-05-04T08:26:08.000Z","comments":true,"path":"2020/05/24/网络/TCP和UDP/","link":"","permalink":"http://xuchen.youtuc.cn/2020/05/24/网络/TCP和UDP/","excerpt":"","text":"UDP 和 TCP 的特点与区别 用户数据报协议 UDP（User Datagram Protocol）是无连接的，尽最大可能交付，没有拥塞控制，面向报文（对于应用程序传下来的报文不合并也不拆分，只是添加 UDP 首部），支持一对一、一对多、多对一和多对多的交互通信。 传输控制协议 TCP（Transmission Control Protocol）是面向连接的，提供可靠交付，有流量控制，拥塞控制，提供全双工通信，面向字节流（把应用层传下来的报文看成字节流，把字节流组织成大小不等的数据块），每一条 TCP 连接只能是点对点的（一对一）。 UDP 、TCP 首部格式UDP 首部字段只有 8 个字节，包括源端口、目的端口、长度、检验和。12 字节的伪首部是为了计算检验和临时添加的。TCP 首部格式比 UDP 复杂。 序号：用于对字节流进行编号，例如序号为 301，表示第一个字节的编号为 301，如果携带的数据长度为 100 字节，那么下一个报文段的序号应为 401。 确认号：期望收到的下一个报文段的序号。例如 B 正确收到 A 发送来的一个报文段，序号为 501，携带的数据长度为 200 字节，因此 B 期望下一个报文段的序号为 701，B 发送给 A 的确认报文段中确认号就为 701。 数据偏移：指的是数据部分距离报文段起始处的偏移量，实际上指的是首部的长度。 控制位：八位从左到右分别是 CWR，ECE，URG，ACK，PSH，RST，SYN，FIN。 字段 含义 CWR CWR 标志与后面的 ECE 标志都用于 IP 首部的 ECN 字段，ECE 标志为 1 时，则通知对方已将拥塞窗口缩小 ECE 若其值为 1 则会通知对方，从对方到这边的网络有阻塞。在收到数据包的 IP 首部中 ECN 为 1 时将 TCP 首部中的 ECE 设为 1 URG 紧急指针是否有效。为1，表示某一位需要被优先处理 ACK 确认号是否有效，一般置为1。 PSH 提示接收端应用程序立即从TCP缓冲区把数据读走 RST 对方要求重新建立连接，复位 SYN 请求建立连接，并在其序列号的字段进行序列号的初始值设定。建立连接，设置为1 FIN 希望断开连接 窗口：窗口值作为接收方让发送方设置其发送窗口的依据。之所以要有这个限制，是因为接收方的数据缓存空间是有限的。 TCP 的三次握手（为什么三次？） 客户端发送一个SYN段，并指明客户端的初始序列号，即ISN(c). 服务端发送自己的SYN段作为应答，同样指明自己的ISN(s)。为了确认客户端的SYN，将ISN(c)+1作为ACK数值。这样，每发送一个SYN，序列号就会加1. 如果有丢失的情况，则会重传。 为了确认服务器端的SYN，客户端将ISN(s)+1作为返回的ACK数值。 为什么三次：客户端和服务端通信前要进行连接，“3次握手”的作用就是双方都能明确自己和对方的收、发能力是正常的。 第一次握手：客户端发送网络包，服务端收到了。这样服务端就能得出结论：客户端的发送能力、服务端的接收能力是正常的。 第二次握手：服务端发包，客户端收到了。这样客户端就能得出结论：服务端的接收、发送能力，客户端的接收、发送能力是正常的。 从客户端的视角来看，我接到了服务端发送过来的响应数据包，说明服务端接收到了我在第一次握手时发送的网络包，并且成功发送了响应数据包，这就说明，服务端的接收、发送能力正常。而另一方面，我收到了服务端的响应数据包，说明我第一次发送的网络包成功到达服务端，这样，我自己的发送和接收能力也是正常的。 第三次握手：客户端发包，服务端收到了。这样服务端就能得出结论：客户端的接收、发送能力，服务端的发送、接收能力是正常的。 第一、二次握手后，服务端并不知道客户端的接收能力以及自己的发送能力是否正常。而在第三次握手时，服务端收到了客户端对第二次握手作的回应。从服务端的角度，我在第二次握手时的响应数据发送出去了，客户端接收到了。所以，我的发送能力是正常的。而客户端的接收能力也是正常的。 经历了上面的三次握手过程，客户端和服务端都确认了自己的接收、发送能力是正常的。之后就可以正常通信了。 TCP 的四次挥手（为什么四次？） 客户端发送一个FIN段，并包含一个希望接收者看到的自己当前的序列号u. 同时还包含一个ACK表示确认对方最近一次发过来的数据。 服务端将u值加1作为ack序号值，表明收到了上一个包。这时上层的应用程序会被告知另一端发起了关闭操作，通常这将引起应用程序发起自己的关闭操作。 服务端发起自己的FIN段和ACK码，ack=u+1, seq=w 客户端确认。ack=w+1 为什么建立连接是三次握手，而关闭连接却是四次挥手呢？ 1、TCP连接是双向传输的对等的模式，就是说双方都可以同时向对方发送或接收数据。当有一方要关闭连接时，会发送指令告知对方，我要关闭连接了。 2、这时对方会回一个ACK，此时一个方向的连接关闭。但是另一个方向仍然可以继续传输数据，也就是说，服务端收到客户端的 FIN 标志，知道客户端想要断开这次连接了，但是，我服务端，我还想发数据呢？我等到发送完了所有的数据后，会发送一个 FIN 段来关闭此方向上的连接。接收方发送 ACK确认关闭连接。 注意，接收到FIN报文的一方只能回复一个ACK, 它是无法马上返回对方一个FIN报文段的，因为结束数据传输的“指令”是上层应用层给出的，我只是一个“搬运工”，我无法了解“上层的意志”。 3、客户端发送了 FIN 连接释放报文之后，服务器收到了这个报文，就进入了 CLOSE-WAIT 状态。这个状态是为了让服务器端发送还未传送完毕的数据，传送完毕之后，服务器会发送 FIN 连接释放报文。 4、因为服务端在 LISTEN 状态下，收到建立连接请求的 SYN 报文后，把 ACK 和 SYN 放在一个报文里发送给客户端。而关闭连接时，当收到对方的 FIN 报文时，仅仅表示对方不再发送数据了但是还能接收数据，己方是否现在关闭发送数据通道，需要上层应用来决定，因此，己方 ACK 和 FIN 一般都会分开发。 TCP 长连接和短连接的区别 短连接：Client 向 Server 发送消息，Server 回应 Client，然后一次读写就完成了，这时候双方任何一个都可以发起 close 操作，不过一般都是 Client 先发起 close 操作。短连接一般只会在 Client/Server 间传递一次读写操作。 短连接的优点：管理起来比较简单，建立存在的连接都是有用的连接，不需要额外的控制手段。 长连接：Client 与 Server 完成一次读写之后，它们之间的连接并不会主动关闭，后续的读写操作会继续使用这个连接。 在长连接的应用场景下，Client 端一般不会主动关闭它们之间的连接，Client 与 Server 之间的连接如果一直不关闭的话，随着客户端连接越来越多，Server 压力也越来越大，这时候 Server 端需要采取一些策略，如关闭一些长时间没有读写事件发生的连接，这样可以避免一些恶意连接导致 Server 端服务受损；如果条件再允许可以以客户端为颗粒度，限制每个客户端的最大长连接数，从而避免某个客户端连累后端的服务。 TCP粘包、拆包及解决办法 为什么常说 TCP 有粘包和拆包的问题而不说 UDP ？ 由前两节可知，UDP 是基于报文发送的，UDP首部采用了 16bit 来指示 UDP 数据报文的长度，因此在应用层能很好的将不同的数据报文区分开，从而避免粘包和拆包的问题。 而 TCP 是基于字节流的，虽然应用层和 TCP 传输层之间的数据交互是大小不等的数据块，但是 TCP 并没有把这些数据块区分边界，仅仅是一连串没有结构的字节流；另外从 TCP 的帧结构也可以看出，在 TCP 的首部没有表示数据长度的字段，基于上面两点，在使用 TCP 传输数据时，才有粘包或者拆包现象发生的可能。 什么是粘包、拆包？假设 Client 向 Server 连续发送了两个数据包，用 packet1 和 packet2 来表示，那么服务端收到的数据可以分为三种情况，现列举如下： 第一种情况，接收端正常收到两个数据包，即没有发生拆包和粘包的现象。 第二种情况，接收端只收到一个数据包，但是这一个数据包中包含了发送端发送的两个数据包的信息，这种现象即为粘包。这种情况由于接收端不知道这两个数据包的界限，所以对于接收端来说很难处理。 第三种情况，这种情况有两种表现形式，如下图。接收端收到了两个数据包，但是这两个数据包要么是不完整的，要么就是多出来一块，这种情况即发生了拆包和粘包。这两种情况如果不加特殊处理，对于接收端同样是不好处理的。 为什么会发生 TCP 粘包、拆包？ 要发送的数据大于 TCP 发送缓冲区剩余空间大小，将会发生拆包。 待发送数据大于 MSS（最大报文长度），TCP 在传输前将进行拆包。 要发送的数据小于 TCP 发送缓冲区的大小，TCP 将多次写入缓冲区的数据一次发送出去，将会发生粘包。 接收数据端的应用层没有及时读取接收缓冲区中的数据，将发生粘包。 粘包、拆包解决办法由于 TCP 本身是面向字节流的，无法理解上层的业务数据，所以在底层是无法保证数据包不被拆分和重组的，这个问题只能通过上层的应用协议栈设计来解决，根据业界的主流协议的解决方案，归纳如下： 消息定长：发送端将每个数据包封装为固定长度（不够的可以通过补 0 填充），这样接收端每次接收缓冲区中读取固定长度的数据就自然而然的把每个数据包拆分开来。 设置消息边界：服务端从网络流中按消息边界分离出消息内容。在包尾增加回车换行符进行分割，例如 FTP 协议。 将消息分为消息头和消息体：消息头中包含表示消息总长度（或者消息体长度）的字段。 更复杂的应用层协议比如 Netty 中实现的一些协议都对粘包、拆包做了很好的处理。 TCP 可靠传输 TCP 滑动窗口窗口是缓存的一部分，用来暂时存放字节流。发送方和接收方各有一个窗口，接收方通过 TCP 报文段中的窗口字段告诉发送方自己的窗口大小，发送方根据这个值和其它信息设置自己的窗口大小。 发送窗口内的字节都允许被发送，接收窗口内的字节都允许被接收。如果发送窗口左部的字节已经发送并且收到了确认，那么就将发送窗口向右滑动一定距离，直到左部第一个字节不是已发送并且已确认的状态；接收窗口的滑动类似，接收窗口左部字节已经发送确认并交付主机，就向右滑动接收窗口。 接收窗口只会对窗口内最后一个按序到达的字节进行确认，例如接收窗口已经收到的字节为 {31, 34, 35}，其中 {31} 按序到达，而 {34, 35} 就不是，因此只对字节 31 进行确认。发送方得到一个字节的确认之后，就知道这个字节之前的所有字节都已经被接收。 TCP 流量控制 TCP 拥塞控制 提供网络利用率","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"网络","slug":"后端/网络","permalink":"http://xuchen.youtuc.cn/categories/后端/网络/"}],"tags":[{"name":"面试","slug":"面试","permalink":"http://xuchen.youtuc.cn/tags/面试/"},{"name":"TCP","slug":"TCP","permalink":"http://xuchen.youtuc.cn/tags/TCP/"},{"name":"UDP","slug":"UDP","permalink":"http://xuchen.youtuc.cn/tags/UDP/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"网络","slug":"后端/网络","permalink":"http://xuchen.youtuc.cn/categories/后端/网络/"}]},{"title":"Go-GMP模型","slug":"Go/GMP模型","date":"2020-04-11T17:07:55.000Z","updated":"2021-05-04T08:26:08.000Z","comments":true,"path":"2020/04/11/Go/GMP模型/","link":"","permalink":"http://xuchen.youtuc.cn/2020/04/11/Go/GMP模型/","excerpt":"","text":"https://learnku.com/articles/41728 GMP 模型 G= Goroutine 协程，P=Processor 处理器， M=Thread 线程 全局队列（Global Queue）：存放等待运行的 G。 P 的本地队列：同全局队列类似，存放的也是等待运行的 G，存的数量有限，不超过 256 个。新建 G’时，G’优先加入到 P 的本地队列，如果队列满了，则会把本地队列中一半的 G 移动到全局队列。 P 列表：所有的 P 都在程序启动时创建，并保存在数组中，最多有 GOMAXPROCS(可配置) 个。 M：线程想运行任务就得获取 P，从 P 的本地队列获取 G，P 队列为空时，M 也会尝试从全局队列拿一批 G 放到 P 的本地队列，或从其他 P 的本地队列偷一半放到自己 P 的本地队列。M 运行 G，G 执行之后，M 会从 P 获取下一个 G，不断重复下去。 Goroutine 调度器和 OS 调度器是通过 M 结合起来的，每个 M 都代表了 1 个内核线程，OS 调度器负责把内核线程分配到 CPU 的核上执行。 有关 P 和 M 的个数问题 P的数量： 由启动时环境变量 $GOMAXPROCS 或者是由 runtime 的方法 GOMAXPROCS() 决定。这意味着在程序执行的任意时刻都只有 $GOMAXPROCS 个 goroutine 在同时运行。 M的数量： go 语言本身的限制：go 程序启动时，会设置 M 的最大数量，默认 10000. 但是内核很难支持这么多的线程数，所以这个限制可以忽略。 runtime/debug 中的 SetMaxThreads 函数，设置 M 的最大数量 一个 M 阻塞了，会创建新的 M。 M 与 P 的数量没有绝对关系，一个 M 阻塞，P 就会去创建或者切换另一个 M，所以，即使 P 的默认数量是 1，也有可能会创建很多个 M 出来。 P 和 M 何时会被创建 P 何时创建：在确定了 P 的最大数量 n 后，运行时系统会根据这个数量创建 n 个 P。 M 何时创建：没有足够的 M 来关联 P 并运行其中的可运行的 G。比如所有的 M 此时都阻塞住了，而 P 中还有很多就绪任务，就会去寻找空闲的 M，而没有空闲的，就会去创建新的 M。 调度器的设计策略 复用线程：避免频繁的创建、销毁线程，而是对线程的复用。 work stealing 机制：当本线程无可运行的 G 时，尝试从其他线程绑定的 P 偷取 G，而不是销毁线程。 hand off 机制：​ 当本线程因为 G 进行系统调用阻塞时，线程释放绑定的 P，把 P 转移给其他空闲的线程执行。 利用并行：GOMAXPROCS 设置 P 的数量，最多有 GOMAXPROCS 个线程分布在多个 CPU 上同时运行。GOMAXPROCS 也限制了并发的程度，比如 GOMAXPROCS= 核数/2，则最多利用了一半的 CPU 核进行并行。 抢占：在 coroutine 中要等待一个协程主动让出 CPU 才执行下一个协程，在 Go 中，一个 goroutine 最多占用 CPU 10ms， 防止其他 goroutine 被饿死，这就是 goroutine 不同于 coroutine 的一个地方。 全局 G 队列：在新的调度器中依然有全局 G 队列，但功能已经被弱化了，当 M 执行 work stealing 从其他 P 偷不到 G 时，它可以从全局 G 队列获取 G。 go func () 调度流程 我们通过 go func () 来创建一个 goroutine； 有两个存储 G 的队列，一个是局部调度器 P 的本地队列、一个是全局 G 队列。新创建的 G 会先保存在 P 的本地队列中，如果 P 的本地队列已经满了就会保存在全局的队列中；​3. G 只能运行在 M 中，一个 M 必须持有一个 P，M 与 P 是 1：1 的关系。M 会从 P 的本地队列弹出一个可执行状态的 G 来执行，如果 P 的本地队列为空，就会想其他的 MP 组合偷取一个可执行的 G 来执行；​4. 一个 M 调度 G 执行的过程是一个循环机制； 当 M 执行某一个 G 时候如果发生了 syscall 或则其余阻塞操作，M 会阻塞，如果当前有一些 G 在执行，runtime 会把这个线程 M 从 P 中摘除 (detach)，然后再创建一个新的操作系统的线程 (如果有空闲的线程可用就复用空闲线程) 来服务于这个 P； 当 M 系统调用结束时候，这个 G 会尝试获取一个空闲的 P 执行，并放入到这个 P 的本地队列。如果获取不到 P，那么这个线程 M 变成休眠状态， 加入到空闲线程中，然后这个 G 会被放入全局队列中。 调度器的生命周期 特殊的 M0 和 G0 M0 是启动程序后的编号为 0 的主线程，这个 M 对应的实例会在全局变量 runtime.m0 中，不需要在 heap 上分配，M0 负责执行初始化操作和启动第一个 G， 在之后 M0 就和其他的 M 一样了。 GO 是每次启动一个 M 都会第一个创建的 gourtine，G0 仅用于负责调度的 G，G0 不指向任何可执行的函数，每个 M 都会有一个自己的 G0。在调度或系统调用时会使用 G0 的栈空间，全局变量的 G0 是 M0 的 G0。 可视化 GMP 编程 方式 1：go tool trace 方式 2：Debug trace","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Golang","slug":"后端/Golang","permalink":"http://xuchen.youtuc.cn/categories/后端/Golang/"}],"tags":[{"name":"面试","slug":"面试","permalink":"http://xuchen.youtuc.cn/tags/面试/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Golang","slug":"后端/Golang","permalink":"http://xuchen.youtuc.cn/categories/后端/Golang/"}]},{"title":"常用算法代码模板","slug":"LeetCode/Note/常用算法代码模板","date":"2020-03-16T16:27:08.000Z","updated":"2020-05-18T05:44:55.000Z","comments":true,"path":"2020/03/16/LeetCode/Note/常用算法代码模板/","link":"","permalink":"http://xuchen.youtuc.cn/2020/03/16/LeetCode/Note/常用算法代码模板/","excerpt":"","text":"深度优先12345678910var vistied Setfunc dfs(node,vistied)&#123; vistied.add(node) //doSomething for next_node in node.chlidren() &#123; if next_node not in vistied &#123; dfs(next_node,vistied) &#125; &#125;&#125; 广度优先12345678910111213141516171819202122232425262728293031//广度搜索的模板func levelOrder(root *TreeNode) [][]int &#123; res := make([][]int, 0) if root == nil &#123; return res &#125; //存放相邻节点的 que := make([]*TreeNode, 0) que = append(que, root) for len(que) &gt; 0 &#123; lvLenght := len(que) //当前层队列有几个数据 lvArr := make([]int, 0) lvQue := make([]*TreeNode, 0) for i := 0; i &lt; lvLenght; i++ &#123; //弹出数据 node := que[0] que = que[1:] lvArr = append(lvArr, node.Val) if node.Left != nil &#123; lvQue = append(lvQue, node.Left) &#125; if node.Right != nil &#123; lvQue = append(lvQue, node.Right) &#125; &#125; que = append(que, lvQue...) res = append(res, lvArr) &#125; return res&#125; 二分查找12345678910111213141516int binary_search(int[] nums, int target) &#123; int left = 0, right = nums.length - 1; while(left &lt;= right) &#123; int mid = left + (right - left) / 2; if (nums[mid] &lt; target) &#123; left = mid + 1; &#125; else if (nums[mid] &gt; target) &#123; right = mid - 1; &#125; else if(nums[mid] == target) &#123; // 直接返回 return mid; &#125; &#125; // 直接返回 return -1;&#125; 二分查找-左边界123456789101112131415161718int left_bound(int[] nums, int target) &#123; int left = 0, right = nums.length - 1; while (left &lt;= right) &#123; int mid = left + (right - left) / 2; if (nums[mid] &lt; target) &#123; left = mid + 1; &#125; else if (nums[mid] &gt; target) &#123; right = mid - 1; &#125; else if (nums[mid] == target) &#123; // 别返回，锁定左侧边界 right = mid - 1; &#125; &#125; // 最后要检查 left 越界的情况 if (left &gt;= nums.length || nums[left] != target) return -1; return left;&#125; 二分查找-右边界123456789101112131415161718int right_bound(int[] nums, int target) &#123; int left = 0, right = nums.length - 1; while (left &lt;= right) &#123; int mid = left + (right - left) / 2; if (nums[mid] &lt; target) &#123; left = mid + 1; &#125; else if (nums[mid] &gt; target) &#123; right = mid - 1; &#125; else if (nums[mid] == target) &#123; // 别返回，锁定右侧边界 left = mid + 1; &#125; &#125; // 最后要检查 right 越界的情况 if (right &lt; 0 || nums[right] != target) return -1; return right;&#125; 快慢指针1234567891011121314func hasCycle(head *ListNode) bool &#123; if head == nil || head.Next == nil &#123; return false &#125; fast, slow := head.Next, head for slow != fast &#123; if fast == nil || fast.Next == nil &#123; return false &#125; fast = fast.Next.Next slow = slow.Next &#125; return true&#125; 链表翻转互换1234567891011var prev *ListNode curr := head for curr != nil &#123; //curr.Next, prev, curr = prev, curr, curr.Next next := curr.Next curr.Next = prev prev = curr curr = next &#125; return prev 回溯算法直接上回溯算法框架。解决一个回溯问题，实际上就是一个决策树的遍历过程。你只需要思考 3 个问题： 路径：也就是已经做出的选择。 选择列表：也就是你当前可以做的选择。 结束条件：也就是到达决策树底层，无法再做选择的条件。代码方面，回溯算法的框架： 12345678910result = []def backtrack(路径, 选择列表): if 满足结束条件: result.add(路径) returnfor 选择 in 选择列表: 做选择 backtrack(路径, 选择列表) 撤销选择 [1,2,3] 所有可能排列组合 12345678910111213141516171819202122232425262728func combinationSum(candidates []int, target int) [][]int &#123; result := make([][]int, 0) track := make([]int, 0) var visited = make([]bool, len(candidates)) backtrack(candidates, track, &amp;result, visited) return result&#125;// 路径：记录在 track 中// 选择列表：nums 中的元素// 结束条件：nums 中的元素全都在 track 中出现func backtrack(nums []int, track []int, result *[][]int, visited []bool) &#123; //触发条件 if len(track) == len(nums) &#123; *result = append(*result, track) return &#125; for i := 0; i &lt; len(nums); i++ &#123; if !visited[i] &#123; visited[i] = true track = append(track, nums[i]) backtrack(nums, track, result, visited) track = track[:len(track)-1] visited[i] = false &#125; &#125;&#125; 滑动窗口算法12345678910111213int left = 0, right = 0;​while (right &lt; s.size()) &#123; // 增大窗口 window.add(s[right]); right++;​ while (window needs shrink) &#123; // 缩小窗口 window.remove(s[left]); left++; &#125;&#125; 滑动窗口算法的思路是这样：1、我们在字符串 S 中使用双指针中的左右指针技巧，初始化 left = right = 0，把索引左闭右开区间 [left, right) 称为一个「窗口」。2、我们先不断地增加 right 指针扩大窗口 [left, right)，直到窗口中的字符串符合要求（包含了 T 中的所有字符）。3、此时，我们停止增加 right，转而不断增加 left 指针缩小窗口 [left, right)，直到窗口中的字符串不再符合要求（不包含 T 中的所有字符了）。同时，每次增加 left，我们都要更新一轮结果。4、重复第 2 和第 3 步，直到 right 到达字符串 S 的尽头。 这个思路其实也不难，第 2 步相当于在寻找一个「可行解」，然后第 3 步在优化这个「可行解」，最终找到最优解，也就是最短的覆盖子串。左右指针轮流前进，窗口大小增增减减，窗口不断向右滑动，这就是「滑动窗口」这个名字的来历。 动态规划模板(背包类型问题)第一步要明确两点，「状态」和「选择」。先说状态，如何才能描述一个问题局面？只要给几个物品和一个背包的容量限制，就形成了一个背包问题呀。所以状态有两个，就是「背包的容量」和「可选择的物品」 1234for 状态1 in 状态1的所有取值： for 状态2 in 状态2的所有取值： for ... dp[状态1][状态2][...] = 择优(选择1，选择2...) 第二步要明确 dp 数组的定义再说选择，也很容易想到啊，对于每件物品，你能选择什么？选择就是「装进背包」或者「不装进背包」嘛。 1234567891011int dp[N+1][W+1]dp[0][..] = 0dp[..][0] = 0for i in [1..N]: for w in [1..W]: dp[i][w] = max( 把物品 i 装进背包, 不把物品 i 装进背包 )return dp[N][W] 第三步，根据「选择」，思考状态转移的逻辑。如果你没有把这第 i 个物品装入背包，那么很显然，最大价值 dp[i][w] 应该等于 dp[i-1][w]，继承之前的结果。如果你把这第 i 个物品装入了背包，那么 dp[i][w] 应该等于 dp[i-1][w - wt[i-1]] + val[i-1] 1234567for i in [1..N]: for w in [1..W]: dp[i][w] = max( dp[i-1][w], dp[i-1][w - wt[i-1]] + val[i-1] )return dp[N][W] 动态规划模板(最长子序列问题) 思路一：一个一维的 dp 数组12345678int n = array.length;int[] dp = new int[n];for (int i = 1; i &lt; n; i++) &#123; for (int j = 0; j &lt; i; j++) &#123; dp[i] = 最值(dp[i], dp[j] + ...) &#125;&#125; 在子数组 array[0..i] 中，我们要求的子序列（最长递增子序列）的长度是 dp[i]。 思路二：一个二维的 dp 数组： 1234567891011int n = arr.length;int[][] dp = new dp[n][n];for (int i = 0; i &lt; n; i++) &#123; for (int j = 0; j &lt; n; j++) &#123; if (arr[i] == arr[j]) dp[i][j] = dp[i][j] + ... else dp[i][j] = 最值(...) &#125;&#125; 涉及两个字符串/数组时 在子数组 arr1[0..i] 和子数组 arr2[0..j] 中，我们要求的子序列（最长公共子序列）长度为 dp[i][j] 只涉及一个字符串/数组时 在子数组 array[i..j] 中，我们要求的子序列（最长回文子序列）的长度为 dp[i][j]。","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"数据结构","slug":"后端/数据结构","permalink":"http://xuchen.youtuc.cn/categories/后端/数据结构/"}],"tags":[{"name":"算法模板","slug":"算法模板","permalink":"http://xuchen.youtuc.cn/tags/算法模板/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"数据结构","slug":"后端/数据结构","permalink":"http://xuchen.youtuc.cn/categories/后端/数据结构/"}]},{"title":"深度优先和广度优先-理论","slug":"LeetCode/Data/图-深度优先和广度优先(理论)","date":"2020-02-18T16:23:00.000Z","updated":"2021-05-04T08:26:08.000Z","comments":true,"path":"2020/02/18/LeetCode/Data/图-深度优先和广度优先(理论)/","link":"","permalink":"http://xuchen.youtuc.cn/2020/02/18/LeetCode/Data/图-深度优先和广度优先(理论)/","excerpt":"","text":"1、深度优先搜索介绍图的深度优先搜索(Depth First Search)，和树的先序遍历比较类似。 它的思想：假设初始状态是图中所有顶点均未被访问，则从某个顶点v出发，首先访问该顶点，然后依次从它的各个未被访问的邻接点出发深度优先搜索遍历图，直至图中所有和v有路径相通的顶点都被访问到。 若此时尚有其他顶点未被访问到，则另选一个未被访问的顶点作起始点，重复上述过程，直至图中所有顶点都被访问到为止。 显然，深度优先搜索是一个递归的过程。 #1.1 深度优先的代码模板 12345678910var vistied Setfunc dfs(node,vistied)&#123; vistied.add(node) //doSomething for next_node in node.chlidren() &#123; if next_node not in vistied &#123; dfs(next_node,vistied) &#125; &#125;&#125; 2、深度优先图解2.1 无向图的深度优先搜索下面以”无向图”为例，来对深度优先搜索进行演示。 对上面的图G1进行深度优先遍历，从顶点A开始。 第1步：访问A。第2步：访问(A的邻接点)C。 在第1步访问A之后，接下来应该访问的是A的邻接点，即”C,D,F”中的一个。但在本文的实现中，顶点ABCDEFG是按照顺序存储，C在”D和F”的前面，因此，先访问C。第3步：访问(C的邻接点)B。 在第2步访问C之后，接下来应该访问C的邻接点，即”B和D”中一个(A已经被访问过，就不算在内)。而由于B在D之前，先访问B。第4步：访问(C的邻接点)D。 在第3步访问了C的邻接点B之后，B没有未被访问的邻接点；因此，返回到访问C的另一个邻接点D。第5步：访问(A的邻接点)F。 前面已经访问了A，并且访问完了”A的邻接点B的所有邻接点(包括递归的邻接点在内)”；因此，此时返回到访问A的另一个邻接点F。第6步：访问(F的邻接点)G。第7步：访问(G的邻接点)E。 因此访问顺序是：A -&gt; C -&gt; B -&gt; D -&gt; F -&gt; G -&gt; E 2.2 有向图的深度优先搜索下面以”有向图”为例，来对深度优先搜索进行演示。 对上面的图G2进行深度优先遍历，从顶点A开始。 第1步：访问A。第2步：访问B。 在访问了A之后，接下来应该访问的是A的出边的另一个顶点，即顶点B。第3步：访问C。 在访问了B之后，接下来应该访问的是B的出边的另一个顶点，即顶点C,E,F。在本文实现的图中，顶点ABCDEFG按照顺序存储，因此先访问C。第4步：访问E。 接下来访问C的出边的另一个顶点，即顶点E。第5步：访问D。 接下来访问E的出边的另一个顶点，即顶点B,D。顶点B已经被访问过，因此访问顶点D。第6步：访问F。 接下应该回溯”访问A的出边的另一个顶点F”。第7步：访问G。 因此访问顺序是：A -&gt; B -&gt; C -&gt; E -&gt; D -&gt; F -&gt; G 3 广度优先搜索介绍广度优先搜索算法(Breadth First Search)，又称为”宽度优先搜索”或”横向优先搜索”，简称BFS。 它的思想是：从图中某顶点v出发，在访问了v之后依次访问v的各个未曾访问过的邻接点，然后分别从这些邻接点出发依次访问它们的邻接点，并使得“先被访问的顶点的邻接点先于后被访问的顶点的邻接点被访问，直至图中所有已被访问的顶点的邻接点都被访问到。如果此时图中尚有顶点未被访问，则需要另选一个未曾被访问过的顶点作为新的起始点，重复上述过程，直至图中所有顶点都被访问到为止。 换句话说，广度优先搜索遍历图的过程是以v为起点，由近至远，依次访问和v有路径相通且路径长度为1,2…的顶点。 3.1 广度搜索的模板1234567891011121314//广度搜索的模板func BFS(graph,start,end)&#123; queue:=[] var visited Set queue.append([start]) visited.add(start) while !queue.isEmpty()&#123; node=queue.pop() visited.add(node) doSomething(node) //节点进行一些操作 nodes:=generate_related_node(node) //去取出当前节点的后继节点，方法 queue.push(nodes) &#125;&#125; 4 广度优先搜索图解4.1 无向图的广度优先搜索下面以”无向图”为例，来对广度优先搜索进行演示。还是以上面的图G1为例进行说明。 第1步：访问A。第2步：依次访问C,D,F。 在访问了A之后，接下来访问A的邻接点。前面已经说过，在本文实现中，顶点ABCDEFG按照顺序存储的，C在”D和F”的前面，因此，先访问C。再访问完C之后，再依次访问D,F。第3步：依次访问B,G。 在第2步访问完C,D,F之后，再依次访问它们的邻接点。首先访问C的邻接点B，再访问F的邻接点G。第4步：访问E。 在第3步访问完B,G之后，再依次访问它们的邻接点。只有G有邻接点E，因此访问G的邻接点E。 因此访问顺序是：A -&gt; C -&gt; D -&gt; F -&gt; B -&gt; G -&gt; E 4.2 有向图的广度优先搜索下面以”有向图”为例，来对广度优先搜索进行演示。还是以上面的图G2为例进行说明。 第1步：访问A。第2步：访问B。第3步：依次访问C,E,F。 在访问了B之后，接下来访问B的出边的另一个顶点，即C,E,F。前面已经说过，在本文实现中，顶点ABCDEFG按照顺序存储的，因此会先访问C，再依次访问E,F。第4步：依次访问D,G。 在访问完C,E,F之后，再依次访问它们的出边的另一个顶点。还是按照C,E,F的顺序访问，C的已经全部访问过了，那么就只剩下E,F；先访问E的邻接点D，再访问F的邻接点G。 因此访问顺序是：A -&gt; B -&gt; C -&gt; E -&gt; F -&gt; D -&gt; G","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"数据结构","slug":"后端/数据结构","permalink":"http://xuchen.youtuc.cn/categories/后端/数据结构/"}],"tags":[{"name":"图","slug":"图","permalink":"http://xuchen.youtuc.cn/tags/图/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"数据结构","slug":"后端/数据结构","permalink":"http://xuchen.youtuc.cn/categories/后端/数据结构/"}]},{"title":"广度和深度搜索代码","slug":"LeetCode/Data/图-广度和深度搜索(代码)","date":"2020-02-15T16:23:00.000Z","updated":"2020-05-18T05:44:55.000Z","comments":true,"path":"2020/02/15/LeetCode/Data/图-广度和深度搜索(代码)/","link":"","permalink":"http://xuchen.youtuc.cn/2020/02/15/LeetCode/Data/图-广度和深度搜索(代码)/","excerpt":"","text":"无向矩阵图代码(DFS-BFS同有向矩阵)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071package graphimport \"fmt\"/**邻接矩阵无向图*/type MatrixUDG struct &#123; mVexs []string //顶点集合 mMatrix [][]int //矩阵 vexnum int // 顶点数 edgnum int // 边数&#125;/**通过已存在的图创建*/func NewExisting(vexs []string, edges [][]string) *MatrixUDG &#123; vexsLeng := len(vexs) edgesLeng := len(edges) m := &amp;MatrixUDG&#123; mVexs: vexs, vexnum: vexsLeng, edgnum: edgesLeng, &#125; // 初始化\"顶点\" mVexs := make([]string, vexsLeng) for i := 0; i &lt; len(vexs); i++ &#123; mVexs[i] = vexs[i] &#125; //初始化二维切片 row, column := vexsLeng, vexsLeng for i := 0; i &lt; row; i++ &#123; inline := make([]int, column) m.mMatrix = append(m.mMatrix, inline) &#125; for i := 0; i &lt; edgesLeng; i++ &#123; // 读取边的起始顶点和结束顶点 p1 := m.getPosition(edges[i][0]) p2 := m.getPosition(edges[i][1]) m.mMatrix[p1][p2] = 1 m.mMatrix[p2][p1] = 1 &#125; // 初始化\"边\" return m&#125;func (m *MatrixUDG) getPosition(s string) int &#123; for i := 0; i &lt; len(m.mVexs); i++ &#123; if m.mVexs[i] == s &#123; return i &#125; &#125; return -1&#125;/* * 打印矩阵队列图 */func (m *MatrixUDG) Print() &#123; fmt.Println(\"Martix Graph:\\n\") for i := 0; i &lt; len(m.mVexs); i++ &#123; for j := 0; j &lt; len(m.mVexs); j++ &#123; fmt.Printf(\"%d \", m.mMatrix[i][j]) &#125; fmt.Println() &#125;&#125; 有向矩阵图代码-完整123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177package graphimport \"fmt\"/**邻接矩阵有向图*/type MatrixDG struct &#123; mVexs []string //顶点集合 mMatrix [][]int //矩阵 vexnum int // 顶点数 edgnum int // 边数&#125;/**通过已存在的图创建*/func NewExistingDG(vexs []string, edges [][]string) *MatrixDG &#123; vexsLeng := len(vexs) edgesLeng := len(edges) m := &amp;MatrixDG&#123; mVexs: vexs, vexnum: vexsLeng, edgnum: edgesLeng, &#125; // 初始化\"顶点\" mVexs := make([]string, vexsLeng) for i := 0; i &lt; len(vexs); i++ &#123; mVexs[i] = vexs[i] &#125; //初始化二维切片 row, column := vexsLeng, vexsLeng for i := 0; i &lt; row; i++ &#123; inline := make([]int, column) m.mMatrix = append(m.mMatrix, inline) &#125; for i := 0; i &lt; edgesLeng; i++ &#123; // 读取边的起始顶点和结束顶点 p1 := m.getPosition(edges[i][0]) p2 := m.getPosition(edges[i][1]) m.mMatrix[p1][p2] = 1 &#125; // 初始化\"边\" return m&#125;func (m *MatrixDG) getPosition(s string) int &#123; for i := 0; i &lt; len(m.mVexs); i++ &#123; if m.mVexs[i] == s &#123; return i &#125; &#125; return -1&#125;/* * 打印矩阵队列图 */func (m *MatrixDG) Print() &#123; fmt.Println(\"Martix Graph:\\n\") for i := 0; i &lt; len(m.mVexs); i++ &#123; for j := 0; j &lt; len(m.mVexs); j++ &#123; fmt.Printf(\"%d \", m.mMatrix[i][j]) &#125; fmt.Println() &#125;&#125;/*深度搜索入口*/func (m *MatrixDG) DFS() &#123; visited := make([]bool, len(m.mVexs)) // 顶点访问标记 // 初始化所有顶点都没有被访问 for i := 0; i &lt; len(m.mVexs); i++ &#123; visited[i] = false &#125; fmt.Println(\"矩阵有向图深度搜索start:\") for i := 0; i &lt; len(m.mVexs); i++ &#123; if !visited[i] &#123; m.doDFS(i, visited) &#125; &#125; fmt.Println(\"\\n矩阵有向图深度搜索end\")&#125;/**深度搜索的递归方法*/func (m *MatrixDG) doDFS(i int, visited []bool) &#123; visited[i] = true fmt.Printf(\"%s-&gt;\", m.mVexs[i]) //从该顶点的第一个边开始，一直到最后一个边，对处于边另一端的顶点调用DFS函数 for w := m.firstVertex(i); w &gt;= 0; w = m.nextVertex(i, w) &#123; //如果该顶点的标记位false，证明未被访问，调用深度优先搜索函数 if !visited[w] &#123; m.doDFS(w, visited) &#125; &#125;&#125;/* * 返回顶点v的第一个邻接顶点的索引，失败则返回-1 */func (m *MatrixDG) firstVertex(v int) int &#123; if v &lt; 0 || v &gt; m.vexnum-1 &#123; return -1 &#125; //查找与数组下标为v的顶点之间有边的顶点，返回它在数组中的下标 for i := 0; i &lt; m.vexnum; i++ &#123; if m.mMatrix[v][i] == 1 &#123; return i &#125; &#125; return -1&#125;/* * 返回顶点v相对于w的下一个邻接顶点的索引，失败则返回-1 */func (m *MatrixDG) nextVertex(v int, w int) int &#123; if v &lt; 0 || v &gt; m.vexnum-1 || w &lt; 0 || w &gt; m.vexnum-1 &#123; return -1 &#125; //从前一个访问位置w的下一个位置开始，查找之间有边的顶点 for i := w + 1; i &lt; m.vexnum; i++ &#123; if m.mMatrix[v][i] == 1 &#123; return i &#125; &#125; return -1&#125;/**广度优先搜索（类似于树的层次遍历）*/func (m *MatrixDG) BFS() &#123; head, rear := 0, 0 queue := make([]int, m.vexnum) // 辅组队列 visited := make([]bool, m.vexnum) //顶点访问标记 for i := 0; i &lt; m.vexnum; i++ &#123; visited[i] = false &#125; fmt.Printf(\"矩阵有向图广度搜索start：\") for i := 0; i &lt; m.vexnum; i++ &#123; if !visited[i] &#123; visited[i] = true fmt.Printf(\"%s\", m.mVexs[i]) queue[rear] = i // 入队列 rear = rear + 1 &#125; for head != rear &#123; head = head + 1 j := queue[head] // 出队列 for k := m.firstVertex(j); k &gt;= 0; k = m.nextVertex(j, k) &#123; //k是为访问的邻接顶点 if !visited[k] &#123; visited[k] = true fmt.Printf(\"%s\", m.mVexs[k]) queue[rear] = k rear = rear + 1 &#125; &#125; &#125; &#125; fmt.Printf(\"矩阵有向图广度搜索end\")&#125; 无向链表图代码(DFS-BFS同有向链表)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103package graphimport \"fmt\"/**邻接链表无向图*/type ListUDG struct &#123; mVexs []VNode // 顶点数组 eNode *ENode vNode *VNode&#125;//邻接表中表对应的链表的顶点type ENode struct &#123; ives int // 该边所指向的顶点的位置 nextEdge *ENode // 指向下一条弧的指针&#125;// 邻接表中表的顶点type VNode struct &#123; data string // 顶点信息 firstEdge *ENode // 指向第一条依附该顶点的弧&#125;/* * 创建图(用已提供的矩阵) * * 参数说明： * vexs -- 顶点数组 * edges -- 边数组 */func NewListUDG(vexs []string, edges [][]string) *ListUDG &#123; // 初始化\"顶点数\"和\"边数\" vlen := len(vexs) elen := len(edges) mVes := make([]VNode, vlen) m := &amp;ListUDG&#123;mVexs: mVes&#125; for i := 0; i &lt; vlen; i++ &#123; mm := &amp;VNode&#123;data: vexs[i], firstEdge: nil&#125; mVes[i] = *mm &#125; //初始化边 for i := 0; i &lt; elen; i++ &#123; // 读取边的起始顶点和结束顶点 p1 := m.getPosition(edges[i][0]) p2 := m.getPosition(edges[i][1]) // 初始化node1 node1 := &amp;ENode&#123;ives: p2&#125; // 将node1链接到\"p1所在链表的末尾\" if mVes[p1].firstEdge == nil &#123; mVes[p1].firstEdge = node1 &#125; else &#123; m.linkLast(mVes[p1].firstEdge, node1) &#125; // 初始化node2 node2 := &amp;ENode&#123;ives: p1&#125; // 将node1链接到\"p1所在链表的末尾\" if mVes[p2].firstEdge == nil &#123; mVes[p2].firstEdge = node2 &#125; else &#123; m.linkLast(mVes[p2].firstEdge, node2) &#125; &#125; return m&#125;func (m *ListUDG) getPosition(s string) int &#123; for i := 0; i &lt; len(m.mVexs); i++ &#123; if m.mVexs[i].data == s &#123; return i &#125; &#125; return -1&#125;func (m *ListUDG) linkLast(list *ENode, node *ENode) &#123; p := list for p.nextEdge != nil &#123; p = p.nextEdge &#125; p.nextEdge = node&#125;func (m *ListUDG) Print() &#123; /* * 打印矩阵队列图 */ fmt.Printf(\"List Graph:\\n\") for i := 0; i &lt; len(m.mVexs); i++ &#123; fmt.Printf(\"%d(%s): \", i, m.mVexs[i].data) node := m.mVexs[i].firstEdge for node != nil &#123; fmt.Printf(\"%d(%s) \", node.ives, m.mVexs[node.ives].data) node = node.nextEdge &#125; fmt.Printf(\"\\n\") &#125;&#125; 有向链表图代码-完整123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174package graphimport \"fmt\"/**邻接链表无向图*/type ListDG struct &#123; mVexs []VNode // 顶点数组 eNode *ENode vNode *VNode&#125;//邻接表中表对应的链表的顶点type ENode struct &#123; ives int // 该边所指向的顶点的位置 nextEdge *ENode // 指向下一条弧的指针&#125;// 邻接表中表的顶点type VNode struct &#123; data string // 顶点信息 firstEdge *ENode // 指向第一条依附该顶点的弧&#125;/* * 创建图(用已提供的矩阵) * * 参数说明： * vexs -- 顶点数组 * edges -- 边数组 */func NewListDG(vexs []string, edges [][]string) *ListDG &#123; // 初始化\"顶点数\"和\"边数\" vlen := len(vexs) elen := len(edges) mVes := make([]VNode, vlen) m := &amp;ListDG&#123;mVexs: mVes&#125; for i := 0; i &lt; vlen; i++ &#123; mm := &amp;VNode&#123;data: vexs[i], firstEdge: nil&#125; mVes[i] = *mm &#125; //初始化边 for i := 0; i &lt; elen; i++ &#123; // 读取边的起始顶点和结束顶点 //c1 := edges[i][0] //c2 := edges[i][1] // 读取边的起始顶点和结束顶点 p1 := m.getPosition(edges[i][0]) p2 := m.getPosition(edges[i][1]) // 初始化node1 node1 := &amp;ENode&#123;ives: p2&#125; // 将node1链接到\"p1所在链表的末尾\" if mVes[p1].firstEdge == nil &#123; mVes[p1].firstEdge = node1 &#125; else &#123; m.linkLast(mVes[p1].firstEdge, node1) &#125; &#125; return m&#125;func (m *ListDG) getPosition(s string) int &#123; for i := 0; i &lt; len(m.mVexs); i++ &#123; if m.mVexs[i].data == s &#123; return i &#125; &#125; return -1&#125;func (m *ListDG) linkLast(list *ENode, node *ENode) &#123; p := list for p.nextEdge != nil &#123; p = p.nextEdge p.nextEdge = node &#125;&#125;func (m *ListDG) Print() &#123; /* * 打印矩阵队列图 */ fmt.Printf(\"List Graph:\\n\") for i := 0; i &lt; len(m.mVexs); i++ &#123; fmt.Printf(\"%d(%s): \", i, m.mVexs[i].data) node := m.mVexs[i].firstEdge for node != nil &#123; fmt.Printf(\"%d(%s) \", node.ives, m.mVexs[node.ives].data) node = node.nextEdge &#125; fmt.Printf(\"\\n\") &#125;&#125;/* * 深度优先搜索遍历图的递归实现 */func (m *ListDG) doDFS(i int, visited []bool) &#123; var node *ENode visited[i] = true fmt.Printf(\"%s \", m.mVexs[i].data) node = m.mVexs[i].firstEdge for node != nil &#123; if (!visited[node.ives]) &#123; m.doDFS(node.ives, visited) &#125; node = node.nextEdge &#125;&#125;/* * 深度优先搜索遍历图 */func (m *ListDG) DFS() &#123; visited := make([]bool, len(m.mVexs)) // 初始化所有顶点都没有被访问 for i := 0; i &lt; len(m.mVexs); i++ &#123; visited[i] = false fmt.Printf(\"DFS: \") for i := 0; i &lt; len(m.mVexs); i++ &#123; if (!visited[i]) &#123; m.doDFS(i, visited) &#125; &#125; fmt.Printf(\"\\n\") &#125;&#125;/* * 广度优先搜索（类似于树的层次遍历） */func (m *ListDG) BFS() &#123; head, rear := 0, 0 queue := make([]int, len(m.mVexs)) // 辅组队列 visited := make([]bool, len(m.mVexs)) // 顶点访问标记 for i := 0; i &lt; len(m.mVexs); i++ &#123; visited[i] = false &#125; fmt.Printf(\"BFS: \") for i := 0; i &lt; len(m.mVexs); i++ &#123; if !visited[i] &#123; visited[i] = true fmt.Printf(\"%s \", m.mVexs[i].data) rear++ queue[rear] = i // 入队列 &#125; for head != rear &#123; head++ j := queue[head] // 出队列 node := m.mVexs[j].firstEdge for node != nil &#123; k := node.ives if !visited[k] &#123; visited[k] = true; fmt.Printf(\"%s \", m.mVexs[k].data) rear++ queue[rear] = k &#125; node = node.nextEdge &#125; &#125; &#125; fmt.Printf(\"\\n\")&#125;","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"数据结构","slug":"后端/数据结构","permalink":"http://xuchen.youtuc.cn/categories/后端/数据结构/"}],"tags":[{"name":"图","slug":"图","permalink":"http://xuchen.youtuc.cn/tags/图/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"数据结构","slug":"后端/数据结构","permalink":"http://xuchen.youtuc.cn/categories/后端/数据结构/"}]},{"title":"图-基本概念","slug":"LeetCode/Data/图-基本概念","date":"2020-02-08T16:23:00.000Z","updated":"2021-05-04T08:26:08.000Z","comments":true,"path":"2020/02/08/LeetCode/Data/图-基本概念/","link":"","permalink":"http://xuchen.youtuc.cn/2020/02/08/LeetCode/Data/图-基本概念/","excerpt":"","text":"图的定义定义：图(graph)是由一些点(vertex)和这些点之间的连线(edge)所组成的；其中，点通常被成为”顶点(vertex)”，而点与点之间的连线则被成为”边或弧”(edege)。通常记为，G=(V,E)。 图的种类根据边是否有方向，将图可以划分为：无向图和有向图。 无向图![1.jpg](http://ww2.sinaimg.cn/large/007lnJOlly1gbp2xll06nj308f08fwf1.jpg) 上面的图G0是无向图，无向图的所有的边都是不区分方向的。G0=(V1,{E1})。其中，(01) V1={A,B,C,D,E,F}。 V1表示由”A,B,C,D,E,F”几个顶点组成的集合。(02) E1={(A,B),(A,C),(B,C),(B,E),(B,F),(C,F), (C,D),(E,F),(C,E)}。 E1是由边(A,B),边(A,C)…等等组成的集合。其中，(A,C)表示由顶点A和顶点C连接成的边。 有向图![2.jpg](http://ww2.sinaimg.cn/large/007lnJOlly1gbp34sljjij308f08yq3k.jpg) 上面的图G2是有向图。和无向图不同，有向图的所有的边都是有方向的！ G2=(V2,{A2})。其中，(01) V2={A,C,B,F,D,E,G}。 V2表示由”A,B,C,D,E,F,G”几个顶点组成的集合。(02) A2={&lt;A,B&gt;,&lt;B,C&gt;,&lt;B,F&gt;,&lt;B,E&gt;,&lt;C,E&gt;,&lt;E,D&gt;,&lt;D,C&gt;,&lt;E,B&gt;,&lt;F,G&gt;}。 E1是由矢量&lt;A,B&gt;,矢量&lt;B,C&gt;...等等组成的集合。其中，矢量&lt;A,C)表示由”顶点A”指向”顶点C”的有向边。 邻接点和度邻接点一条边上的两个顶点叫做邻接点。例如，上面无向图G0中的顶点A和顶点C就是邻接点。在有向图中，除了邻接点之外；还有”入边”和”出边”的概念。顶点的入边，是指以该顶点为终点的边。而顶点的出边，则是指以该顶点为起点的边。例如，上面有向图G2中的B和E是邻接点；&lt;B,E&gt;是B的出边，还是E的入边。 度在无向图中，某个顶点的度是邻接到该顶点的边(或弧)的数目。例如，上面无向图G0中顶点A的度是2。在有向图中，度还有”入度”和”出度”之分。某个顶点的入度，是指以该顶点为终点的边的数目。而顶点的出度，则是指以该顶点为起点的边的数目。顶点的度=入度+出度。例如，上面有向图G2中，顶点B的入度是2，出度是3；顶点B的度=2+3=5。 路径和回路 路径：如果顶点(Vm)到顶点(Vn)之间存在一个顶点序列。则表示Vm到Vn是一条路径。 路径长度：路径中”边的数量”。 简单路径：若一条路径上顶点不重复出现，则是简单路径。 回路：若路径的第一个顶点和最后一个顶点相同，则是回路。 简单回路：第一个顶点和最后一个顶点相同，其它各顶点都不重复的回路则是简单回路。 连通图和连通分量 连通图：对无向图而言，任意两个顶点之间都存在一条无向路径，则称该无向图为连通图。 对有向图而言，若图中任意两个顶点之间都存在一条有向路径，则称该有向图为强连通图。 连通分量：非连通图中的各个连通子图称为该图的连通分量。 权在学习”哈夫曼树”的时候，了解过”权”的概念。图中权的概念与此类似。 ![1.jpg](http://ww2.sinaimg.cn/large/007lnJOlly1gbp4fje3fhj308f08f750.jpg) 图的存储结构图的存储结构，常用的是”邻接矩阵”和”邻接表”。 邻接矩阵邻接矩阵是指用矩阵来表示图。它是采用矩阵来描述图中顶点之间的关系(及弧或边的权)。假设图中顶点数为n，则邻接矩阵定义为：","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"数据结构","slug":"后端/数据结构","permalink":"http://xuchen.youtuc.cn/categories/后端/数据结构/"}],"tags":[{"name":"图","slug":"图","permalink":"http://xuchen.youtuc.cn/tags/图/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"数据结构","slug":"后端/数据结构","permalink":"http://xuchen.youtuc.cn/categories/后端/数据结构/"}]},{"title":"二叉堆","slug":"LeetCode/Data/堆-二叉堆","date":"2020-01-14T21:55:00.000Z","updated":"2021-05-04T08:26:08.000Z","comments":true,"path":"2020/01/14/LeetCode/Data/堆-二叉堆/","link":"","permalink":"http://xuchen.youtuc.cn/2020/01/14/LeetCode/Data/堆-二叉堆/","excerpt":"","text":"堆和二叉堆的介绍堆的定义堆(heap)，这里所说的堆是数据结构中的堆，而不是内存模型中的堆。堆通常是一个可以被看做一棵树，它满足下列性质： 堆中任意节点的值总是不大于(不小于)其子节点的值 堆总是一棵完全树。将任意节点不大于其子节点的堆叫做最小堆或小根堆，而将任意节点不小于其子节点的堆叫做最大堆或大根堆。常见的堆有二叉堆、左倾堆、斜堆、二项堆、斐波那契堆等等。 二叉堆的定义二叉堆是完全二元树或者是近似完全二元树，它分为两种：最大堆和最小堆。 最大堆：父结点的键值总是大于或等于任何一个子节点的键值；最小堆：父结点的键值总是小于或等于任何一个子节点的键值。 二叉堆一般都通过”数组”来实现，下面是数组实现的最大堆和最小堆的示意图： 二叉堆一般都通过”数组“来实现。数组实现的二叉堆，父节点和子节点的位置存在一定的关系。有时候，我们将”二叉堆的第一个元素”放在数组索引0的位置，有时候放在1的位置。当然，它们的本质一样(都是二叉堆)，只是实现上稍微有一丁点区别。 假设”第一个元素”在数组中的索引为 0 的话，则父节点和子节点的位置关系如下： 索引为i的左孩子的索引是 (2*i+1); 索引为i的右孩子的索引是 (2*i+2); 索引为i的父结点的索引是 floor((i-1)/2);假设”第一个元素”在数组中的索引为 1 的话，则父节点和子节点的位置关系如下： 索引为i的左孩子的索引是 (2*i); 索引为i的左孩子的索引是 (2*i+1); 索引为i的父结点的索引是 floor(i/2); 二叉堆的图文解析在前面，我们已经了解到：”最大堆”和”最小堆”是对称关系。这也意味着，了解其中之一即可。本节的图文解析是以”最大堆”来进行介绍的。 二叉堆的核心是”添加节点”和”删除节点”，理解这两个算法，二叉堆也就基本掌握了。下面对它们进行介绍。 添加假设在最大堆[90,80,70,60,40,30,20,10,50]种添加85，需要执行的步骤如下： 删除假设从最大堆[90,85,70,60,80,30,20,10,50,40]中删除90，需要执行的步骤如下：从[90,85,70,60,80,30,20,10,50,40]删除90之后，最大堆变成了[85,80,70,60,40,30,20,10,50]。如上图所示，当从最大堆中删除数据时：先删除该数据，然后用最大堆中最后一个的元素插入这个空位；接着，把这个“空位”尽量往上挪，直到剩余的数据变成一个最大堆。 注意：考虑从最大堆[90,85,70,60,80,30,20,10,50,40]中删除60，执行的步骤不能单纯的用它的子节点来替换；而必须考虑到”替换后的树仍然要是最大堆”！转换规则如索引计算规则一样即可，然后数组往前移动 最大堆完整代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100package heaptype BinaryHeap struct &#123; Array []int //切片存储&#125;/**返回数据在数组中的索引*/func (this *BinaryHeap) GetIndex(data int) int &#123; i := 0 for i = 0; i &lt; len(this.Array); i++ &#123; if data == this.Array[i] &#123; return i &#125; &#125; return -1&#125;/* * 最大堆的向下调整算法 * * 注：数组实现的堆中，第N个节点的左孩子的索引值是(2N+1)，右孩子的索引是(2N+2)。 * * 参数说明： * start -- 被下调节点的起始位置(一般为0，表示从第1个开始) * end -- 截至范围(一般为数组中最后一个元素的索引) */func (this *BinaryHeap) filterdown(start, end int) &#123; current := start // 当前(current)节点的位置 left := 2*current + 1 // 左(left)孩子的位置 tmpValue := this.Array[current] // 当前(current)节点的大小 for left &lt; end &#123; // \"left\"是左孩子，\"left+1\"是右孩子 if left &lt; end &amp;&amp; this.Array[left] &lt; this.Array[left+1] &#123; left++ // 左右两孩子中选择较大者，即mHeap[left+1] &#125; if tmpValue &gt;= this.Array[left] &#123; //调整结束 break &#125; else &#123; this.Array[current] = this.Array[left] current = left left = 2*left + 1 &#125; &#125; this.Array[current] = tmpValue&#125;/** 删除最大堆的值*/func (this *BinaryHeap) Remove(data int) int &#123; // 如果\"堆\"已空，则返回-1 if len(this.Array) == 0 &#123; return -1 &#125; // 获取data在数组中的索引 index := this.GetIndex(data) if index == -1 &#123; return -1 &#125; size := len(this.Array) this.Array[index] = this.Array[size-1] // 用最后元素填补 this.Array = this.Array[:size-1] // 删除最后的元素 if len(this.Array) &gt; 1 &#123; // 从index号位置开始自上向下调整为最小堆 this.filterdown(index, len(this.Array)-1) &#125; return 0&#125;/* * 最大堆的向上调整算法(从start开始向上直到0，调整堆) * * 注：数组实现的堆中，第N个节点的左孩子的索引值是(2N+1)，右孩子的索引是(2N+2)。 * * 参数说明： * start -- 被上调节点的起始位置(一般为数组中最后一个元素的索引) */func (this *BinaryHeap) filterup(start int) &#123; current := start // 当前(current)节点的位置 parent := (current - 1) / 2 // 父(parent)结点的位置 tmpValue := this.Array[current] // 当前(current)节点的大小 for current &gt; 0 &#123; if this.Array[parent] &gt;= tmpValue &#123; break &#125; else &#123; this.Array[current] = this.Array[parent] current = parent parent = (parent - 1) / 2 &#125; &#125; this.Array[current] = tmpValue&#125;func (this *BinaryHeap) Add(data ...int) &#123; size := len(this.Array) this.Array = append(this.Array, data...) this.filterup(size)&#125;","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"数据结构","slug":"后端/数据结构","permalink":"http://xuchen.youtuc.cn/categories/后端/数据结构/"}],"tags":[{"name":"堆","slug":"堆","permalink":"http://xuchen.youtuc.cn/tags/堆/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"数据结构","slug":"后端/数据结构","permalink":"http://xuchen.youtuc.cn/categories/后端/数据结构/"}]},{"title":"二叉树","slug":"LeetCode/Data/树-二叉树","date":"2019-12-16T17:38:52.000Z","updated":"2021-05-04T08:26:08.000Z","comments":true,"path":"2019/12/16/LeetCode/Data/树-二叉树/","link":"","permalink":"http://xuchen.youtuc.cn/2019/12/16/LeetCode/Data/树-二叉树/","excerpt":"","text":"树的基本概念 树（tree）是一种抽象数据类型（ADT），用来模拟具有树状结构性质的数据集合。它是由n（n&gt;0）个有限节点通过连接它们的边组成一个具有层次关系的集合。把它叫做“树”是因为它看起来像一棵倒挂的树，也就是说它是根朝上，而叶朝下的。它具有以下的特点： 每个节点都只有有限个子节点或无子节点； 没有父节点的节点称为根节点； 每一个非根节点有且只有一个父节点； 除了根节点外，每个子节点可以分为多个不相交的子树； 树里面没有环路(cycle) 树的三个比较相似的概念：高度（Height）、深度（Depth）、层（Level） 节点的高度=节点到叶子结点的最长路径（边数） 节点的深度=根节点到这个节点所经历的边的个数 节点的层数=节点的深度+1 树的高度=根节点的高度 节点：上图的圆圈，比如A,B,C等都是表示节点。节点一般代表一些实体，在java面向对象编程中，节点一般代表对象。 边：连接节点的线称为边，边表示节点的关联关系。一般从一个节点到另一个节点的唯一方法就是沿着一条顺着有边的道路前进。在Java当中通常表示引用。 树有很多种，向上面的一个节点有多余两个的子节点的树，称为多路树，后面会讲解2-3-4树和外部存储都是多路树的例子。而每个节点最多只能有两个子节点的一种形式称为二叉树，本篇博客重点讲解二叉查找树。 路径：顺着节点的边从一个节点走到另一个节点，所经过的节点的顺序排列就称为“路径”。 根：树顶端的节点称为根。一棵树只有一个根，如果要把一个节点和边的集合称为树，那么从根到其他任何一个节点都必须有且只有一条路径。A是根节点。 父节点：若一个节点含有子节点，则这个节点称为其子节点的父节点；B是D的父节点。 子节点：一个节点含有的子树的根节点称为该节点的子节点；D是B的子节点。 兄弟节点：具有相同父节点的节点互称为兄弟节点；比如上图的D和E就互称为兄弟节点。 叶节点：没有子节点的节点称为叶节点，也叫叶子节点，比如上图的H、E、F、G都是叶子节点。 子树：每个节点都可以作为子树的根，它和它所有的子节点、子节点的子节点等都包含在子树中。 节点的层次：从根开始定义，根为第一层，根的子节点为第二层，以此类推。 深度：对于任意节点n,n的深度为从根到n的唯一路径长，根的深度为0； 高度：对于任意节点n,n的高度为从n到一片树叶的最长路径长，所有树叶的高度为0； 遍历树（深度优先遍历）遍历树是根据一种特定的顺序访问树的每一个节点。比较常用的有前序遍历，中序遍历和后序遍历。而二叉搜索树最常用的是中序遍历。 中序遍历:左子树——》根节点——》右子树 前序遍历:根节点——》左子树——》右子树 后序遍历:左子树——》右子树——》根节点 层序遍历（广度优先遍历） 删除节点删除节点是二叉搜索树中最复杂的操作，删除的节点有三种情况，前两种比较简单，但是第三种却很复杂。 该节点是叶节点（没有子节点） 该节点有一个子节点 该节点有两个子节点 该节点是叶节点（没有子节点）要删除叶节点，只需要改变该节点的父节点引用该节点的值，即将其引用改为null即可。删除节点，我们要先找到该节点，并记录该节点的父节点。在检查该节点是否有子节点。如果没有子节点，接着检查其是否是根节点，如果是根节点，只需要将其设置为null即可。如果不是根节点，是叶节点，那么断开父节点和其的关系即可。 删除有一个子节点的节点删除有一个子节点的节点，我们只需要将其父节点原本指向该节点的引用，改为指向该节点的子节点即可。 删除有两个子节点的节点 当删除的节点存在两个子节点，那么删除之后，两个子节点的位置我们就没办法处理了。既然处理不了，我们就想到一种办法，用另一个节点来代替被删除的节点，那么用哪一个节点来代替呢？我们知道二叉搜索树中的节点是按照关键字来进行排列的，某个节点的关键字次高节点是它的中序遍历后继节点。用后继节点来代替删除的节点，显然该二叉搜索树还是有序的。 那么如何找到删除节点的中序后继节点呢？其实我们稍微分析，这实际上就是要找比删除节点关键值大的节点集合中最小的一个节点，只有这样代替删除节点后才能满足二叉搜索树的特性。 删除有两个子节点的节点-后继节点确认方法如果删除的X的左子树L和右子树均R存在，则存在两种删除的思路，一种是在左子树L中寻找最大值节点LMax（LMax比为叶子节点），删除LMax并用LMax代替x即可；另一种思路则是在右子树R中寻找最小值节点RMin（RMin必为叶子节点），删除RMin并用RMin代替x即可。 真的需要删除吗？在Node节点增加isDel状态属性，再可以不破坏树的情况下完成删除，显示查找时候判断一下即可 需要确定后继节点没有子节点，如果后继节点存在子节点，分情况讨论 后继节点是删除节点的右子节点 后继节点是删除节点的右子节点的左子节点 完整代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250package treeimport ( \"fmt\")type Node struct &#123; Value int Left *Node Right *Node&#125;type BinaryTree struct &#123; Root *Node&#125;/**查找节点查找某个节点，我们必须从根节点开始遍历。①、查找值比当前节点值大，则搜索右子树；②、查找值等于当前节点值，停止搜索（终止条件）；③、查找值小于当前节点值，则搜索左子树；树的效率：查找节点的时间取决于这个节点所在的层数，每一层最多有2n-1个节点，总共N层共有2n-1个节点，那么时间复杂度为O(logN),底数为2。*/func (this *BinaryTree) Find(data int) *Node &#123; current := this.Root for current != nil &#123; if current.Value &gt; data &#123; current = current.Left &#125; else if current.Value &lt; data &#123; current = current.Right &#125; else &#123; return current &#125; &#125; return nil&#125;/**要插入节点，必须先找到插入的位置。与查找操作相似，由于二叉搜索树的特殊性，待插入的节点也需要从根节点开始进行比较，小于根节点则与根节点左子树比较，反之则与右子树比较，直到左子树为空或右子树为空，则插入到相应为空的位置，在比较的过程中要注意保存父节点的信息 及 待插入的位置是父节点的左子树还是右子树，才能插入到正确的位置。*/func (this *BinaryTree) Insert(data int) bool &#123; addNode := &amp;Node&#123;Value: data, Left: nil, Right: nil&#125; if this.Root == nil &#123; this.Root = addNode return true &#125; current := this.Root var parentNode *Node for current != nil &#123; parentNode = current //===判断 if current.Value &gt; data &#123; //当前值比插入值大，搜索左子节点 current = current.Left if current == nil &#123; parentNode.Left = addNode return true &#125; &#125; else &#123; current = current.Right if current == nil &#123; parentNode.Right = addNode return true &#125; &#125; //===判断 &#125; return false&#125;/**中序遍历*/func (this *BinaryTree) InfixOrder(current *Node) &#123; if current != nil &#123; this.InfixOrder(current.Left) fmt.Printf(\"%d,\", current.Value) this.InfixOrder(current.Right) &#125;&#125;/**前序遍历*/func (this *BinaryTree) PreOrder(current *Node) &#123; if current != nil &#123; fmt.Printf(\"%d,\", current.Value) this.PreOrder(current.Left) this.PreOrder(current.Right) &#125;&#125;/**后序遍历*/func (this *BinaryTree) PostOrder(current *Node) &#123; if current != nil &#123; this.PostOrder(current.Left) this.PostOrder(current.Right) fmt.Printf(\"%d,\", current.Value) &#125;&#125;/**层次遍历(广度遍历)*/func (this *BinaryTree) LevelOrder() [][]int &#123; valueList := make([][]int, 0) if this.Root == nil &#123; return valueList &#125; queue := make([]*Node, 0) queue = append(queue, this.Root) for len(queue) &gt; 0 &#123; lvLenght := len(queue) //当前层队列有几个数据 lvArr := make([]int, 0) lvQue := make([]*Node, 0) for i := 0; i &lt; lvLenght; i++ &#123; //弹出数据 node := queue[0] queue = queue[1:] lvArr = append(lvArr, node.Value) if node.Left != nil &#123; lvQue = append(lvQue, node.Left) &#125; if node.Right != nil &#123; lvQue = append(lvQue, node.Right) &#125; &#125; queue = append(queue, lvQue...) valueList = append(valueList, lvArr) &#125; return valueList&#125;/**查找最大值直接从树的右边开始找到最后*/func (this *BinaryTree) FindMax() *Node &#123; current := this.Root max := current for current != nil &#123; if current.Right != nil &#123; max = current.Right &#125; current = current.Right &#125; return max&#125;/**查找最小值直接从树的左边开始找到最后*/func (this *BinaryTree) FindMin() *Node &#123; current := this.Root min := current for current != nil &#123; if current.Left != nil &#123; min = current.Left &#125; current = current.Left &#125; return min&#125;func (this *BinaryTree) Delete(key int) bool &#123; current := this.Root parent := this.Root isLeftChild := false //查找删除值，找不到直接返回false for current.Value != key &#123; parent = current if current.Value &gt; key &#123; isLeftChild = true current = current.Left &#125; else &#123; isLeftChild = false current = current.Right &#125; if current == nil &#123; return false &#125; &#125; if current.Left == nil &amp;&amp; current.Right == nil &#123; //如果当前节点没有子节点 if current == this.Root &#123; this.Root = nil &#125; else if isLeftChild &#123; parent.Left = nil &#125; else &#123; parent.Right = nil &#125; return true &#125; else if current.Left != nil &amp;&amp; current.Right == nil &#123; //有子左节点 if current == this.Root &#123; this.Root = current.Left &#125; else if isLeftChild &#123; parent.Left = current.Left &#125; else &#123; parent.Right = current.Left &#125; return true &#125; else if current.Left == nil &amp;&amp; current.Right != nil &#123; //有子右节点 if current == this.Root &#123; this.Root = current.Right &#125; else if isLeftChild &#123; parent.Left = current.Right &#125; else &#123; parent.Right = current.Right &#125; return true &#125; else &#123; successor := this.getSuccessor(current) if current == this.Root &#123; this.Root = successor &#125; else if isLeftChild &#123; parent.Left = successor &#125; else &#123; parent.Right = successor &#125; &#125; return false&#125;/**后继节点查找*/func (this *BinaryTree) getSuccessor(delNode *Node) *Node &#123; successorParent := delNode successor := delNode current := delNode.Left for current != nil &#123; successorParent = successor successor = current current = current.Right &#125; if successor != delNode.Left &#123; successorParent.Right = nil //删除引用 successor.Left = successorParent successor.Right = delNode.Right &#125; return successor&#125;","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"数据结构","slug":"后端/数据结构","permalink":"http://xuchen.youtuc.cn/categories/后端/数据结构/"}],"tags":[{"name":"树","slug":"树","permalink":"http://xuchen.youtuc.cn/tags/树/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"数据结构","slug":"后端/数据结构","permalink":"http://xuchen.youtuc.cn/categories/后端/数据结构/"}]},{"title":"算法笔记","slug":"LeetCode/Note/算法笔记","date":"2019-11-10T21:08:01.000Z","updated":"2021-05-04T08:26:08.000Z","comments":true,"path":"2019/11/10/LeetCode/Note/算法笔记/","link":"","permalink":"http://xuchen.youtuc.cn/2019/11/10/LeetCode/Note/算法笔记/","excerpt":"","text":"算法推导大O阶方法 用常数1取代运行时间中的所有加法常数 在修改后的运行次数函数中，只保留最高阶项 如果最高阶存在且不是1，则去除与这个项相乘的常数 常数阶首先顺序结构的时间复杂度。下面这个算法案例： 123int sum=0,n=100 /*执行第一次*/sum=(1+n)*n/2 /*执行第一次*/printf(&quot;%d&quot;,sum) /*执行第一次*/ 这个算法的运行函数是f(n)=3,所以根据推倒大O，如果结果是常数3，所以常熟3改为1，记为O(1),事实上无论sum=(1+n)*n/2执行多少次时间都是恒定的。 线性阶线性阶的循环结构会复制很多。要确定某个算法的阶次，我们常常需要确定某个特定语句或某个函数运行的次数。下面的代码示例复杂度为O(n),因为循环体中的代码要执行n次。 1234int i;for(i=0;i&lt;n;i++)&#123; /*执行复杂度未O(1)的程序*/&#125; 对数阶下面这段代码，由于每次count乘以2以后，就距离n更近，由$2^x=n 得到x=log2n。所以这个循环的负责度为O(logn). 12345int count=1;while(count&lt;n)&#123; count=count*2 /*执行复杂度未O(1)的程序*/&#125; 平方阶下面这段代码，是一个循环嵌套的，时间复杂度为O(n^2) 123456int i,jfor(i=0;i&lt;n;i++)&#123; for(j=0;j&lt;n;j++)&#123; /*执行复杂度未O(1)的程序*/ &#125;&#125; 如果外循环改成了m,时间复杂度就是，时间复杂度为O(n*m) 123456int i,jfor(i=0;i&lt;m;i++)&#123; for(j=0;j&lt;n;j++)&#123; /*执行复杂度未O(1)的程序*/ &#125;&#125; 所以总结规律，循环的时间复杂度等于循环体复杂度乘以改循环的运行的次数 123456int i,j;for(i=0;i&lt;m;i++)&#123; for(j=i;j&lt;n;j++)&#123; //注意j=i /*执行复杂度未O(1)的程序*/ &#125;&#125; 由于i逐步递减，所以总执行次数为：n+(n-1)+(n-2)+…+1=n(n+1)/2=n^2/2+n/2所以我们推倒方法，第一条，没有加常数不予考虑；第二条，只保留最高阶，因此保留n^2/2;第三条，去除这个项相乘的常数，也就是去除1/2,最终这段代码的复杂度未O(n^2) 常用数据结构 数据结构分类 数据结构比较 O符号 O(1)：最低的复杂度，无论数据量大小，耗时都不变，都可以在一次计算后获得。哈希算法就是典型的O(1) O(n)：线性，n表示数据的量，当量增大，耗时也增大，常见有遍历算法 O(n²)：平方，表示耗时是n的平方倍，当看到循环嵌循环的时候，基本上这个算法就是平方级的，如：冒泡排序等 O(log n)：对数，通常ax=n,那么数x叫做以a为底n的对数,也就是x=logan，这里是a通常是2，如：数量增大8倍，耗时只增加了3倍，二分查找就是对数级的算法，每次剔除一半 O(n log n)：线性对数，就是n乘以log n,按照上面说的数据增大8倍，耗时就是8*3=24倍，归并排序就是线性对数级的算法 数据结构选择 常用数据结构和算法的时间复杂度","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"数据结构","slug":"后端/数据结构","permalink":"http://xuchen.youtuc.cn/categories/后端/数据结构/"}],"tags":[{"name":"数据结构算法","slug":"数据结构算法","permalink":"http://xuchen.youtuc.cn/tags/数据结构算法/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"数据结构","slug":"后端/数据结构","permalink":"http://xuchen.youtuc.cn/categories/后端/数据结构/"}]},{"title":"Go-深入解析slice底层实现","slug":"Go/深入解析slice底层实现","date":"2019-10-14T14:43:44.000Z","updated":"2021-05-04T08:26:08.000Z","comments":true,"path":"2019/10/14/Go/深入解析slice底层实现/","link":"","permalink":"http://xuchen.youtuc.cn/2019/10/14/Go/深入解析slice底层实现/","excerpt":"","text":"原文地址：https://halfrost.com/go_slice/ 切片是 Go 中的一种基本的数据结构，使用这种结构可以用来管理数据集合。切片的设计想法是由动态数组概念而来，为了开发者可以更加方便的使一个数据结构可以自动增加和减少。但是切片本身并不是动态数据或者数组指针。切片常见的操作有 reslice、append、copy。与此同时，切片还具有可索引，可迭代的优秀特性。 切片和数组在 Go 中，与 C 数组变量隐式作为指针使用不同，Go 数组是值类型，赋值和函数传参操作都会复制整个数组数据。 123456789101112131415func main() &#123; arrayA := [2]int&#123;100, 200&#125; var arrayB [2]int arrayB = arrayA fmt.Printf(\"arrayA : %p , %v\\n\", &amp;arrayA, arrayA) fmt.Printf(\"arrayB : %p , %v\\n\", &amp;arrayB, arrayB) testArray(arrayA)&#125;func testArray(x [2]int) &#123; fmt.Printf(\"func Array : %p , %v\\n\", &amp;x, x)&#125; 打印结果： 123arrayA : 0xc4200bebf0 , [100 200]arrayB : 0xc4200bec00 , [100 200]func Array : 0xc4200bec30 , [100 200] 可以看到，三个内存地址都不同，这也就验证了 Go 中数组赋值和函数传参都是值复制的。那这会导致什么问题呢？ 假想每次传参都用数组，那么每次数组都要被复制一遍。如果数组大小有 100万，在64位机器上就需要花费大约 800W 字节，即 8MB 内存。这样会消耗掉大量的内存。于是乎有人想到，函数传参用数组的指针。 123456789101112func main() &#123; arrayA := []int&#123;100, 200&#125; testArrayPoint(&amp;arrayA) // 1.传数组指针 arrayB := arrayA[:] testArrayPoint(&amp;arrayB) // 2.传切片 fmt.Printf(\"arrayA : %p , %v\\n\", &amp;arrayA, arrayA)&#125;func testArrayPoint(x *[]int) &#123; fmt.Printf(\"func Array : %p , %v\\n\", x, *x) (*x)[1] += 100&#125; 打印结果: 123func Array : 0xc4200b0140 , [100 200]func Array : 0xc4200b0180 , [100 300]arrayA : 0xc4200b0140 , [100 400] 这也就证明了数组指针确实到达了我们想要的效果。现在就算是传入10亿的数组，也只需要再栈上分配一个8个字节的内存给指针就可以了。这样更加高效的利用内存，性能也比之前的好。 不过传指针会有一个弊端，从打印结果可以看到，第一行和第三行指针地址都是同一个，万一原数组的指针指向更改了，那么函数里面的指针指向都会跟着更改。 切片的优势也就表现出来了。用切片传数组参数，既可以达到节约内存的目的，也可以达到合理处理好共享内存的问题。打印结果第二行就是切片，切片的指针和原来数组的指针是不同的。 由此我们可以得出结论： 把第一个大数组传递给函数会消耗很多内存，采用切片的方式传参可以避免上述问题。切片是引用传递，所以它们不需要使用额外的内存并且比使用数组更有效率。 但是，依旧有反例。 12345678910111213141516171819202122232425262728293031package mainimport \"testing\"func array() [1024]int &#123; var x [1024]int for i := 0; i &lt; len(x); i++ &#123; x[i] = i &#125; return x&#125;func slice() []int &#123; x := make([]int, 1024) for i := 0; i &lt; len(x); i++ &#123; x[i] = i &#125; return x&#125;func BenchmarkArray(b *testing.B) &#123; for i := 0; i &lt; b.N; i++ &#123; array() &#125;&#125;func BenchmarkSlice(b *testing.B) &#123; for i := 0; i &lt; b.N; i++ &#123; slice() &#125;&#125; 我们做一次性能测试，并且禁用内联和优化，来观察切片的堆上内存分配的情况。 1go test -bench . -benchmem -gcflags \"-N -l\" 输出结果比较“令人意外”： 12BenchmarkArray-4 500000 3637 ns/op 0 B/op 0 alloc s/opBenchmarkSlice-4 300000 4055 ns/op 8192 B/op 1 alloc s/op 解释一下上述结果，在测试 Array 的时候，用的是4核，循环次数是500000，平均每次执行时间是3637 ns，每次执行堆上分配内存总量是0，分配次数也是0 。 而切片的结果就“差”一点，同样也是用的是4核，循环次数是300000，平均每次执行时间是4055 ns，但是每次执行一次，堆上分配内存总量是8192，分配次数也是1 。 这样对比看来，并非所有时候都适合用切片代替数组，因为切片底层数组可能会在堆上分配内存，而且小数组在栈上拷贝的消耗也未必比 make 消耗大。 – 切片上的数据结构切片本身并不是动态数组或者数组指针。它内部实现的数据结构通过指针引用底层数组，设定相关属性将数据读写操作限定在指定的区域内。切片本身是一个只读对象，其工作机制类似数组指针的一种封装。 切片（slice）是对数组一个连续片段的引用，所以切片是一个引用类型（因此更类似于 C/C++ 中的数组类型，或者 Python 中的 list 类型）。这个片段可以是整个数组，或者是由起始和终止索引标识的一些项的子集。需要注意的是，终止索引标识的项不包括在切片内。切片提供了一个与指向数组的动态窗口。 给定项的切片索引可能比相关数组的相同元素的索引小。和数组不同的是，切片的长度可以在运行时修改，最小为 0 最大为相关数组的长度：切片是一个长度可变的数组。 12345type slice struct &#123; array unsafe.Pointer len int cap int&#125; 切片的结构体由3部分构成，Pointer 是指向一个数组的指针，len 代表当前切片的长度，cap 是当前切片的容量。cap 总是大于等于 len 的。 如果想从 slice 中得到一块内存地址，可以这样做： 12s := make([]byte, 200)ptr := unsafe.Pointer(&amp;s[0]) 如果反过来呢？从 Go 的内存地址中构造一个 slice。 1234567var ptr unsafe.Pointervar s1 = struct &#123; addr uintptr len int cap int&#125;&#123;ptr, length, length&#125;s := *(*[]byte)(unsafe.Pointer(&amp;s1)) 构造一个虚拟的结构体，把 slice 的数据结构拼出来。 当然还有更加直接的方法，在 Go 的反射中就存在一个与之对应的数据结构 SliceHeader，我们可以用它来构造一个 slice 12345var o []bytesliceHeader := (*reflect.SliceHeader)((unsafe.Pointer(&amp;o)))sliceHeader.Cap = lengthsliceHeader.Len = lengthsliceHeader.Data = uintptr(ptr) 创建切片make 函数允许在运行期动态指定数组长度，绕开了数组类型必须使用编译期常量的限制。 创建切片有两种形式，make 创建切片，空切片。 make 和切片字面量12345678910111213141516func makeslice(et *_type, len, cap int) slice &#123; // 根据切片的数据类型，获取切片的最大容量 maxElements := maxSliceCap(et.size) // 比较切片的长度，长度值域应该在[0,maxElements]之间 if len &lt; 0 || uintptr(len) &gt; maxElements &#123; panic(errorString(\"makeslice: len out of range\")) &#125; // 比较切片的容量，容量值域应该在[len,maxElements]之间 if cap &lt; len || uintptr(cap) &gt; maxElements &#123; panic(errorString(\"makeslice: cap out of range\")) &#125; // 根据切片的容量申请内存 p := mallocgc(et.size*uintptr(cap), et, true) // 返回申请好内存的切片的首地址 return slice&#123;p, len, cap&#125;&#125; 上图是用 make 函数创建的一个 len = 4， cap = 6 的切片。内存空间申请了6个 int 类型的内存大小。由于 len = 4，所以后面2个暂时访问不到，但是容量还是在的。这时候数组里面每个变量都是0 。 除了 make 函数可以创建切片以外，字面量也可以创建切片。 这里是用字面量创建的一个 len = 6，cap = 6 的切片，这时候数组里面每个元素的值都初始化完成了。需要注意的是 [ ] 里面不要写数组的容量，因为如果写了个数以后就是数组了，而不是切片了。 还有一种简单的字面量创建切片的方法。如上图。上图就 Slice A 创建出了一个 len = 3，cap = 3 的切片。从原数组的第二位元素(0是第一位)开始切，一直切到第四位为止(不包括第五位)。同理，Slice B 创建出了一个 len = 2，cap = 4 的切片。 nil 和空切片nil 切片和空切片也是常用的。 1var slice []int nil 切片被用在很多标准库和内置函数中，描述一个不存在的切片的时候，就需要用到 nil 切片。比如函数在发生异常的时候，返回的切片就是 nil 切片。nil 切片的指针指向 nil。 空切片一般会用来表示一个空的集合。比如数据库查询，一条结果也没有查到，那么就可以返回一个空切片。 12silce := make( []int , 0 )slice := []int&#123; &#125; 空切片和 nil 切片的区别在于，空切片指向的地址不是nil，指向的是一个内存地址，但是它没有分配任何内存空间，即底层元素包含0个元素。 最后需要说明的一点是。不管是使用 nil 切片还是空切片，对其调用内置函数 append，len 和 cap 的效果都是一样的。 – 切片扩容首先看看源码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192func growslice(et *_type, old slice, cap int) slice &#123; if raceenabled &#123; callerpc := getcallerpc(unsafe.Pointer(&amp;et)) racereadrangepc(old.array, uintptr(old.len*int(et.size)), callerpc, funcPC(growslice)) &#125; if msanenabled &#123; msanread(old.array, uintptr(old.len*int(et.size))) &#125; if et.size == 0 &#123; // 如果新要扩容的容量比原来的容量还要小，这代表要缩容了，那么可以直接报panic了。 if cap &lt; old.cap &#123; panic(errorString(\"growslice: cap out of range\")) &#125; // 如果当前切片的大小为0，还调用了扩容方法，那么就新生成一个新的容量的切片返回。 return slice&#123;unsafe.Pointer(&amp;zerobase), old.len, cap&#125; &#125; // 这里就是扩容的策略 newcap := old.cap doublecap := newcap + newcap if cap &gt; doublecap &#123; newcap = cap &#125; else &#123; if old.len &lt; 1024 &#123; newcap = doublecap &#125; else &#123; // Check 0 &lt; newcap to detect overflow // and prevent an infinite loop. for 0 &lt; newcap &amp;&amp; newcap &lt; cap &#123; newcap += newcap / 4 &#125; // Set newcap to the requested cap when // the newcap calculation overflowed. if newcap &lt;= 0 &#123; newcap = cap &#125; &#125; &#125; // 计算新的切片的容量，长度。 var lenmem, newlenmem, capmem uintptr const ptrSize = unsafe.Sizeof((*byte)(nil)) switch et.size &#123; case 1: lenmem = uintptr(old.len) newlenmem = uintptr(cap) capmem = roundupsize(uintptr(newcap)) newcap = int(capmem) case ptrSize: lenmem = uintptr(old.len) * ptrSize newlenmem = uintptr(cap) * ptrSize capmem = roundupsize(uintptr(newcap) * ptrSize) newcap = int(capmem / ptrSize) default: lenmem = uintptr(old.len) * et.size newlenmem = uintptr(cap) * et.size capmem = roundupsize(uintptr(newcap) * et.size) newcap = int(capmem / et.size) &#125; // 判断非法的值，保证容量是在增加，并且容量不超过最大容量 if cap &lt; old.cap || uintptr(newcap) &gt; maxSliceCap(et.size) &#123; panic(errorString(\"growslice: cap out of range\")) &#125; var p unsafe.Pointer if et.kind&amp;kindNoPointers != 0 &#123; // 在老的切片后面继续扩充容量 p = mallocgc(capmem, nil, false) // 将 lenmem 这个多个 bytes 从 old.array地址 拷贝到 p 的地址处 memmove(p, old.array, lenmem) // 先将 P 地址加上新的容量得到新切片容量的地址，然后将新切片容量地址后面的 capmem-newlenmem 个 bytes 这块内存初始化。为之后继续 append() 操作腾出空间。 memclrNoHeapPointers(add(p, newlenmem), capmem-newlenmem) &#125; else &#123; // 重新申请新的数组给新切片 // 重新申请 capmen 这个大的内存地址，并且初始化为0值 p = mallocgc(capmem, et, true) if !writeBarrier.enabled &#123; // 如果还不能打开写锁，那么只能把 lenmem 大小的 bytes 字节从 old.array 拷贝到 p 的地址处 memmove(p, old.array, lenmem) &#125; else &#123; // 循环拷贝老的切片的值 for i := uintptr(0); i &lt; lenmem; i += et.size &#123; typedmemmove(et, add(p, i), add(old.array, i)) &#125; &#125; &#125; // 返回最终新切片，容量更新为最新扩容之后的容量 return slice&#123;p, old.len, newcap&#125;&#125; 扩容策略1234567891011121314func main() &#123; slice := []int&#123;10, 20, 30, 40&#125; newSlice := append(slice, 50) fmt.Printf(\"Before slice = %v, Pointer = %p, len = %d, cap = %d\\n\", slice, &amp;slice, len(slice), cap(slice)) fmt.Printf(\"Before newSlice = %v, Pointer = %p, len = %d, cap = %d\\n\", newSlice, &amp;newSlice, len(newSlice), cap(newSlice)) newSlice[1] += 10 fmt.Printf(\"After slice = %v, Pointer = %p, len = %d, cap = %d\\n\", slice, &amp;slice, len(slice), cap(slice)) fmt.Printf(\"After newSlice = %v, Pointer = %p, len = %d, cap = %d\\n\", newSlice, &amp;newSlice, len(newSlice), cap(newSlice))&#125;//输出结果Before slice = [10 20 30 40], Pointer = 0xc4200b0140, len = 4, cap = 4Before newSlice = [10 20 30 40 50], Pointer = 0xc4200b0180, len = 5, cap = 8After slice = [10 20 30 40], Pointer = 0xc4200b0140, len = 4, cap = 4After newSlice = [10 30 30 40 50], Pointer = 0xc4200b0180, len = 5, cap = 8 用图表示 从图上我们可以很容易的看出，新的切片和之前的切片已经不同了，因为新的切片更改了一个值，并没有影响到原来的数组，新切片指向的数组是一个全新的数组。并且 cap 容量也发生了变化。这之间究竟发生了什么呢？ Go 中切片扩容的策略是这样的： 首先判断，如果新申请容量（cap）大于2倍的旧容量（old.cap），最终容量（newcap）就是新申请的容量（cap） 否则判断，如果旧切片的长度小于1024，则最终容量(newcap)就是旧容量(old.cap)的两倍，即（newcap=doublecap） 否则判断，如果旧切片长度大于等于1024，则最终容量（newcap）从旧容量（old.cap）开始循环增加原来的 1/4，即（newcap=old.cap,for {newcap += newcap/4}）直到最终容量（newcap）大于等于新申请的容量(cap)，即（newcap &gt;= cap） 如果最终容量（cap）计算值溢出，则最终容量（cap）就是新申请容量（cap） 注意：扩容扩大的容量都是针对原来的容量而言的，而不是针对原来数组的长度而言的。 新数组 or 老数组 ？再谈谈扩容之后的数组一定是新的么？这个不一定，分两种情况。 情况一： 123456789101112131415161718func main() &#123; array := [4]int&#123;10, 20, 30, 40&#125; slice := array[0:2] newSlice := append(slice, 50) fmt.Printf(\"Before slice = %v, Pointer = %p, len = %d, cap = %d\\n\", slice, &amp;slice, len(slice), cap(slice)) fmt.Printf(\"Before newSlice = %v, Pointer = %p, len = %d, cap = %d\\n\", newSlice, &amp;newSlice, len(newSlice), cap(newSlice)) newSlice[1] += 10 fmt.Printf(\"After slice = %v, Pointer = %p, len = %d, cap = %d\\n\", slice, &amp;slice, len(slice), cap(slice)) fmt.Printf(\"After newSlice = %v, Pointer = %p, len = %d, cap = %d\\n\", newSlice, &amp;newSlice, len(newSlice), cap(newSlice)) fmt.Printf(\"After array = %v\\n\", array)&#125;//输出Before slice = [10 20], Pointer = 0xc4200c0040, len = 2, cap = 4Before newSlice = [10 20 50], Pointer = 0xc4200c0060, len = 3, cap = 4After slice = [10 30], Pointer = 0xc4200c0040, len = 2, cap = 4After newSlice = [10 30 50], Pointer = 0xc4200c0060, len = 3, cap = 4After array = [10 30 50 40] 把上述过程用图表示出来，如下图。 通过打印的结果，我们可以看到，在这种情况下，扩容以后并没有新建一个新的数组，扩容前后的数组都是同一个，这也就导致了新的切片修改了一个值，也影响到了老的切片了。并且 append() 操作也改变了原来数组里面的值。一个 append() 操作影响了这么多地方，如果原数组上有多个切片，那么这些切片都会被影响！无意间就产生了莫名的 bug！ 这种情况，由于原数组还有容量可以扩容，所以执行 append() 操作以后，会在原数组上直接操作，所以这种情况下，扩容以后的数组还是指向原来的数组。 这种情况也极容易出现在字面量创建切片时候，第三个参数 cap 传值的时候，如果用字面量创建切片，cap 并不等于指向数组的总容量，那么这种情况就会发生。 1slice := array[1:2:3] 上面这种情况非常危险，极度容易产生 bug 。建议用字面量创建切片的时候，cap 的值一定要保持清醒，避免共享原数组导致的 bug。 情况二： 情况二其实就是在扩容策略里面举的例子，在那个例子中之所以生成了新的切片，是因为原来数组的容量已经达到了最大值，再想扩容， Go 默认会先开一片内存区域，把原来的值拷贝过来，然后再执行 append() 操作。这种情况丝毫不影响原数组。 所以建议尽量避免情况一，尽量使用情况二，避免 bug 产生。举例： 123456789101112func main() &#123; s1 := []int&#123;1, 2, 3&#125; s2 := s1[1:] s2[1] = 4 fmt.Println(s1) s2 = append(s2, 5, 6, 7) fmt.Println(s1)&#125;//output [1 2 4][1 2 4] 切片拷贝Slice 中拷贝方法有2个。 1234567891011121314151617181920212223242526272829303132333435363738func slicecopy(to, fm slice, width uintptr) int &#123; // 如果源切片或者目标切片有一个长度为0，那么就不需要拷贝，直接 return if fm.len == 0 || to.len == 0 &#123; return 0 &#125; // n 记录下源切片或者目标切片较短的那一个的长度 n := fm.len if to.len &lt; n &#123; n = to.len &#125; // 如果入参 width = 0，也不需要拷贝了，返回较短的切片的长度 if width == 0 &#123; return n &#125; // 如果开启了竞争检测 if raceenabled &#123; callerpc := getcallerpc(unsafe.Pointer(&amp;to)) pc := funcPC(slicecopy) racewriterangepc(to.array, uintptr(n*int(width)), callerpc, pc) racereadrangepc(fm.array, uintptr(n*int(width)), callerpc, pc) &#125; // 如果开启了 The memory sanitizer (msan) if msanenabled &#123; msanwrite(to.array, uintptr(n*int(width))) msanread(fm.array, uintptr(n*int(width))) &#125; size := uintptr(n) * width if size == 1 &#123; // TODO: is this still worth it with new memmove impl? // 如果只有一个元素，那么指针直接转换即可 *(*byte)(to.array) = *(*byte)(fm.array) // known to be a byte pointer &#125; else &#123; // 如果不止一个元素，那么就把 size 个 bytes 从 fm.array 地址开始，拷贝到 to.array 地址之后 memmove(to.array, fm.array, size) &#125; return n&#125; 在这个方法中，slicecopy 方法会把源切片值(即 fm Slice )中的元素复制到目标切片(即 to Slice )中，并返回被复制的元素个数，copy 的两个类型必须一致。slicecopy 方法最终的复制结果取决于较短的那个切片，当较短的切片复制完成，整个复制过程就全部完成了。 说到拷贝，切片中有一个需要注意的问题。 1234567891011func main() &#123; slice := []int&#123;10, 20, 30, 40&#125; for index, value := range slice &#123; fmt.Printf(\"value = %d , value-addr = %x , slice-addr = %x\\n\", value, &amp;value, &amp;slice[index]) &#125;&#125;//输出value = 10 , value-addr = c4200aedf8 , slice-addr = c4200b0320value = 20 , value-addr = c4200aedf8 , slice-addr = c4200b0328value = 30 , value-addr = c4200aedf8 , slice-addr = c4200b0330value = 40 , value-addr = c4200aedf8 , slice-addr = c4200b0338 由于 Value 是值拷贝的，并非引用传递，所以直接改 Value 是达不到更改原切片值的目的的，需要通过 &amp;slice[index] 获取真实的地址。","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Golang","slug":"后端/Golang","permalink":"http://xuchen.youtuc.cn/categories/后端/Golang/"}],"tags":[],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Golang","slug":"后端/Golang","permalink":"http://xuchen.youtuc.cn/categories/后端/Golang/"}]},{"title":"RabbitMQ-工作原理","slug":"Amqp/RabbitMQ-工作原理","date":"2019-09-04T22:48:46.000Z","updated":"2021-05-04T08:26:08.000Z","comments":true,"path":"2019/09/04/Amqp/RabbitMQ-工作原理/","link":"","permalink":"http://xuchen.youtuc.cn/2019/09/04/Amqp/RabbitMQ-工作原理/","excerpt":"","text":"工作机制在了解消息通讯之前首先要了解3个概念：生产者、消费者和代理。 生产者：消息的创建者，负责创建和推送数据到消息服务器； 消费者：消息的接收方，用于处理数据和确认消息； 代理：就是RabbitMQ本身，用于扮演“快递”的角色，本身不生产消息，只是扮演“快递”的角色。 消息发送原理你的应用程序和Rabbit Server之间会创建一个TCP连接，一旦TCP打开，并通过了认证，认证就是你试图连接Rabbit之前发送的Rabbit服务器连接信息和用户名和密码，有点像程序连接数据库，一旦认证通过你的应用程序和Rabbit就创建了一条AMQP信道（Channel）。信道是创建在“真实”TCP上的虚拟连接，AMQP命令都是通过信道发送出去的，每个信道都会有一个唯一的ID，不论是发布消息，订阅队列或者介绍消息都是通过信道完成的。 为什么直接通过TCP发送命名对于操作系统来说创建和销毁TCP会话是非常昂贵的开销，假设高峰期每秒有成千上万条连接，每个连接都要创建一条TCP会话，这就造成了TCP连接的巨大浪费，而且操作系统每秒能创建的TCP也是有限的，因此很快就会遇到系统瓶颈。如果我们每个请求都使用一条TCP连接，既满足了性能的需要，又能确保每个连接的私密性，这就是引入信道概念的原因。 名词解释包括：ConnectionFactory（连接管理器）、Channel（信道）、Exchange（交换器）、Queue（队列）、RoutingKey（路由键）、BindingKey（绑定键）。 ConnectionFactory（连接管理器）：应用程序与Rabbit之间建立连接的管理器，程序代码中使用； Channel（信道）：消息推送使用的通道； Exchange（交换器）：用于接受、分配消息； Queue（队列）：用于存储生产者的消息； RoutingKey（路由键）：用于把生成者的数据分配到交换器上； BindingKey（绑定键）：用于把交换器的消息绑定到队列上； 消息持久化Rabbit队列和交换器有一个不可告人的秘密，就是默认情况下重启服务器会导致消息丢失，那么怎么保证Rabbit在重启的时候不丢失呢？答案就是消息持久化。 当你把消息发送到Rabbit服务器的时候，你需要选择你是否要进行持久化，但这并不能保证Rabbit能从崩溃中恢复，想要Rabbit消息能恢复必须满足3个条件： 投递消息的时候durable设置为true，消息持久化，代码：channel.queueDeclare(x, true, false, false, null)，参数2设置为true持久化；设置投递模式deliveryMode设置为2（持久），代码：channel.basicPublish(x, x, MessageProperties.PERSISTENT_TEXT_PLAIN,x)，参数3设置为存储纯文本到磁盘；消息已经到达持久化交换器上；消息已经到达持久化的队列； 持久化工作原理Rabbit会将你的持久化消息写入磁盘上的持久化日志文件，等消息被消费之后，Rabbit会把这条消息标识为等待垃圾回收。 持久化的缺点消息持久化的优点显而易见，但缺点也很明显，那就是性能，因为要写入硬盘要比写入内存性能较低很多，从而降低了服务器的吞吐量，尽管使用SSD硬盘可以使事情得到缓解，但他仍然吸干了Rabbit的性能，当消息成千上万条要写入磁盘的时候，性能是很低的。","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"RabbitMQ","slug":"后端/RabbitMQ","permalink":"http://xuchen.youtuc.cn/categories/后端/RabbitMQ/"}],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://xuchen.youtuc.cn/tags/RabbitMQ/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"RabbitMQ","slug":"后端/RabbitMQ","permalink":"http://xuchen.youtuc.cn/categories/后端/RabbitMQ/"}]},{"title":"RabbitMQ-面试","slug":"Amqp/RabbitMQ-面试","date":"2019-09-04T22:48:46.000Z","updated":"2021-05-04T08:26:08.000Z","comments":true,"path":"2019/09/04/Amqp/RabbitMQ-面试/","link":"","permalink":"http://xuchen.youtuc.cn/2019/09/04/Amqp/RabbitMQ-面试/","excerpt":"","text":"问答 重复消息问题 生产者-&gt;服务端出现网络抖动等问题的重发(上半场): 此时重发是MQ-client发起的，消息的处理是MQ-server,为了避免重复，对每条消息MQ系统内部必须生成一个inner-msg-id，全局唯一，由MQ生成对业务透明 服务端-&gt;消费端出现网络抖动等问题的重发(下半场): 为了保证业务幂等性，业务消息体中，必须有一个biz-id，作为去重和幂等的依据，这个业务ID的特性是：对于同一个业务场景，全局唯一、由业务消息发送方生成，业务相关，对MQ透明、由业务消息消费方负责判重，以保证幂等，常见的有订单id,业务唯一id等 顺序消息问题问题场景1：业务上产生三条消息，分别是对数据的增加、修改、删除，而如果没有保证顺序消费，结果可能是删除、修改、增加，本来数据最终要删除，最后结果变成增加 解决方案,需要保证以下几点: 发送的顺序消息，必须保证在投递到同一个队列，且这个消费者只能有一个（独占模式） 然后统一提交（可以合并一个大消息，或拆分多个消息，最好是拆分），并且所有消息的会话ID一致 添加消息属性：顺序表及序号、本地顺序消息的size属性，进行落库操作 并行进行发送给自身的延迟消息（带上关键属性：会话ID、SIZE）进行后续处理消费 事物消息问题 消息丢失问题解决办法 生产者：方案一，开启事物机制，不推荐使用，分布式环境尤其复杂；方案二，开启confir模式 MQ：开启消息持久化 消费者：关闭自动的ack,采用手动ack方式 高可用场景 集群 RabbitMQ集群处理新增节点： 有新节点加入，RabbitMQ不会同步之前的历史数据，新节点只会复制该节点加入到集群之后新增的消息。 既然master节点退出集群会选一个slave作为master，那么如果不幸选中了一个刚刚加入集群的节点怎么办？那消息不就丢了吗？这里您可以把心放到肚子里，RabbitMQ集群内部会维护节点的状态是否已经同步，使用rabbitmqctl的synchronised_slave_pids参数，就可以查看状态。如果slave_pids和synchronised_slave_pids里面的节点是一致的，那说明全都同步了；如果不一致很容易比较出来哪些还没有同步，集群只会在“最老”的slave节点之间选一个出来作为新的master节点。另外对于node节点的重启也是按照新节点来处理的。 镜像队列（集群模式可启用）： 在镜像队列集群模式中，对某个queue来说，只有master对外提供服务，而其他slave只提供备份服务，在master所在节点不可用时，选出一个slave作为新的master继续对外提供服务。通常是加入时间最长的选中为新的master 镜像队列不能作为负载均衡使用，因为每个声明和消息操作都要在所有节点复制一遍。 每当一个节点加入或者重新加入镜像队列，之前保存的队列内容会被清空。 对于镜像队列，客户端basic.publish操作会同步到所有节点；而其他操作则是通过master中转，再由master将操作作用于salve。 RabbitMQ 中的 broker 是指什么？cluster 又是指什么？broker 是指一个或多个 erlang node 的逻辑分组，且 node 上运行着 RabbitMQ 应用程序。cluster 是在 broker 的基础之上，增加了 node 之间共享元数据的约束。 什么是元数据？元数据分为哪些类型？包括哪些内容？与 cluster 相关的元数据有哪些？元数据是如何保存的？元数据在 cluster 中是如何分布的？在非 cluster 模式下，元数据主要分为 Queue 元数据（queue 名字和属性等）、Exchange 元数据（exchange 名字、类型和属性等）、Binding 元数据（存放路由关系的查找表）、Vhost 元数据（vhost 范围内针对前三者的名字空间约束和安全属性设置）。在cluster 模式下，还包括 cluster 中 node 位置信息和 node 关系信息。元数据按照 erlang node 的类型确定是仅保存于 RAM 中，还是同时保存在 RAM 和 disk 上。元数据在cluster 中是全 node 分布的。 RAM node 和 disk node 的区别？RAM node 仅将 fabric（即 queue、exchange 和 binding 等 RabbitMQ 基础构件）相关元数据保存到内存中，但 disk node 会在内存和磁盘中均进行存储。RAM node 上唯一会存储到磁盘上的元数据是 cluster 中使用的 disk node 的地址。要求在 RabbitMQ cluster 中至少存在一个 disk node RabbitMQ 上的一个 queue 中存放的 message 是否有数量限制？可以认为是无限制，因为限制取决于机器的内存，但是消息过多会导致处理效率的下降。 RabbitMQ 概念里的 channel、exchange 和 queue 这些东东是逻辑概念，还是对应着进程实体？这些东东分别起什么作用？queue 具有自己的 erlang 进程；exchange 内部实现为保存 binding 关系的查找表；channel 是实际进行路由工作的实体，即负责按照 routing_key 将 message 投递给queue 。由 AMQP 协议描述可知，channel 是真实 TCP 连接之上的虚拟连接，所有AMQP 命令都是通过 channel 发送的，且每一个 channel 有唯一的 ID。一个 channel 只能被单独一个操作系统线程使用，故投递到特定 channel 上的 message 是有顺序的。但一个操作系统线程上允许使用多个 channel 。channel 号为 0 的 channel 用于处理所有对于当前 connection 全局有效的帧，而 1-65535 号 channel 用于处理和特定 channel 相关的帧。其中每一个 channel 运行在一个独立的线程上，多线程共享同一个 socket。 vhost 是什么？起什么作用？vhost 可以理解为虚拟 broker ，即 mini-RabbitMQ server。其内部均含有独立的queue、exchange 和 binding 等，但最最重要的是，其拥有独立的权限系统，可以做到vhost 范围的用户控制。当然，从 RabbitMQ 的全局角度，vhost 可以作为不同权限隔离的手段（一个典型的例子就是不同的应用可以跑在不同的 vhost 中）。 为什么 heavy RPC 的使用场景下不建议采用 disk node ？heavy RPC 是指在业务逻辑中高频调用 RabbitMQ 提供的 RPC 机制，导致不断创建、销毁 reply queue ，进而造成 disk node 的性能问题（因为会针对元数据不断写盘）。所以在使用 RPC 机制时需要考虑自身的业务场景。 向不存在的 exchange 发 publish 消息会发生什么？向不存在的 queue 执行consume 动作会发生什么？都会收到 Channel.Close 信令告之不存在（内含原因 404 NOT_FOUND）。 RabbitMQ 允许发送的 message 最大可达多大？根据 AMQP 协议规定，消息体的大小由 64-bit 的值来指定，所以你就可以知道到底能发多大的数据了。 什么情况下 producer 不主动创建 queue 是安全的？1.message是允许丢失的；2.实现了针对未处理消息的republish功能（例如采用Publisher Confirm 机制）。 “dead letter”queue 的用途？当消息被 RabbitMQ server 投递到 consumer 后，但 consumer 却通过 Basic.Reject 进行了拒绝时（同时设置 requeue=false），那么该消息会被放入“dead letter”queue 中。该 queue 可用于排查 message 被 reject 或 undeliver 的原因。 什么情况下会出现 blackholed 问题？blackholed 问题是指，向 exchange 投递了 message ，而由于各种原因导致该message 丢失，但发送者却不知道。可导致 blackholed 的情况：1.向未绑定 queue 的exchange 发送 message；2.exchange 以 binding_key key_A 绑定了 queue queue_A，但向该 exchange 发送 message 使用的 routing_key 却是 key_B。","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"RabbitMQ","slug":"后端/RabbitMQ","permalink":"http://xuchen.youtuc.cn/categories/后端/RabbitMQ/"}],"tags":[{"name":"面试","slug":"面试","permalink":"http://xuchen.youtuc.cn/tags/面试/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"RabbitMQ","slug":"后端/RabbitMQ","permalink":"http://xuchen.youtuc.cn/categories/后端/RabbitMQ/"}]},{"title":"RabbitMQ-Exchange","slug":"Amqp/RabbitMQ-Exchange","date":"2019-09-04T22:48:46.000Z","updated":"2021-05-04T08:26:08.000Z","comments":true,"path":"2019/09/04/Amqp/RabbitMQ-Exchange/","link":"","permalink":"http://xuchen.youtuc.cn/2019/09/04/Amqp/RabbitMQ-Exchange/","excerpt":"","text":"交换器分类RabbitMQ的Exchange（交换器）分为四类： direct（默认） headers fanout topic 其中headers交换器允许你匹配AMQP消息的header而非路由键，除此之外headers交换器和direct交换器完全一致，但性能却很差，几乎用不到，所以我们本文也不做讲解。 注意：fanout、topic交换器是没有历史数据的，也就是说对于中途创建的队列，获取不到之前的消息。 directdirect为默认的交换器类型，也非常的简单，如果路由键匹配的话，消息就投递到相应的队列，如图： 注意：不能使用for循环单个消息消费来替代持续消息消费，因为这样性能很低； 公平调度当接收端订阅者有多个的时候，direct会轮询公平的分发给每个订阅者（订阅者消息确认正常） 消息的发后既忘特性发后既忘模式是指接受者不知道消息的来源，如果想要指定消息的发送者，需要包含在发送内容里面，这点就像我们在信件里面注明自己的姓名一样，只有这样才能知道发送者是谁。 消息确认看了上面的代码我们可以知道，消息接收到之后必须使用channel.basicAck()方法手动确认（非自动确认删除模式下），那么问题来了。 消息收到未确认会怎么样？如果应用程序接收了消息，因为bug忘记确认接收的话，消息在队列的状态会从“Ready”变为“Unacked”，如图：总结：消费者消费的每条消息都必须确认。 消息拒绝消息在确认之前，可以有两个选择： 选择1：断开与Rabbit的连接，这样Rabbit会重新把消息分派给另一个消费者； 选择2：拒绝Rabbit发送的消息使用channel.basicReject(long deliveryTag, boolean requeue)，参数1：消息的id；参数2：处理消息的方式，如果是true Rabbib会重新分配这个消息给其他订阅者，如果设置成false的话，Rabbit会把消息发送到一个特殊的“死信”队列，用来存放被拒绝而不重新放入队列的消息。 fanout交换器——发布/订阅模式不处理路由键。你只需要简单的将队列绑定到交换机上。一个发送到交换机的消息都会被转发到与该交换机绑定的所有队列上。很像子网广播，每台子网内的主机都获得了一份复制的消息。Fanout交换机转发消息是最快的。 topictopic交换器运行和fanout类似，但是可以更灵活的匹配自己想要订阅的信息，这个时候routingKey路由键就排上用场了，使用路由键进行消息（规则）匹配。假设我们现在有一个日志系统，会把所有日志级别的日志发送到交换器，warning、log、error、fatal，但我们只想处理error以上的日志，要怎么处理？这就需要使用topic路由器了。topic路由器的关键在于定义路由键，定义routingKey名称不能超过255字节，使用“.”作为分隔符，例如：com.mq.rabbit.error。","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"RabbitMQ","slug":"后端/RabbitMQ","permalink":"http://xuchen.youtuc.cn/categories/后端/RabbitMQ/"}],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://xuchen.youtuc.cn/tags/RabbitMQ/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"RabbitMQ","slug":"后端/RabbitMQ","permalink":"http://xuchen.youtuc.cn/categories/后端/RabbitMQ/"}]},{"title":"Go-log日志","slug":"Go/log日志","date":"2019-08-28T23:23:53.000Z","updated":"2020-05-18T05:44:55.000Z","comments":true,"path":"2019/08/28/Go/log日志/","link":"","permalink":"http://xuchen.youtuc.cn/2019/08/28/Go/log日志/","excerpt":"","text":"日志使用o语言为我们提供了标准的log包，来跟踪日志的记录。下面我们看看日志包log的使用 1234func main() &#123; log.Println(&quot;这是百度地址:&quot;,&quot;http://www.baidu.com&quot;) log.Printf(&quot;这是百度地址域名：%s\\n&quot;,&quot;baidu.com&quot;)&#125; 122019/08/28 13:18:44 这是百度地址: http://www.baidu.com2019/08/28 13:18:44 这是百度地址域名：baidu.com 有了时间了，我们还想要更多的信息，必然发生的源代码行号等，对此日志包log 为我们提供了可定制化的配制，让我们可以自己定制日志的抬头信息。 123func init()&#123; log.SetFlags(log.Ldate|log.Lshortfile)&#125; 我们使用init函数，这个函数在main函数执行之前就可以初始化，可以帮我们做一些配置，这里我们自定义日志的抬头信息为时间+文件名+源代码所在行号。也就是log.Ldate|log.Lshortfile,中间是一个位运算符|，然后通过函数log.SetFlags进行设置。 122017/04/29 main.go:10: 飞雪无情的博客: http://www.flysnow.org2017/04/29 main.go:11: 飞雪无情的微信公众号：flysnow_org 看看log包为我们提供了那些可以定义的选项常量。 123456789const ( Ldate = 1 &lt;&lt; iota //日期示例： 2009/01/23 Ltime //时间示例: 01:23:23 Lmicroseconds //毫秒示例: 01:23:23.123123. Llongfile //绝对路径和行号: /a/b/c/d.go:23 Lshortfile //文件和行号: d.go:23. LUTC //日期时间转为0时区的 LstdFlags = Ldate | Ltime //Go提供的标准抬头信息) 这是log包定义的一些抬头信息，有日期、时间、毫秒时间、绝对路径和行号、文件名和行号等，在上面都有注释说明，这里需要注意的是：如果设置了Lmicroseconds，那么Ltime就不生效了；设置了Lshortfile， Llongfile也不会生效，大家自己可以测试一下。 LUTC比较特殊，如果我们配置了时间标签，那么如果设置了LUTC的话，就会把输出的日期时间转为0时区的日期时间显示。 1log.SetFlags(log.Ldate|log.Ltime |log.LUTC) 那么对我们东八区的时间来说，就会减去8个小时，我们看输出： 122017/04/29 05:46:29 飞雪无情的博客: http://www.flysnow.org2017/04/29 05:46:29 飞雪无情的微信公众号：flysnow_org 最后一个LstdFlags表示标准的日志抬头信息，也就是默认的，包含日期和具体时间。 我们大部分情况下，都有很多业务，每个业务都需要记录日志，那么有没有办法，能区分这些业务呢？这样我们在查找日志的时候，就方便多了。 对于这种情况，Go语言也帮我们考虑到了，这就是设置日志的前缀，比如一个用户中心系统的日志，我们可以这么设置。 1234func init()&#123; log.SetPrefix(&quot;【UserCenter】&quot;) log.SetFlags(log.LstdFlags | log.Lshortfile |log.LUTC)&#125; 通过log.SetPrefix可以指定输出日志的前缀，这里我们指定为【UserCenter】，然后就可以看到日志的打印输出已经清晰的标记出我们的这些日志是属于哪些业务的啦。 12【UserCenter】2017/04/29 05:53:26 main.go:11: 飞雪无情的博客: http://www.flysnow.org【UserCenter】2017/04/29 05:53:26 main.go:12: 飞雪无情的微信公众号：flysnow_org log包除了有Print系列的函数，还有Fatal以及Panic系列的函数，其中Fatal表示程序遇到了致命的错误，需要退出，这时候使用Fatal记录日志后，然后程序退出，也就是说Fatal相当于先调用Print打印日志，然后再调用os.Exit(1)退出程序。 同理Panic系列的函数也一样，表示先使用Print记录日志，然后调用panic()函数抛出一个恐慌，这时候除非使用recover()函数，否则程序就会打印错误堆栈信息，然后程序终止。 这里贴下这几个系列函数的源代码，更好理解。 1234567891011121314func Println(v ...interface&#123;&#125;) &#123; std.Output(2, fmt.Sprintln(v...))&#125;func Fatalln(v ...interface&#123;&#125;) &#123; std.Output(2, fmt.Sprintln(v...)) os.Exit(1)&#125;func Panicln(v ...interface&#123;&#125;) &#123; s := fmt.Sprintln(v...) std.Output(2, s) panic(s)&#125; 实现原理通过上面的源代码，我们发现，日志包log的这些函数都是类似的，关键的输出日志就在于std.Output方法 12345func New(out io.Writer, prefix string, flag int) *Logger &#123; return &amp;Logger&#123;out: out, prefix: prefix, flag: flag&#125;&#125;var std = New(os.Stderr, &quot;&quot;, LstdFlags) 从以上源代码可以看出，变量std其实是一个*Logger，通过log.New函数创建，默认输出到os.Stderr设备，前缀为空，日志抬头信息为标准抬头LstdFlags。 os.Stderr对应的是UNIX里的标准错误警告信息的输出设备，同时被作为默认的日志输出目的地。初次之外，还有标准输出设备os.Stdout以及标准输入设备os.Stdin。 12345var ( Stdin = NewFile(uintptr(syscall.Stdin), &quot;/dev/stdin&quot;) Stdout = NewFile(uintptr(syscall.Stdout), &quot;/dev/stdout&quot;) Stderr = NewFile(uintptr(syscall.Stderr), &quot;/dev/stderr&quot;)) 以上就是定义的UNIX的标准的三种设备，分别用于输入、输出和警告错误信息。理解了os.Stderr，现在我们看下Logger这个结构体，日志的信息和操作，都是通过这个Logger操作的。 1234567type Logger struct &#123; mu sync.Mutex // 字段mu是一个互斥锁，主要是是保证这个日志记录器Logger在多goroutine下也是安全的 prefix string // 字段prefix是每一行日志的前缀 flag int // 字段flag是日志抬头信息 out io.Writer // 字段out是日志输出的目的地，默认情况下是os.Stderr。 buf []byte // 字段buf是一次日志输出文本缓冲，最终会被写到out里。&#125; 了解了结构体Logger的字段，现在就可以看下它最重要的方法Output了，这个方法会输出格式化好的日志信息。 12345678910111213141516171819202122232425262728293031func (l *Logger) Output(calldepth int, s string) error &#123; now := time.Now() // get this early. var file string var line int //加锁，保证多goroutine下的安全 l.mu.Lock() defer l.mu.Unlock() //如果配置了获取文件和行号的话 if l.flag&amp;(Lshortfile|Llongfile) != 0 &#123; //因为runtime.Caller代价比较大，先不加锁 l.mu.Unlock() var ok bool _, file, line, ok = runtime.Caller(calldepth) if !ok &#123; file = &quot;???&quot; line = 0 &#125; //获取到行号等信息后，再加锁，保证安全 l.mu.Lock() &#125; //把我们的日志信息和设置的日志抬头进行拼接 l.buf = l.buf[:0] l.formatHeader(&amp;l.buf, now, file, line) l.buf = append(l.buf, s...) if len(s) == 0 || s[len(s)-1] != &apos;\\n&apos; &#123; l.buf = append(l.buf, &apos;\\n&apos;) &#125; //输出拼接好的缓冲buf里的日志信息到目的地 _, err := l.out.Write(l.buf) return err&#125; 整个代码比较简洁，为了多goroutine安全互斥锁也用上了，但是在获取调用堆栈信息的时候，又要先解锁，因为这个过程比较重。获取到文件、行号等信息后，继续加互斥锁保证安全。 后面的就比较简单了，formatHeader方法主要是格式化日志抬头信息，然后存储在buf这个缓冲中，最后再把我们自己的日志信息拼接到缓冲buf的后面，然后为一次log日志输出追加一个换行符，这样每次日志输出都是一行一行的。 有了最终的日志信息buf，然后把它写到输出的目的地out里就可以了，这是一个实现了io.Writer接口的类型，只要实现了这个接口，都可以当作输出目的地。 12345func (l *Logger) SetOutput(w io.Writer) &#123; l.mu.Lock() defer l.mu.Unlock() l.out = w&#125; log包的SetOutput函数，可以设置输出目的地。这里稍微简单介绍下runtime.Caller，它可以获取运行时方法的调用信息。 1func Caller(skip int) (pc uintptr, file string, line int, ok bool) 参数skip表示跳过栈帧数，0表示不跳过，也就是runtime.Caller的调用者。1的话就是再向上一层，表示调用者的调用者。 log日志包里使用的是2，也就是表示我们在源代码中调用log.Print、log.Fatal和log.Panic这些函数的调用者。 以main函数调用log.Println为例，是main-&gt;log.Println-&gt;*Logger.Output-&gt;runtime.Caller这么一个方法调用栈，所以这时候，skip的值分别代表： 0表示*Logger.Output中调用runtime.Caller的源代码文件和行号 1表示log.Println中调用*Logger.Output的源代码文件和行号 2表示main中调用log.Println的源代码文件和行号 所以这也是log包里的这个skip的值为什么一直是2的原因。 定制自己的日志通过上面的源码分析，我们知道日志记录的根本就在于一个日志记录器Logger，所以我们定制自己的日志，其实就是创建不同的Logger。 1234567891011121314151617181920212223var ( Info *log.Logger Warning *log.Logger Error * log.Logger)func init()&#123; errFile,err:=os.OpenFile(&quot;errors.log&quot;,os.O_CREATE|os.O_WRONLY|os.O_APPEND,0666) if err!=nil&#123; log.Fatalln(&quot;打开日志文件失败：&quot;,err) &#125; Info = log.New(os.Stdout,&quot;Info:&quot;,log.Ldate | log.Ltime | log.Lshortfile) Warning = log.New(os.Stdout,&quot;Warning:&quot;,log.Ldate | log.Ltime | log.Lshortfile) Error = log.New(io.MultiWriter(os.Stderr,errFile),&quot;Error:&quot;,log.Ldate | log.Ltime | log.Lshortfile)&#125;func main() &#123; Info.Println(&quot;飞雪无情的博客:&quot;,&quot;http://www.flysnow.org&quot;) Warning.Printf(&quot;飞雪无情的微信公众号：%s\\n&quot;,&quot;flysnow_org&quot;) Error.Println(&quot;欢迎关注留言&quot;)&#125; 我们根据日志级别定义了三种不同的Logger，分别为Info,Warning,Error，用于不同级别日志的输出。这三种日志记录器都是使用log.New函数进行创建。 这里创建Logger的时候，Info和Warning都比较正常，Error这里采用了多个目的地输出，这里可以同时把错误日志输出到os.Stderr以及我们创建的errors.log文件中。 io.MultiWriter函数可以包装多个io.Writer为一个io.Writer，这样我们就可以达到同时对多个io.Writer输出日志的目的。 io.MultiWriter的实现也很简单，定义一个类型实现io.Writer，然后在实现的Write方法里循环调用要包装的多个Writer接口的Write方法即可。 12345678910111213func (t *multiWriter) Write(p []byte) (n int, err error) &#123; for _, w := range t.writers &#123; n, err = w.Write(p) if err != nil &#123; return &#125; if n != len(p) &#123; err = ErrShortWrite return &#125; &#125; return len(p), nil&#125; 这里我们通过定义了多个Logger来区分不同的日志级别，使用比较麻烦，针对这种情况，可以使用第三方的log框架，也可以自定包装定义，直接通过不同级别的方法来记录不同级别的日志，还可以设置记录日志的级别等。 本文收集来源：https://www.flysnow.org","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Golang","slug":"后端/Golang","permalink":"http://xuchen.youtuc.cn/categories/后端/Golang/"}],"tags":[],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Golang","slug":"后端/Golang","permalink":"http://xuchen.youtuc.cn/categories/后端/Golang/"}]},{"title":"Go-错误(error)处理方案","slug":"Go/错误处理方案","date":"2019-08-28T23:04:50.000Z","updated":"2020-05-18T05:44:55.000Z","comments":true,"path":"2019/08/28/Go/错误处理方案/","link":"","permalink":"http://xuchen.youtuc.cn/2019/08/28/Go/错误处理方案/","excerpt":"","text":"error接口error其实是一个接口，内置的，看下他的定义 12345// The error built-in interface type is the conventional interface for// representing an error condition, with the nil value representing no error.type error interface &#123; Error() string&#125; 它只有一个方法 Error，只要实现了这个方法，就是实现了error。现在我们自己定义一个错误试试。 123456type fileError struct &#123;&#125;func (fe *fileError) Error() string &#123; return &quot;文件错误&quot;&#125; 自定义 error自定义了一个fileError类型，实现了error接口。现在测试下看看效果。 12345678910111213func main() &#123; conent, err := openFile() if err != nil &#123; fmt.Println(err) &#125; else &#123; fmt.Println(string(conent)) &#125;&#125;//只是模拟一个错误func openFile() ([]byte, error) &#123; return nil, &amp;fileError&#123;&#125;&#125; 运行模拟的代码，可以看到文件错误的通知。 在实际的使用过程中，我们可能遇到很多错误，他们的区别是错误信息不一样，一种做法是每种错误都类似上面一样定义一个错误类型，但是这样太麻烦了。我们发现Error返回的其实是个字符串，我们可以修改下，让这个字符串可以设置就可以了。 1234567type fileError struct &#123; s string&#125;func (fe *fileError) Error() string &#123; return fe.s&#125; 这样改造后，我们就可以在声明fileError的时候，设置好要提示的错误文字，就可以满足我们不同的需要了。 1234//只是模拟一个错误func openFile() ([]byte, error) &#123; return nil, &amp;fileError&#123;&quot;文件错误，自定义&quot;&#125;&#125; 修改fileError的名字，再创建一个辅助函数，便于我们创建不同的错误类型。 12345678910111213//blog:www.flysnow.org//wechat:flysnow_orgfunc New(text string) error &#123; return &amp;errorString&#123;text&#125;&#125;type errorString struct &#123; s string&#125;func (e *errorString) Error() string &#123; return e.s&#125; 可以通过New函数，辅助我们创建不同的错误了，这其实就是我们经常用到的errors.New函数，被我们一步步剖析演化而来 但是上面的方案只是解决了文案提示的错误自定义，能否像PHP那样指定到错误的文件行数，具体是哪一个方法错误呢 推荐的方案因为Go语言提供的错误太简单了，以至于简单的我们无法更好的处理问题，甚至不能为我们处理错误，提供更有用的信息，所以诞生了很多对错误处理的库，github.com/pkg/errors是比较简洁的一样，并且功能非常强大，受到了大量开发者的欢迎，使用者很多。 它的使用非常简单，如果我们要新生成一个错误，可以使用New函数,生成的错误，自带调用堆栈信息。 1func New(message string) error 如果有一个现成的error，我们需要对他进行再次包装处理，这时候有三个函数可以选择。 12345678//只附加新的信息func WithMessage(err error, message string) error//只附加调用堆栈信息func WithStack(err error) error//同时附加堆栈和信息func Wrap(err error, message string) error 其实上面的包装，很类似于Java的异常包装，被包装的error，其实就是Cause,在前面的章节提到错误的根本原因，就是这个Cause。所以这个错误处理库为我们提供了Cause函数让我们可以获得最根本的错误原因。 1234567891011121314func Cause(err error) error &#123; type causer interface &#123; Cause() error &#125; for err != nil &#123; cause, ok := err.(causer) if !ok &#123; break &#125; err = cause.Cause() &#125; return err&#125; 使用for循环一直找到最根本（最底层）的那个error。 以上的错误我们都包装好了，也收集好了，那么怎么把他们里面存储的堆栈、错误原因等这些信息打印出来呢？其实，这个错误处理库的错误类型，都实现了Formatter接口，我们可以通过fmt.Printf函数输出对应的错误信息。 123%s,%v //功能一样，输出错误信息，不包含堆栈%q //输出的错误信息带引号，不包含堆栈%+v //输出错误信息和堆栈","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Golang","slug":"后端/Golang","permalink":"http://xuchen.youtuc.cn/categories/后端/Golang/"}],"tags":[],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Golang","slug":"后端/Golang","permalink":"http://xuchen.youtuc.cn/categories/后端/Golang/"}]},{"title":"Go 中 defer 与 return 之间的迷之执行顺序","slug":"Go/defer与return之间的迷之执行顺序","date":"2019-08-28T17:02:04.000Z","updated":"2020-06-14T04:00:02.000Z","comments":true,"path":"2019/08/28/Go/defer与return之间的迷之执行顺序/","link":"","permalink":"http://xuchen.youtuc.cn/2019/08/28/Go/defer与return之间的迷之执行顺序/","excerpt":"","text":"执行顺序偶然间发现了一个有意思的地方：在使用defer时，匿名返回值的函数和命名返回值的函数的返回结果是不一样的。具体见如下代码: 123456789101112131415161718192021222324252627282930313233343536373839func f1() (r int) &#123; defer func() &#123; r++ &#125;() return r&#125;func f2() (r int) &#123; t := 5 defer func() &#123; t = t + 5 &#125;() return t&#125;func f3() (r int) &#123; defer func(r int) &#123; r = r + 5 &#125;(r) return r&#125;func f4(a int) int &#123; defer func(r int) &#123; a = a + 5 &#125;(a) return a&#125;func main() &#123; fmt.Println(f1()) fmt.Println(f2()) fmt.Println(f3()) fmt.Println(f4(1))&#125;//output 1501 f1()拆解12345678910111213func f1() (r int) &#123; // 1.赋值 r = 0 // 2.闭包引用，返回值被修改 defer func() &#123; r++ &#125;() // 3.空的 return return&#125; defer 是闭包引用，返回值被修改，所以 f() 返回 1。 f2()拆解12345678910111213func f2() (r int) &#123; t := 5 // 1.赋值 r = t // 2.闭包引用，但是没有修改返回值 r defer func() &#123; t = t + 5 &#125;() // 3.空的 return return&#125; 第二步没涉及返回值 r 的操作，所以返回 5。 f3()拆解（f4同理）12345678910111213func f3() (r int) &#123; // 1.赋值 r = 1 // 2.r 作为函数参数，不会修改要返回的那个 r 值 defer func(r int) &#123; r = r + 5 &#125;(r) // 3.空的 return return&#125; 第二步，r 是作为函数参数使用，是一份复制，defer 语句里面的 r 和 外面的 r 其实是两个变量，里面变量的改变不会影响外层变量 r，所以不是返回 6 ，而是返回 1。 总结一下就是，函数的整个返回过程应该是： return对返回变量赋值，如果是匿名返回值就先声明再赋值； 执行defer函数； return携带返回值返回。 return 之后的 defer12345678910111213var a bool = truefunc main() &#123; defer func()&#123; fmt.Println(\"1\") &#125;() if a == true &#123; fmt.Println(\"2\") return &#125; defer func()&#123; fmt.Println(\"3\") &#125;()&#125; defer 关键字后面的函数或者方法想要执行必须先注册，return 之后的 defer 是不能注册的， 也就不能执行后面的函数或方法。","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Golang","slug":"后端/Golang","permalink":"http://xuchen.youtuc.cn/categories/后端/Golang/"}],"tags":[],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Golang","slug":"后端/Golang","permalink":"http://xuchen.youtuc.cn/categories/后端/Golang/"}]},{"title":"Go 中 defer坑","slug":"Go/defer的坑","date":"2019-08-28T17:02:04.000Z","updated":"2020-06-13T14:50:43.000Z","comments":true,"path":"2019/08/28/Go/defer的坑/","link":"","permalink":"http://xuchen.youtuc.cn/2019/08/28/Go/defer的坑/","excerpt":"","text":"defer nil函数123456789func() &#123; var run func() = nil defer run() fmt.Println(\"runs\")&#125;//outputrunspanic: runtime error: invalid memory address or nil pointer dereference 名为 func 的函数一直运行至结束，然后 defer 函数会被执行且会因为值为 nil 而产生 panic 异常。然而值得注意的是，run() 的声明是没有问题，因为在外围函数运行完成后它才会被调用。 循环中使用defer慎重在循环中使用defer，因为结果出人意料 123456789func demo()&#123; for&#123; row,err:=db.Query(\"select .....\") if err!=nil&#123; ... &#125; defer row.close() &#125;&#125; 在上面的例子中，defer row.Close() 在循环中的延迟函数会在函数结束过后运行，而不是每次 for 循环结束之后。这些延迟函数会不停地堆积到延迟调用栈中，最终可能会导致一些不可预知的问题。 解决方案1：不使用defer 123456789func demo()&#123; for&#123; row,err:=db.Query(\"select .....\") if err!=nil&#123; ... &#125; row.close() &#125;&#125; 解决方案2：移交给函数这样每次匿名函数执行完，会执行defer 1234567891011func demo()&#123; for&#123; func()&#123; row,err:=db.Query(\"select .....\") if err!=nil&#123; ... &#125; defer row.close() &#125;() &#125;&#125; 循环Z-A(倒叙)12345678910func main() &#123; for i := 0; i &lt; 4; i++ &#123; defer fmt.Print(i) &#125;&#125;//output3210 延迟调用含有闭包的函数123456789101112131415161718type database struct&#123;&#125;func (db *database) connect() (disconnect func()) &#123; fmt.Println(\"connect\") return func() &#123; fmt.Println(\"disconnect\") &#125;&#125;//运行 db := &amp;database&#123;&#125;defer db.connect()fmt.Println(\"query db...\")//outputquery db...connect 最终 disconnect 并没有输出，最后只有 connect ，这是一个 bug，最终的情况是 connect() 执行结束后，其执行域得以被保存起来，但内部的闭包并不会被执行。 解决方案123456func() &#123; db := &amp;database&#123;&#125; close := db.connect() defer close() fmt.Println(\"query db...\")&#125; 在执行块中使用 defer想要在执行块执行结束后执行在块内延迟调用的函数，但事实并非如此，它们只会在块所属的函数执行结束后才被执行，这种情况适用于所有的代码块除了上文的函数块例如，for，switch 等 123456789101112131415func main() &#123; &#123; defer func() &#123; fmt.Println(\"block: defer runs\") &#125;() fmt.Println(\"block: ends\") &#125; fmt.Println(\"main: ends\")&#125;//outputblock: endsmain: endsblock: defer runs 解决方案1234567891011func main() &#123; func() &#123; defer func() &#123; fmt.Println(\"func: defer runs\") &#125;() fmt.Println(\"func: ends\") &#125;() fmt.Println(\"main: ends\")&#125;","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Golang","slug":"后端/Golang","permalink":"http://xuchen.youtuc.cn/categories/后端/Golang/"}],"tags":[],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Golang","slug":"后端/Golang","permalink":"http://xuchen.youtuc.cn/categories/后端/Golang/"}]},{"title":"Go-channel总结","slug":"Go/channel总结","date":"2019-08-28T15:28:28.000Z","updated":"2020-06-21T13:59:38.000Z","comments":true,"path":"2019/08/28/Go/channel总结/","link":"","permalink":"http://xuchen.youtuc.cn/2019/08/28/Go/channel总结/","excerpt":"","text":"channel的使用场景把channel用在数据流动的地方： 消息传递、消息过滤 信号广播 事件订阅与广播 请求、响应转发 任务分发 结果汇总 并发控制 同步与异步 channel的基本操作和注意事项channel 存在3种状态 nil,未初始化，刚刚申明或者手动复制为nil active，正常运行中的可读可写 closed,关闭时，千万不要认为关闭以后，channel的值是nil channel 可进行3种操作 读 写 关闭 3种状态存在9种情况 操作 nil的channel 正常channel 已关闭channel &lt;- ch 阻塞 成功or阻塞 读到零值 ch &lt;- 阻塞 成功or阻塞 panic close(ch) panic 成功 panic 对于nil通道的情况，也并非完全遵循上表，有1个特殊场景：当nil的通道在select的某个case中时，这个case会阻塞，但不会造成死锁 使用for range读channel 场景 当需要不断从channel读取数据时。 原理 使用for-range读取channel，这样既安全又便利，当channel关闭时，for循环会自动退出，无需主动监测channel是否关闭，可以防止读取已经关闭的channel，造成读到数据为通道所存储的数据类型的零值。 用法123for x := range ch&#123; fmt.Println(x)&#125; 使用v,ok := &lt;-ch + select操作判断channel是否关闭 场景 v,ok := &lt;-ch + select操作判断channel是否关闭 原理 ok的结果和含义： 12- `true`：读到通道数据，不确定是否关闭，可能channel还有保存的数据，但channel已关闭。- `false`：通道关闭，无数据读到。 从关闭的channel读值读到是channel所传递数据类型的零值，这个零值有可能是发送者发送的，也可能是channel关闭了。 _, ok := &lt;-ch与select配合使用的，当ok为false时，代表了channel已经close。 下面解释原因，_,ok := &lt;-ch对应的函数是func chanrecv(c *hchan, ep unsafe.Pointer, block bool) (selected, received bool)，入参block含义是当前goroutine是否可阻塞，当block为false代表的是select操作，不可阻塞当前goroutine的在channel操作，否则是普通操作（即_, ok不在select中）。返回值selected代表当前操作是否成功，主要为select服务，返回received代表是否从channel读到有效值。它有3种返回值情况： block为false，即执行select时，如果channel为空，返回(false,false)，代表select操作失败，没接收到值。 否则，如果channel已经关闭，并且没有数据，ep即接收数据的变量设置为零值，返回(true,false)，代表select操作成功，但channel已关闭，没读到有效值。 否则，其他读到有效数据的情况，返回(true,ture)。 我们考虑_, ok := &lt;-ch和select结合使用的情况。 情况1：当chanrecv返回(false,false)时，本质是select操作失败了，所以相关的case会阻塞，不会执行，比如下面的代码： 12345678910111213func main() &#123; ch := make(chan int) select &#123; case v, ok := &lt;-ch: fmt.Printf(\"v: %v, ok: %v\\n\", v, ok) default: fmt.Println(\"nothing\") &#125;&#125;// 结果：// nothing 情况2：下面的结果会是零值和false： 12345678910111213func main() &#123; ch := make(chan int) // 增加关闭 close(ch) select &#123; case v, ok := &lt;-ch: fmt.Printf(\"v: %v, ok: %v\\n\", v, ok) &#125;&#125;// v: 0, ok: false 情况3的received为true，即_, ok中的ok为true，不做讨论了，只讨论ok为false的情况。 最后ok为false的时候，只有情况2，此时channel必然已经关闭，我们便可以在select中用ok判断channel是否已经关闭。 用法12345678910111213141516171819202122232425262728func main() &#123; ch := make(chan int, 1) // 发送1个数据关闭channel ch &lt;- 1 close(ch) print(\"close channel\\n\") // 不停读数据直到channel没有有效数据 for &#123; select &#123; case v, ok := &lt;-ch: print(\"v: \", v, \", ok:\", ok, \"\\n\") if !ok &#123; print(\"channel is close\\n\") return &#125; default: print(\"nothing\\n\") &#125; &#125;&#125;// 结果// close channel// v: 1, ok:true// v: 0, ok:false// channel is close 使用select处理多个channel 场景需要对多个通道进行同时处理，但只处理最先发生的channel时 原理select可以同时监控多个通道的情况，只处理未阻塞的case。当通道为nil时，对应的case永远为阻塞，无论读写。特殊关注：普通情况下，对nil的通道写操作是要panic的。 用法123456789// 分配job时，如果收到关闭的通知则退出，不分配jobfunc (h *Handler) handle(job *Job) &#123; select &#123; case h.jobCh&lt;-job: return case &lt;-h.stopCh: return &#125;&#125; 使用channel的声明控制读写权限 场景协程对某个通道只读或只写时 目的： 使代码更易读、更易维护， 防止只读协程对通道进行写数据，但通道已关闭，造成panic。 用法 如果协程对某个channel只有写操作，则这个channel声明为只写。 如果协程对某个channel只有读操作，则这个channe声明为只读。 12345678910111213141516171819// 只有generator进行对outCh进行写操作，返回声明// &lt;-chan int，可以防止其他协程乱用此通道，造成隐藏bugfunc generator(int n) &lt;-chan int &#123; outCh := make(chan int) go func()&#123; for i:=0;i&lt;n;i++&#123; outCh&lt;-i &#125; &#125;() return outCh&#125;// consumer只读inCh的数据，声明为&lt;-chan int// 可以防止它向inCh写数据func consumer(inCh &lt;-chan int) &#123; for x := range inCh &#123; fmt.Println(x) &#125;&#125; 使用缓冲channel增强并发 场景异步 原理有缓冲通道可供多个协程同时处理，在一定程度可提高并发性。 用法12345// 无缓冲ch1 := make(chan int)ch2 := make(chan int, 0)// 有缓冲ch3 := make(chan int, 1) 12345678910111213141516171819// 使用5个`do`协程同时处理输入数据func test() &#123; inCh := generator(100) outCh := make(chan int, 10) for i := 0; i &lt; 5; i++ &#123; go do(inCh, outCh) &#125; for r := range outCh &#123; fmt.Println(r) &#125;&#125;func do(inCh &lt;-chan int, outCh chan&lt;- int) &#123; for v := range inCh &#123; outCh &lt;- v * v &#125;&#125; 为操作加上超时 场景异步 原理使用select和time.After，看操作和定时器哪个先返回，处理先完成的，就达到了超时控制的效果 用法1234567891011121314151617func doWithTimeOut(timeout time.Duration) (int, error) &#123; select &#123; case ret := &lt;-do(): return ret, nil case &lt;-time.After(timeout): return 0, errors.New(\"timeout\") &#125;&#125;func do() &lt;-chan int &#123; outCh := make(chan int) go func() &#123; // do work &#125;() return outCh&#125; 使用close(ch)关闭所有下游协程 场景退出时，显示通知所有协程退出 原理所有读ch的协程都会收到close(ch)的信号 用法123456789101112131415161718func (h *Handler) Stop() &#123; close(h.stopCh) // 可以使用WaitGroup等待所有协程退出&#125;// 收到停止后，不再处理请求func (h *Handler) loop() error &#123; for &#123; select &#123; case req := &lt;-h.reqCh: go handle(req) case &lt;-h.stopCh: return &#125; &#125;&#125; 使用chan struct{}作为信号channel 场景使用channel传递信号，而不是传递数据时 原理没数据需要传递时，传递空struct 用法123456// 上例中的Handler.stopCh就是一个例子，stopCh并不需要传递任何数据// 只是要给所有协程发送退出的信号type Handler struct &#123; stopCh chan struct&#123;&#125; reqCh chan *Request&#125; 使用channel传递结构体的指针而非结构体 场景使用channel传递结构体数据时 原理channel本质上传递的是数据的拷贝，拷贝的数据越小传输效率越高，传递结构体指针，比传递结构体更高效 用法1234reqCh chan *Request// 好过reqCh chan Request 使用channel传递channel 场景使用场景有点多，通常是用来获取结果。 原理channel可以用来传递变量，channel自身也是变量，可以传递自己。 用法12345678910111213141516171819202122232425262728293031323334353637383940414243package mainimport ( \"fmt\" \"math/rand\" \"sync\" \"time\")func main() &#123; reqs := []int&#123;1, 2, 3, 4, 5, 6, 7, 8, 9&#125; // 存放结果的channel的channel outs := make(chan chan int, len(reqs)) var wg sync.WaitGroup wg.Add(len(reqs)) for _, x := range reqs &#123; o := handle(&amp;wg, x) outs &lt;- o &#125; go func() &#123; wg.Wait() close(outs) &#125;() // 读取结果，结果有序 for o := range outs &#123; fmt.Println(&lt;-o) &#125;&#125;// handle 处理请求，耗时随机模拟func handle(wg *sync.WaitGroup, a int) chan int &#123; out := make(chan int) go func() &#123; time.Sleep(time.Duration(rand.Intn(3)) * time.Second) out &lt;- a wg.Done() &#125;() return out&#125; 本文收集来源： http://lessisbetter.site/2019/01/20/golang-channel-all-usage/","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Golang","slug":"后端/Golang","permalink":"http://xuchen.youtuc.cn/categories/后端/Golang/"}],"tags":[{"name":"go基础","slug":"go基础","permalink":"http://xuchen.youtuc.cn/tags/go基础/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Golang","slug":"后端/Golang","permalink":"http://xuchen.youtuc.cn/categories/后端/Golang/"}]},{"title":"Golang sync 包的相关使用方法","slug":"Go/sync","date":"2019-08-28T13:35:29.000Z","updated":"2020-05-27T13:13:24.000Z","comments":true,"path":"2019/08/28/Go/sync/","link":"","permalink":"http://xuchen.youtuc.cn/2019/08/28/Go/sync/","excerpt":"","text":"为什么需要锁在并发的情况下，多个线程或协程同时去修改一个变量，可能会出现如下情况： 1234567891011121314151617181920212223242526package mainimport ( \"fmt\" \"sync\" \"time\")func main() &#123; var a = 0 // 启动 100 个协程，需要足够大 // var lock sync.Mutex for i := 0; i &lt; 100; i++ &#123; go func(idx int) &#123; // lock.Lock() // defer lock.Unlock() a += 1 fmt.Printf(\"goroutine %d, a=%d\\n\", idx, a) &#125;(i) &#125; // 等待 1s 结束主程序 // 确保所有协程执行完 time.Sleep(time.Second)&#125; 观察打印结果，是否出现 a 的值是相同的情况（未出现则重试或调大协程数），答案：是的。 显然这不是我们想要的结果。出现这种情况的原因是，协程依次执行：从寄存器读取 a 的值 -&gt; 然后做加法运算 -&gt; 最后写会寄存器。试想，此时一个协程取出 a 的值 3，正在做加法运算（还未写回寄存器）。同时另一个协程此时去取，取出了同样的 a 的值 3。最终导致的结果是，两个协程产出的结果相同，a 相当于只增加了 1。 所以，锁的概念就是，我正在处理 a（锁定），你们谁都别和我抢，等我处理完了（解锁），你们再处理。这样就实现了，同时处理 a 的协程只有一个，就实现了同步。 什么是互斥锁 Mutex？什么是互斥锁？它是锁的一种具体实现，有两个方法： 12func (m *Mutex) Lock()func (m *Mutex) Unlock() 在首次使用后不要复制该互斥锁。对一个未锁定的互斥锁解锁将会产生运行时错误。 一个互斥锁只能同时被一个 goroutine 锁定，其它 goroutine 将阻塞直到互斥锁被解锁（重新争抢对互斥锁的锁定）。如： 12345678910111213141516171819202122232425262728293031323334package mainimport ( \"fmt\" \"sync\" \"time\")func main() &#123; ch := make(chan struct&#123;&#125;, 2) var l sync.Mutex go func() &#123; l.Lock() defer l.Unlock() fmt.Println(\"goroutine1: 我会锁定大概 2s\") time.Sleep(time.Second * 2) fmt.Println(\"goroutine1: 我解锁了，你们去抢吧\") ch &lt;- struct&#123;&#125;&#123;&#125; &#125;() go func() &#123; fmt.Println(\"groutine2: 等待解锁\") l.Lock() defer l.Unlock() fmt.Println(\"goroutine2: 哈哈，我锁定了\") ch &lt;- struct&#123;&#125;&#123;&#125; &#125;() // 等待 goroutine 执行结束 for i := 0; i &lt; 2; i++ &#123; &lt;-ch &#125;&#125; 注意，平时所说的锁定，其实就是去锁定互斥锁，而不是说去锁定一段代码。也就是说，当代码执行到有锁的地方时，它获取不到互斥锁的锁定，会阻塞在那里，从而达到控制同步的目的。 什么是读写锁 RWMutex?那么什么是读写锁呢？它是针对读写操作的互斥锁，读写锁与互斥锁最大的不同就是可以分别对 读、写 进行锁定。一般用在大量读操作、少量写操作的情况： 12345func (rw *RWMutex) Lock()func (rw *RWMutex) Unlock()func (rw *RWMutex) RLock()func (rw *RWMutex) RUnlock() 由于这里需要区分读写锁定，我们这样定义： 读锁定（RLock），对读操作进行锁定 读解锁（RUnlock），对读锁定进行解锁 写锁定（Lock），对写操作进行锁定 写解锁（Unlock），对写锁定进行解锁 在首次使用之后，不要复制该读写锁。不要混用锁定和解锁，如：Lock 和 RUnlock、RLock 和 Unlock。因为对未读锁定的读写锁进行读解锁或对未写锁定的读写锁进行写解锁将会引起运行时错误。 如何理解读写锁呢？ 同时只能有一个 goroutine 能够获得写锁定。 同时可以有任意多个 gorouinte 获得读锁定。 同时只能存在写锁定或读锁定（读和写互斥）。 也就是说，当有一个 goroutine 获得写锁定，其它无论是读锁定还是写锁定都将阻塞直到写解锁；当有一个 goroutine 获得读锁定，其它读锁定任然可以继续；当有一个或任意多个读锁定，写锁定将等待所有读锁定解锁之后才能够进行写锁定。所以说这里的读锁定（RLock）目的其实是告诉写锁定：有很多人正在读取数据，你给我站一边去，等它们读（读解锁）完你再来写（写锁定）。 使用例子： 12345678910111213141516171819202122232425262728293031323334353637383940414243package mainimport ( \"fmt\" \"math/rand\" \"sync\")var count intvar rw sync.RWMutexfunc main() &#123; ch := make(chan struct&#123;&#125;, 10) for i := 0; i &lt; 5; i++ &#123; go read(i, ch) &#125; for i := 0; i &lt; 5; i++ &#123; go write(i, ch) &#125; for i := 0; i &lt; 10; i++ &#123; &lt;-ch &#125;&#125;func read(n int, ch chan struct&#123;&#125;) &#123; rw.RLock() fmt.Printf(\"goroutine %d 进入读操作...\\n\", n) v := count fmt.Printf(\"goroutine %d 读取结束，值为：%d\\n\", n, v) rw.RUnlock() ch &lt;- struct&#123;&#125;&#123;&#125;&#125;func write(n int, ch chan struct&#123;&#125;) &#123; rw.Lock() fmt.Printf(\"goroutine %d 进入写操作...\\n\", n) v := rand.Intn(1000) count = v fmt.Printf(\"goroutine %d 写入结束，新值为：%d\\n\", n, v) rw.Unlock() ch &lt;- struct&#123;&#125;&#123;&#125;&#125; WaitGroup 例子WaitGroup 用于等待一组 goroutine 结束，用法很简单。它有三个方法： 123func (wg *WaitGroup) Add(delta int)func (wg *WaitGroup) Done()func (wg *WaitGroup) Wait() Add 用来添加 goroutine 的个数。Done 执行一次数量减 1。Wait 用来等待结束： 1234567891011121314151617181920212223242526package mainimport ( \"fmt\" \"sync\" \"time\")func main() &#123; var wg sync.WaitGroup for i := 0; i &lt; 5; i++ &#123; // 计数加 1 wg.Add(1) go func(i int) &#123; // 计数减 1 defer wg.Done() time.Sleep(time.Second * time.Duration(i)) fmt.Printf(\"goroutine%d 结束\\n\", i) &#125;(i) &#125; // 等待执行结束 wg.Wait() fmt.Println(\"所有 goroutine 执行结束\")&#125; 注意，wg.Add() 方法一定要在 goroutine 开始前执行哦。 Cond 条件变量Cond 实现一个条件变量，即等待或宣布事件发生的 goroutines 的会合点，它会保存一个通知列表。基本思想是当某中状态达成，goroutine 将会等待（Wait）在那里，当某个时刻状态改变时通过通知的方式（Broadcast，Signal）的方式通知等待的 goroutine。这样，不满足条件的 goroutine 唤醒继续向下执行，满足条件的重新进入等待序列。 123456789type Cond struct &#123; noCopy noCopy // L is held while observing or changing the condition L Locker notify notifyList // 通知列表 checker copyChecker&#125; 1234func NewCond(l Locker) *Condfunc (c *Cond) Broadcast()func (c *Cond) Signal()func (c *Cond) Wait() Wait 方法、Signal 方法和 Broadcast 方法。它们分别代表了等待通知、单发通知和广播通知的操作。 我们来看一下 Wait 方法： 1234567func (c *Cond) Wait() &#123; c.checker.check() t := runtime_notifyListAdd(&amp;c.notify) c.L.Unlock() runtime_notifyListWait(&amp;c.notify, t) c.L.Lock()&#125; 它的操作为：加入到通知列表 -&gt; 解锁 L -&gt; 等待通知 -&gt; 锁定 L。其使用方法是： 123456c.L.Lock()for !condition() &#123; c.Wait()&#125;... make use of condition ...c.L.Unlock() 举个例子: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465// Package main provides ...package mainimport ( \"fmt\" \"sync\" \"time\")var count int = 4func main() &#123; ch := make(chan struct&#123;&#125;, 5) // 新建 cond var l sync.Mutex cond := sync.NewCond(&amp;l) for i := 0; i &lt; 5; i++ &#123; go func(i int) &#123; // 争抢互斥锁的锁定 cond.L.Lock() defer func() &#123; cond.L.Unlock() ch &lt;- struct&#123;&#125;&#123;&#125; &#125;() // 条件是否达成 for count &gt; i &#123; cond.Wait() fmt.Printf(\"收到一个通知 goroutine%d\\n\", i) &#125; fmt.Printf(\"goroutine%d 执行结束\\n\", i) &#125;(i) &#125; // 确保所有 goroutine 启动完成 time.Sleep(time.Millisecond * 20) // 锁定一下 fmt.Println(\"broadcast...\") cond.L.Lock() count -= 1 cond.Broadcast() cond.L.Unlock() time.Sleep(time.Second) fmt.Println(\"signal...\") cond.L.Lock() count -= 2 cond.Signal() cond.L.Unlock() time.Sleep(time.Second) fmt.Println(\"broadcast...\") cond.L.Lock() count -= 1 cond.Broadcast() cond.L.Unlock() for i := 0; i &lt; 5; i++ &#123; &lt;-ch &#125;&#125; Pool 临时对象池sync.Pool 可以作为临时对象的保存和复用的集合。其结构为： 1234567891011121314type Pool struct &#123; noCopy noCopy local unsafe.Pointer // local fixed-size per-P pool, actual type is [P]poolLocal localSize uintptr // size of the local array // New optionally specifies a function to generate // a value when Get would otherwise return nil. // It may not be changed concurrently with calls to Get. New func() interface&#123;&#125;&#125;func (p *Pool) Get() interface&#123;&#125;func (p *Pool) Put(x interface&#123;&#125;) 新键 Pool 需要提供一个 New 方法，目的是当获取不到临时对象时自动创建一个（不会主动加入到 Pool 中），Get 和 Put 方法都很好理解。 深入了解过 Go 的同学应该知道，Go 的重要组成结构为 M、P、G。Pool 实际上会为每一个操作它的 goroutine 相关联的 P 都生成一个本地池。如果从本地池 Get 对象的时候，本地池没有，则会从其它的 P 本地池获取。因此，Pool 的一个特点就是：可以把由其中的对象值产生的存储压力进行分摊。 它有着以下特点： Pool 中的对象在仅有 Pool 有着唯一索引的情况下可能会被自动删除（取决于下一次 GC 执行的时间）。 goroutines 协程安全，可以同时被多个协程使用。 GC 的执行一般会使 Pool 中的对象全部移除。 那么 Pool 都适用于什么场景呢？从它的特点来说，适用与无状态的对象的复用，而不适用与如连接池之类的。在 fmt 包中有一个很好的使用池的例子，它维护一个动态大小的临时输出缓冲区。 12345678910111213141516171819202122232425262728293031323334353637383940package mainimport ( \"bytes\" \"io\" \"os\" \"sync\" \"time\")var bufPool = sync.Pool&#123; New: func() interface&#123;&#125; &#123; return new(bytes.Buffer) &#125;,&#125;func timeNow() time.Time &#123; return time.Unix(1136214245, 0)&#125;func Log(w io.Writer, key, val string) &#123; // 获取临时对象，没有的话会自动创建 b := bufPool.Get().(*bytes.Buffer) b.Reset() b.WriteString(timeNow().UTC().Format(time.RFC3339)) b.WriteByte(' ') b.WriteString(key) b.WriteByte('=') b.WriteString(val) w.Write(b.Bytes()) // 将临时对象放回到 Pool 中 bufPool.Put(b)&#125;func main() &#123; Log(os.Stdout, \"path\", \"/search?q=flowers\")&#125;打印结果：2006-01-02T15:04:05Z path=/search?q=flowers Once 执行一次使用 sync.Once 对象可以使得函数多次调用只执行一次。其结构为： 123456type Once struct &#123; m Mutex done uint32&#125;func (o *Once) Do(f func()) 用 done 来记录执行次数，用 m 来保证保证仅被执行一次。只有一个 Do 方法，调用执行。","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Golang","slug":"后端/Golang","permalink":"http://xuchen.youtuc.cn/categories/后端/Golang/"}],"tags":[{"name":"go包详解","slug":"go包详解","permalink":"http://xuchen.youtuc.cn/tags/go包详解/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Golang","slug":"后端/Golang","permalink":"http://xuchen.youtuc.cn/categories/后端/Golang/"}]},{"title":"Go-context详解","slug":"Go/context详解","date":"2019-08-28T13:31:17.000Z","updated":"2020-05-27T13:15:31.000Z","comments":true,"path":"2019/08/28/Go/context详解/","link":"","permalink":"http://xuchen.youtuc.cn/2019/08/28/Go/context详解/","excerpt":"","text":"背景golang在1.6.2的时候还没有自己的context，在1.7的版本中就把golang.org/x/net/context包被加入到了官方的库中。golang 的 Context包，是专门用来简化对于处理单个请求的多个goroutine之间与请求域的数据、取消信号、截止时间等相关操作，这些操作可能涉及多个 API 调用。 比如有一个网络请求Request，每个Request都需要开启一个goroutine做一些事情，这些goroutine又可能会开启其他的goroutine。这样的话， 我们就可以通过Context，来跟踪这些goroutine，并且通过Context来控制他们的目的，这就是Go语言为我们提供的Context，中文可以称之为“上下文”。 另外一个实际例子是，在Go服务器程序中，每个请求都会有一个goroutine去处理。然而，处理程序往往还需要创建额外的goroutine去访问后端资源，比如数据库、RPC服务等。由于这些goroutine都是在处理同一个请求，所以它们往往需要访问一些共享的资源，比如用户身份信息、认证token、请求截止时间等。而且如果请求超时或者被取消后，所有的goroutine都应该马上退出并且释放相关的资源。这种情况也需要用Context来为我们取消掉所有goroutine 如果要使用可以通过 go get golang.org/x/net/context 命令获取这个包。 Context原理Context 的调用应该是链式的，通过WithCancel，WithDeadline，WithTimeout或WithValue派生出新的 Context.当父 Context 被取消时，其派生的所有 Context 都将取消. 通过context.WithXXX都将返回新的 Context 和 CancelFunc.调用 CancelFunc 将取消子代，移除父代对子代的引用，并且停止所有定时器.未能调用 CancelFunc 将泄漏子代，直到父代被取消或定时器触发.go vet工具检查所有流程控制路径上使用 CancelFuncs. 遵循规则遵循以下规则，以保持包之间的接口一致，并启用静态分析工具以检查上下文传播. 不要将 Contexts 放入结构体，相反context应该作为第一个参数传入，命名为ctx. func DoSomething（ctx context.Context，arg Arg）error { // ... use ctx ... } 即使函数允许，也不要传入nil的 Context.如果不知道用哪种 Context，可以使用context.TODO(). 使用context的Value相关方法只应该用于在程序和接口中传递的和请求相关的元数据，不要用它来传递一些可选的参数. 相同的 Context 可以传递给在不同的goroutine；Context 是并发安全的. Context包Context结构 123456789101112131415type Context interface &#123; // 在Context超时或取消时（即结束了）返回一个关闭的channel // 即如果当前Context超时或取消时，Done方法会返回一个channel，然后其他地方就可以通过判断Done方法是否有返回（channel），如果有则说明Context已结束 // 故其可以作为广播通知其他相关方本Context已结束，请做相关处理. Done() &lt;-chan struct&#123;&#125; // 返回Context取消的原因 Err() error // 返回Context的超时时间（超时返回场景） Deadline() (deadline time.Time, ok bool) // 值返回与键关联的值，如果没有则返回nil。 Value(key interface&#123;&#125;) interface&#123;&#125;&#125; 所有方法 1234567func Background() Contextfunc TODO() Contextfunc WithCancel(parent Context) (ctx Context, cancel CancelFunc)func WithDeadline(parent Context, deadline time.Time) (Context, CancelFunc)func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc)func WithValue(parent Context, key, val interface&#123;&#125;) Context 上面可以看到Context是一个接口，想要使用就得实现其方法.在context包内部已经为我们实现好了两个空的Context，可以通过调用Background()和TODO()方法获取.一般的将它们作为Context的根，往下派生. WithCancel 例子WithCancel 以一个新的 Done channel 返回一个父 Context 的拷贝. 12345678910111213func WithCancel(parent Context) (ctx Context, cancel CancelFunc) &#123; c := newCancelCtx(parent) propagateCancel(parent, &amp;c) return &amp;c, func() &#123; c.cancel(true, Canceled) &#125; &#125; // newCancelCtx returns an initialized cancelCtx. func newCancelCtx(parent Context) cancelCtx &#123; return cancelCtx&#123; Context: parent, done: make(chan struct&#123;&#125;), &#125; &#125; 此示例演示使用一个可取消的上下文，以防止 goroutine 泄漏.示例函数结束时，defer 调用 cancel 方法，gen goroutine 将返回而不泄漏. 12345678910111213141516171819202122232425262728293031323334package mainimport ( \"context\" \"fmt\")func main() &#123; gen := func(ctx context.Context) &lt;-chan int &#123; dst := make(chan int) n := 1 go func() &#123; for &#123; select &#123; case &lt;-ctx.Done(): return // returning not to leak the goroutine case dst &lt;- n: n++ &#125; &#125; &#125;() return dst &#125; ctx, cancel := context.WithCancel(context.Background()) defer cancel() // cancel when we are finished consuming integers for n := range gen(ctx) &#123; fmt.Println(n) if n == 5 &#123; break &#125; &#125;&#125; WithDeadline 例子12345678910func WithDeadline(parent Context, deadline time.Time) (Context, CancelFunc) &#123; if cur, ok := parent.Deadline(); ok &amp;&amp; cur.Before(deadline) &#123; // The current deadline is already sooner than the new one. return WithCancel(parent) &#125; c := &amp;timerCtx&#123; cancelCtx: newCancelCtx(parent), deadline: deadline, &#125; ...... 可以清晰的看到，当派生出的子 Context 的deadline在父Context之后，直接返回了一个父Context的拷贝.故语义上等效为父. WithDeadline 的最后期限调整为不晚于 d 返回父上下文的副本.如果父母的截止日期已经早于 d，WithDeadline （父，d） 是在语义上等效为父.返回的上下文完成的通道关闭的最后期限期满后，返回的取消函数调用时，或当父上下文完成的通道关闭，以先发生者为准. 看看官方的例子： 123456789101112131415161718192021222324package mainimport ( \"context\" \"fmt\" \"time\")func main() &#123; d := time.Now().Add(50 * time.Millisecond) ctx, cancel := context.WithDeadline(context.Background(), d) //即使ctx将会过期，还是最好将其调用 //在任何情况下都具有取消功能。 否则可能会使 //上下文及其父对象的生存时间超出了必要。 defer cancel() select &#123; case &lt;-time.After(1 * time.Second): fmt.Println(\"overslept\") case &lt;-ctx.Done(): fmt.Println(ctx.Err()) &#125;&#125; WithTimeout 例子123func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) &#123; return WithDeadline(parent, time.Now().Add(timeout)) &#125; 官方例子： 123456789101112131415161718192021package mainimport ( \"context\" \"fmt\" \"time\")func main() &#123; // Pass a context with a timeout to tell a blocking function that it // should abandon its work after the timeout elapses. ctx, cancel := context.WithTimeout(context.Background(), 50*time.Millisecond) defer cancel() select &#123; case &lt;-time.After(1 * time.Second): fmt.Println(\"overslept\") case &lt;-ctx.Done(): fmt.Println(ctx.Err()) // prints \"context deadline exceeded\" &#125;&#125; WithValue123456789func WithValue(parent Context, key, val interface&#123;&#125;) Context &#123; if key == nil &#123; panic(\"nil key\") &#125; if !reflect.TypeOf(key).Comparable() &#123; panic(\"key is not comparable\") &#125; return &amp;valueCtx&#123;parent, key, val&#125; &#125; WithValue 返回的父与键关联的值在 val 的副本. 使用上下文值仅为过渡进程和 Api 的请求范围的数据，而不是将可选参数传递给函数. 提供的键必须是可比性和应该不是字符串类型或任何其他内置的类型以避免包使用的上下文之间的碰撞.WithValue 用户应该定义自己的键的类型.为了避免分配分配给接口 {} 时，上下文键经常有具体类型结构 {}.另外，导出的上下文关键变量静态类型应该是一个指针或接口. 看看官方例子： 123456789101112131415161718192021222324package mainimport ( \"context\" \"fmt\")func main() &#123; type favContextKey string f := func(ctx context.Context, k favContextKey) &#123; if v := ctx.Value(k); v != nil &#123; fmt.Println(\"found value:\", v) return &#125; fmt.Println(\"key not found:\", k) &#125; k := favContextKey(\"language\") ctx := context.WithValue(context.Background(), k, \"Go\") f(ctx, k) f(ctx, favContextKey(\"color\"))&#125; 文章来源：https://mojotv.cn/2019/06/26/golang-context","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Golang","slug":"后端/Golang","permalink":"http://xuchen.youtuc.cn/categories/后端/Golang/"}],"tags":[],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Golang","slug":"后端/Golang","permalink":"http://xuchen.youtuc.cn/categories/后端/Golang/"}]},{"title":"RabbitMQ-基本概念","slug":"Amqp/RabbitMQ-入门","date":"2019-08-04T22:48:46.000Z","updated":"2021-05-04T08:26:08.000Z","comments":true,"path":"2019/08/04/Amqp/RabbitMQ-入门/","link":"","permalink":"http://xuchen.youtuc.cn/2019/08/04/Amqp/RabbitMQ-入门/","excerpt":"","text":"历史RabbitMQ是一个Erlang开发的AMQP（Advanced Message Queuing Protocol ）的开源实现。AMQP 的出现其实也是应了广大人民群众的需求，虽然在同步消息通讯的世界里有很多公开标准（如 Cobar）的 IIOP ，或者是 SOAP 等），但是在异步消息处理中却不是这样，只有大企业有一些商业实现（如微软的 MSMQ ，IBM 的 WebSphere MQ 等），因此，在 2006 年的 6 月，Cisco 、Red Hat、iMatix 等联合制定了 AMQP 的公开标准。 系统架构 RabbitMQ Server也叫Broker Server.它的角色就是维护一条从Producer到Consumer的路线，保证数据能够按照指定的方式传输。虽然这个保证也不是100%的保证，但是对于普通的应用来说这已经足够了。当然对于商业系统来说，可以再做一层数据一致性的guard，就可以彻底保证系统的一致性了。 Client P也叫Producer，数据的发送方。Create messages and publish (send) them to a Broker Server (RabbitMQ)。一个Message有两个部分：payload（有效载荷）和label（标签）。payload顾名思义就是传输的数据。label是exchange的名字或者说是一个tag，它描述了payload，而且RabbitMQ也是通过这个label来决定把这个Message发给哪个Consumer。AMQP仅仅描述了label，而RabbitMQ决定了如何使用这个label的规则。 Client C也叫Consumer，数据的接收方。Consumers attach to a Broker Server (RabbitMQ) and subscribe to a queue。把queue比作是一个有名字的邮箱。当有Message到达某个邮箱后，RabbitMQ把它发送给它的某个订阅者即Consumer。当然可能会把同一个Message发送给很多的Consumer。在这个Message中，只有payload，label已经被删掉了。对于Consumer来说，它是不知道谁发送的这个信息的,就是协议本身不支持。当然了,如果Producer发送的payload包含了Producer的信息就另当别论了。 对于一个数据从Producer到Consumer的正确传递，还有三个概念需要明确：exchanges, queues and bindings。 Exchanges ： 消息都会发送到交换器上 Queues ：队列是消息结束并由消费者接收的地方。 Bindings ：绑定是消息从交换器路由到特定队列的方式。 还有几个概念是上述图中没有标明的，那就是Connection（连接）和Channel（通道，频道）。 Connection就是一个TCP的连接。Producer和Consumer都是通过TCP连接到RabbitMQ Server的。以后我们可以看到，程序的起始处就是建立这个TCP连接。 Channel信道。它建立在上述的TCP连接中。数据流动都是在Channel中进行的。也就是说，一般情况是程序起始建立TCP连接，第二步就是建立这个Channel。 那么，为什么使用Channel，而不是直接使用TCP连接？ 对于OS来说，建立和关闭TCP连接是有代价的，频繁的建立关闭TCP连接对于系统的性能有很大的影响，而且TCP的连接数也有限制，这也限制了系统处理高并发的能力。但是，在TCP连接中建立Channel是没有上述代价的。对于Producer或者Consumer来说，可以并发的使用多个Channel进行Publish或者Receive。有实验表明，1s的数据可以Publish10K的数据包。当然对于不同的硬件环境，不同的数据包大小这个数据肯定不一样，但是我只想说明，对于普通的Consumer或者Producer来说，这已经足够了。如果不够用，你考虑的应该是如何细化SPLIT你的设计。 相关定义 Broker： 简单来说就是消息队列服务器实体 Exchange： 消息交换机，它指定消息按什么规则，路由到哪个队列 Queue： 消息队列载体，每个消息都会被投入到一个或多个队列 Binding： 绑定，它的作用就是把exchange和queue按照路由规则绑定起来 Routing Key： 路由关键字，exchange根据这个关键字进行消息投递 VHost： 虚拟主机，一个broker里可以开设多个vhost，用作不同用户的权限分离。 Producer： 消息生产者，就是投递消息的程序 Consumer： 消息消费者，就是接受消息的程序 Channel： 消息通道，在客户端的每个连接里，可建立多个channel，每个channel代表一个会话任务 基本概念QueueQueue（队列）是RabbitMQ的内部对象，用于存储消息，如下图表示。 RabbitMQ中的消息都只能存储在Queue中，生产者（下图中的P）生产消息并最终投递到Queue中，消费者（下图中的C）可以从Queue中获取消息并消费。 多个消费者可以订阅同一个Queue，这时Queue中的消息会被平均分摊给多个消费者进行处理，而不是每个消费者都收到所有的消息并处理。 Message ack(应答)在实际应用中，可能会发生消费者收到Queue中的消息，但没有处理完成就宕机（或出现其他意外）的情况，这种情况下就可能会导致消息丢失。为了避免这种情况发生，我们可以要求消费者在消费完消息后发送一个回执给RabbitMQ，RabbitMQ收到消息回执（Message acknowledgment）后才将该消息从Queue中移除。 如果RabbitMQ没有收到回执并检测到消费者的RabbitMQ连接断开，则RabbitMQ会将该消息发送给其他消费者（如果存在多个消费者）进行处理。这里不存在timeout，一个消费者处理消息时间再长也不会导致该消息被发送给其他消费者，除非它的RabbitMQ连接断开。 这里会产生另外一个问题，如果我们的开发人员在处理完业务逻辑后，忘记发送回执给RabbitMQ，这将会导致严重的bug——Queue中堆积的消息会越来越多。消费者重启后会重复消费这些消息并重复执行业务逻辑。 另外publish message 是没有ACK的。 Message durability(持久化)如果我们希望即使在RabbitMQ服务重启的情况下，也不会丢失消息，我们可以将Queue与Message都设置为可持久化的（durable），这样可以保证绝大部分情况下我们的RabbitMQ消息不会丢失。但依然解决不了小概率丢失事件的发生（比如RabbitMQ服务器已经接收到生产者的消息，但还没来得及持久化该消息时RabbitMQ服务器就断电了），如果我们需要对这种小概率事件也要管理起来，那么我们要用到事务。由于这里仅为RabbitMQ的简单介绍，所以这里将不讲解RabbitMQ相关的事务。 Prefetch count(类似平均分配)前面我们讲到如果有多个消费者同时订阅同一个Queue中的消息，Queue中的消息会被平摊给多个消费者。这时如果每个消息的处理时间不同，就有可能会导致某些消费者一直在忙，而另外一些消费者很快就处理完手头工作并一直空闲的情况。我们可以通过设置Prefetch count来限制Queue每次发送给每个消费者的消息数，比如我们设置prefetchCount=1，则Queue每次给每个消费者发送一条消息；消费者处理完这条消息后Queue会再给该消费者发送一条消息。 Exchange（交换器）在上一节我们看到生产者将消息投递到Queue中，实际上这在RabbitMQ中这种事情永远都不会发生。实际的情况是，生产者将消息发送到Exchange（交换器，下图中的X），由Exchange将消息路由到一个或多个Queue中（或者丢弃）。 Exchange是按照什么逻辑将消息路由到Queue的？这个将在Binding一节中介绍。RabbitMQ中的Exchange有四种类型，不同的类型有着不同的路由策略，这将在Exchange Types一节介绍。 Routing Key生产者在将消息发送给Exchange的时候，一般会指定一个Routing Key，来指定这个消息的路由规则，而这个Routing Key需要与Exchange Type及Binding key联合使用才能最终生效。 在Exchange Type与Binding key固定的情况下（在正常使用时一般这些内容都是固定配置好的），我们的生产者就可以在发送消息给Exchange时，通过指定Routing Key来决定消息流向哪里。 RabbitMQ为Routing Key设定的长度限制为 255 bytes。 BindingRabbitMQ中通过Binding将Exchange与Queue关联起来，这样RabbitMQ就知道如何正确地将消息路由到指定的Queue了。 Binding key在绑定（Binding）Exchange与Queue的同时，一般会指定一个Binding key。消费者将消息发送给Exchange时，一般会指定一个Routing Key。当Binding key与Routing Key相匹配时，消息将会被路由到对应的Queue中。这个将在Exchange Types章节会列举实际的例子加以说明。 在绑定多个Queue到同一个Exchange的时候，这些Binding允许使用相同的Binding key。 Binding key并不是在所有情况下都生效，它依赖于Exchange Type，比如fanout类型的Exchange就会无视Binding key，而是将消息路由到所有绑定到该Exchange的Queue。 Exchange TypesRabbitMQ常用的Exchange Type有fanout、direct、topic、headers这四种（AMQP规范里还提到两种Exchange Type，分别为system与自定义，这里不予以描述），下面分别进行介绍。 fanoutfanout类型的Exchange路由规则非常简单，它会把所有发送到该Exchange的消息路由到所有与它绑定的Queue中。 上图中，生产者（P）发送到Exchange（X）的所有消息都会路由到图中的两个Queue，并最终被两个消费者（C1与C2）消费。 directdirect类型的Exchange路由规则也很简单，它会把消息路由到那些Binding key与Routing key完全匹配的Queue中。 以上图的配置为例，我们以routingKey=”error”发送消息到Exchange，则消息会路由到Queue1（amqp.gen-S9b…，这是由RabbitMQ自动生成的Queue名称）和Queue2（amqp.gen-Agl…）；如果我们以Routing Key=”info”或routingKey=”warning”来发送消息，则消息只会路由到Queue2。如果我们以其他Routing Key发送消息，则消息不会路由到这两个Queue中。 topic前面讲到direct类型的Exchange路由规则是完全匹配Binding Key与Routing Key，但这种严格的匹配方式在很多情况下不能满足实际业务需求。topic类型的Exchange在匹配规则上进行了扩展，它与direct类型的Exchage相似，也是将消息路由到Binding Key与Routing Key相匹配的Queue中，但这里的匹配规则有些不同，它约定： Routing Key为一个句点号“.”分隔的字符串（我们将被句点号”. “分隔开的每一段独立的字符串称为一个单词），如”stock.usd.nyse”、”nyse.vmw”、”quick.orange.rabbit”。Binding Key与Routing Key一样也是句点号“. ”分隔的字符串。 Binding Key中可以存在两种特殊字符”*”与”#”，用于做模糊匹配，其中”*”用于匹配一个单词，”#”用于匹配多个单词（可以是零个）。 以上图中的配置为例，routingKey=”quick.orange.rabbit”的消息会同时路由到Q1与Q2，routingKey=”lazy.orange.fox”的消息会路由到Q1，routingKey=”lazy.brown.fox”的消息会路由到Q2，routingKey=”lazy.pink.rabbit”的消息会路由到Q2（只会投递给Q2一次，虽然这个routingKey与Q2的两个bindingKey都匹配）；routingKey=”quick.brown.fox”、routingKey=”orange”、routingKey=”quick.orange.male.rabbit”的消息将会被丢弃，因为它们没有匹配任何bindingKey。 headersheaders类型的Exchange不依赖于Routing Key与Binding Key的匹配规则来路由消息，而是根据发送的消息内容中的headers属性进行匹配。 在绑定Queue与Exchange时指定一组键值对；当消息发送到Exchange时，RabbitMQ会取到该消息的headers（也是一个键值对的形式），对比其中的键值对是否完全匹配Queue与Exchange绑定时指定的键值对。如果完全匹配则消息会路由到该Queue，否则不会路由到该Queue。 该类型的Exchange没有用到过（不过也应该很有用武之地），所以不做介绍。 RPCMQ本身是基于异步的消息处理，前面的示例中所有的生产者（P）将消息发送到RabbitMQ后不会知道消费者（C）处理成功或者失败（甚至连有没有消费者来处理这条消息都不知道）。 但实际的应用场景中，我们很可能需要一些同步处理，需要同步等待服务端将我的消息处理完成后再进行下一步处理。这相当于RPC（Remote Procedure Call，远程过程调用）。在RabbitMQ中也支持RPC。 RabbitMQ中实现RPC的机制是： 客户端发送请求（消息）时，在消息的属性（Message Properties，在AMQP协议中定义了14种properties，这些属性会随着消息一起发送）中设置两个值replyTo（一个Queue名称，用于告诉服务器处理完成后将通知我的消息发送到这个Queue中）和correlationId（此次请求的标识号，服务器处理完成后需要将此属性返还，客户端将根据这个id了解哪条请求被成功执行了或执行失败）。服务器端收到消息处理完后，将生成一条应答消息到replyTo指定的Queue，同时带上correlationId属性。客户端之前已订阅replyTo指定的Queue，从中收到服务器的应答消息后，根据其中的correlationId属性分析哪条请求被执行了，根据执行结果进行后续业务处理。","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"RabbitMQ","slug":"后端/RabbitMQ","permalink":"http://xuchen.youtuc.cn/categories/后端/RabbitMQ/"}],"tags":[{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://xuchen.youtuc.cn/tags/RabbitMQ/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"RabbitMQ","slug":"后端/RabbitMQ","permalink":"http://xuchen.youtuc.cn/categories/后端/RabbitMQ/"}]},{"title":"elasticsearch query 语法","slug":"Elasticsearch/SQL","date":"2019-07-28T09:51:14.000Z","updated":"2020-05-23T11:48:06.000Z","comments":true,"path":"2019/07/28/Elasticsearch/SQL/","link":"","permalink":"http://xuchen.youtuc.cn/2019/07/28/Elasticsearch/SQL/","excerpt":"","text":"SQL语法查询所有GET /Product/cpu/_search 123&#123; \"query\": &#123; \"match_all\": &#123;&#125; &#125;&#125; 单条件匹配和排序GET /Product/cpu/_search 12345678910&#123; \"query\": &#123; \"match\": &#123; \"name\":\"amd\" &#125; &#125;, \"sort\":[ &#123;\"price\":\"desc\"&#125; ] &#125; 查询指定的字段GET /Product/cpu/_search 1234&#123; \"query\": &#123; \"match_all\": &#123;&#125; &#125;, \"_source\":[\"name\",\"price\"]&#125; filter数据过滤GET /Product/cpu/_search例如：cpu名称包含amd,且价格大于1000 12345678910111213141516&#123; \"query\": &#123; \"bool\": &#123; \"must\":&#123; \"match\":&#123; \"name\": \"amd\" &#125; &#125;, \"filter\":&#123; \"range\":&#123; \"price\": &#123;\"gt\":1000&#125; &#125; &#125; &#125; &#125;&#125; full-text search 全文检索GET /Product/cpu/_search例如：desc字段内容去被倒排索引一一检索，包含任意词条的数据会被反驳 1234567&#123; \"query\": &#123; \"match\": &#123; \"desc\": \"cpu chaopin pianyi\" &#125; &#125;&#125; phrase search 短语检索GET /Product/cpu/_search例如：desc字段内容必须全匹配短语chaopin pianyi 1234567&#123; \"query\": &#123; \"match_phrase\": &#123; \"desc\": \"chaopin pianyi\" &#125; &#125;&#125; highlight search 高亮检索GET /Product/cpu/_search例如：desc字段内容必须全匹配短语chaopin pianyi 1234567&#123; \"query\": &#123; \"match_phrase\": &#123; \"desc\": \"chaopin pianyi\" &#125; &#125;&#125; 复合查询aggs 聚合查询GET /Product/cpu/_search 123456789&#123; \"aggs\": &#123; \"demo_tags\": &#123; \"terms\": &#123; \"field\": \"tag\" &#125; &#125; &#125;&#125; 设置字段为truePUT /product/cpu/_mapping 12345678&#123; \"properties\": &#123; \"tag\":&#123; \"type\": \"text\", \"fielddata\": true &#125; &#125;&#125; aggs 聚合分组求平均GET /Product/cpu/_search 12345678910111213141516&#123; \"aggs\": &#123; \"demo_tags\": &#123; \"terms\": &#123; \"field\": \"tag\" &#125;, \"aggs\": &#123; \"avg_demo_price\": &#123; \"avg\": &#123; \"field\": \"price\" &#125; &#125; &#125; &#125; &#125;&#125; aggs 聚合分组求平均后排序GET /Product/cpu/_search 1234567891011121314151617181920&#123; \"size\": 0, \"aggs\": &#123; \"demo_tags\": &#123; \"terms\": &#123; \"field\": \"tag\", \"order\": &#123; \"avg_price\": \"desc\" &#125; &#125;, \"aggs\": &#123; \"avg_demo_price\": &#123; \"avg\": &#123; \"field\": \"price\" &#125; &#125; &#125; &#125; &#125;&#125; aggs 范围区间聚合排序GET /Product/cpu/_search 123456789101112131415161718192021&#123; \"size\": 0, \"aggs\": &#123; \"group_tags\": &#123; \"range\": &#123; \"field\": \"\", \"ranges\": [ &#123; \"from\": 50, \"to\": 100 &#125; ] &#125;, \"aggs\": &#123; \"NAME\": &#123; \"AGG_TYPE\": &#123;&#125; &#125; &#125; &#125; &#125;&#125;","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"elasticsearch","slug":"后端/elasticsearch","permalink":"http://xuchen.youtuc.cn/categories/后端/elasticsearch/"}],"tags":[{"name":"elasticsearch","slug":"elasticsearch","permalink":"http://xuchen.youtuc.cn/tags/elasticsearch/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"elasticsearch","slug":"后端/elasticsearch","permalink":"http://xuchen.youtuc.cn/categories/后端/elasticsearch/"}]},{"title":"elasticsearch核心概念(初版)","slug":"Elasticsearch/基本概念","date":"2019-07-24T09:51:14.000Z","updated":"2021-05-04T08:26:08.000Z","comments":true,"path":"2019/07/24/Elasticsearch/基本概念/","link":"","permalink":"http://xuchen.youtuc.cn/2019/07/24/Elasticsearch/基本概念/","excerpt":"","text":"核心概念Node 与 ClusterElastic 本质上是一个分布式数据库，允许多台服务器协同工作，每台服务器可以运行多个 Elastic 实例。 单个 Elastic 实例称为一个节点（node）。一组节点构成一个集群（cluster）。 IndexElastic 会索引所有字段，经过处理后写入一个反向索引（Inverted Index）。查找数据的时候，直接查找该索引。 所以，Elastic 数据管理的顶层单位就叫做 Index（索引）。它是单个数据库的同义词。每个 Index （即数据库）的名字必须是小写。 下面的命令可以查看当前节点的所有 Index。 1$ curl -X GET &apos;http://localhost:9200/_cat/indices?v&apos; DocumentIndex 里面单条的记录称为 Document（文档）。许多条 Document 构成了一个 Index。 Document 使用 JSON 格式表示，下面是一个例子。 12345&#123; &quot;user&quot;: &quot;张三&quot;, &quot;title&quot;: &quot;工程师&quot;, &quot;desc&quot;: &quot;数据库管理&quot;&#125; 同一个 Index 里面的 Document，不要求有相同的结构（scheme），但是最好保持相同，这样有利于提高搜索效率。 TypeDocument 可以分组，比如weather这个 Index 里面，可以按城市分组（北京和上海），也可以按气候分组（晴天和雨天）。这种分组就叫做 Type，它是虚拟的逻辑分组，用来过滤 Document。 不同的 Type 应该有相似的结构（schema），举例来说，id字段不能在这个组是字符串，在另一个组是数值。这是与关系型数据库的表的一个区别。性质完全不同的数据（比如products和logs）应该存成两个 Index，而不是一个 Index 里面的两个 Type（虽然可以做到）。 下面的命令可以列出每个 Index 所包含的 Type。 1$ curl &apos;localhost:9200/_mapping?pretty=true&apos; es与数据库类比 es 数据库 document 行 type 表 index 数据库 share（primary 数据分片) &amp; replica(replica share数据副本) 深入理解1）一个index包含多个share2）每个share都是一个最小工作单元，包含完整的lucene实例，完整的建立索引和处理业务能力3）增加节点时，share会自动在node中负载4）每个document只存在一个share和其对应的replica中，不可能存在多个share中5）replica数据副本，负责容错和负载6）primary share在创建index的时候就已经确定了，replica share可以随时更改7）primary share默认是5个，每个primary share有1个replica share,所以一个节点默认5个primary share和5个replica share8）primary share和自己的replica share不能放在同一个节点上，避免宕机，但是可以同其他rimary share的replica share在同一个节点 document删除（或者全量替换） 删除的时候只是打了标记，并没有实时删除，es后台会在到达一定量的时候物理删除 全量替换也是打了标记，所以数据的version会变 version并发版本控制和乐观锁什么是partial update &amp;&amp; 实现原理POST /index/type/id/_update 12345&#123; \"doc\": &#123; \"要修改的几个少数filed,不需要全量的数据\" &#125;&#125; 内部原理：其实es跟传统全量替换一样，只不过是ES内部share完成 获取到document 将传过来的filed更新到document的json中，存放在内存中 将老的document标记为删除 将新的document创建出来优点： 由于是内部完成，减少网络请求开销，一瞬间完成 减少并发造成的问题 bulk语法 调优仅索引层面调优手段： 1.1、设计阶段调优1）根据业务增量需求，采取基于日期模板创建索引，通过roll over API滚动索引；2）使用别名进行索引管理；3）每天凌晨定时对索引做force_merge操作，以释放空间；4）采取冷热分离机制，热数据存储到SSD，提高检索效率；冷数据定期进行shrink操作，以缩减存储；5）采取curator进行索引的生命周期管理；6）仅针对需要分词的字段，合理的设置分词器；7）Mapping阶段充分结合各个字段的属性，是否需要检索、是否需要存储等。 1.2、写入调优1）写入前副本数设置为0；2）写入前关闭refresh_interval设置为-1，禁用刷新机制；3）写入过程中：采取bulk批量写入；4）写入后恢复副本数和刷新间隔；5）尽量使用自动生成的id。 1.3、查询调优1）禁用wildcard；2）禁用批量terms（成百上千的场景）；3）充分利用倒排索引机制，能keyword类型尽量keyword；4）数据量大时候，可以先基于时间敲定索引再检索；5）设置合理的路由机制。 ES中的倒排索引是什么？传统的检索方式是通过文章，逐个遍历找到对应关键词的位置。倒排索引，是通过分词策略，形成了词和文章的映射关系表，也称倒排表，这种词典 + 映射表即为倒排索引。 其中词典中存储词元，倒排表中存储该词元在哪些文中出现的位置。有了倒排索引，就能实现 O(1) 时间复杂度的效率检索文章了，极大的提高了检索效率。倒排索引的底层实现是基于：FST（Finite State Transducer）数据结构。 Lucene 从 4+ 版本后开始大量使用的数据结构是 FST。FST 有两个优点：1）空间占用小。通过对词典中单词前缀和后缀的重复利用，压缩了存储空间；2）查询速度快。O(len(str)) 的查询时间复杂度。 ES是如何实现master选举的？ 前置条件：1）只有是候选主节点（master：true）的节点才能成为主节点。2）最小主节点数（min_master_nodes）的目的是防止脑裂。 选举流程大致描述如下：第一步：确认候选主节点数达标，elasticsearch.yml 设置的值 discovery.zen.minimum_master_nodes;第二步：对所有候选主节点根据nodeId字典排序，每次选举每个节点都把自己所知道节点排一次序，然后选出第一个（第0位）节点，暂且认为它是master节点。第三步：如果对某个节点的投票数达到一定的值（候选主节点数n/2+1）并且该节点自己也选举自己，那这个节点就是master。否则重新选举一直到满足上述条件。 如何解决ES集群的脑裂问题所谓集群脑裂，是指 Elasticsearch 集群中的节点（比如共 20 个），其中的 10 个选了一个 master，另外 10 个选了另一个 master 的情况。 当集群 master 候选数量不小于 3 个时，可以通过设置最少投票通过数量（discovery.zen.minimum_master_nodes）超过所有候选节点一半以上来解决脑裂问题；当候选数量为两个时，只能修改为唯一的一个 master 候选，其他作为 data 节点，避免脑裂问题。 详细描述一下ES索引文档的过程？ 第一步：客户端向集群某节点写入数据，发送请求。（如果没有指定路由/协调节点，请求的节点扮演协调节点的角色。）第二步：协调节点接受到请求后，默认使用文档 ID 参与计算（也支持通过 routing），得到该文档属于哪个分片。随后请求会被转到另外的节点。路由算法：根据文档id或路由计算目标的分片id shard = hash(document_id) % (num_of_primary_shards)第三步：当分片所在的节点接收到来自协调节点的请求后，会将请求写入到 Memory Buffer，然后定时（默认是每隔 1 秒）写入到F ilesystem Cache，这个从 Momery Buffer 到 Filesystem Cache 的过程就叫做 refresh；第四步：当然在某些情况下，存在 Memery Buffer 和 Filesystem Cache 的数据可能会丢失，ES 是通过 translog 的机制来保证数据的可靠性的。其实现机制是接收到请求后，同时也会写入到 translog 中，当 Filesystem cache 中的数据写入到磁盘中时，才会清除掉，这个过程叫做 flush；第五步：在 flush 过程中，内存中的缓冲将被清除，内容被写入一个新段，段的 fsync 将创建一个新的提交点，并将内容刷新到磁盘，旧的 translog 将被删除并开始一个新的 translog。第六步：flush 触发的时机是定时触发（默认 30 分钟）或者 translog 变得太大（默认为 512 M）时。 在并发情况下，ES如果保证读写一致？可以通过版本号使用乐观并发控制，以确保新版本不会被旧版本覆盖，由应用层来处理具体的冲突；另外对于写操作，一致性级别支持quorum/one/all，默认为quorum，即只有当大多数分片可用时才允许写操作。但即使大多数可用，也可能存在因为网络等原因导致写入副本失败，这样该副本被认为故障，分片将会在一个不同的节点上重建。对于读操作，可以设置replication为sync(默认)，这使得操作在主分片和副本分片都完成后才会返回；如果设置replication为async时，也可以通过设置搜索请求参数_preference为primary来查询主分片，确保文档是最新版本。 lucence内部结构","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"elasticsearch","slug":"后端/elasticsearch","permalink":"http://xuchen.youtuc.cn/categories/后端/elasticsearch/"}],"tags":[{"name":"面试","slug":"面试","permalink":"http://xuchen.youtuc.cn/tags/面试/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"elasticsearch","slug":"后端/elasticsearch","permalink":"http://xuchen.youtuc.cn/categories/后端/elasticsearch/"}]},{"title":"protobuf","slug":"protobuf","date":"2019-07-12T09:52:39.000Z","updated":"2020-05-18T05:44:56.000Z","comments":true,"path":"2019/07/12/protobuf/","link":"","permalink":"http://xuchen.youtuc.cn/2019/07/12/protobuf/","excerpt":"","text":"grpc与protobufProtobuf 协议详解各语言类型.proto TypeC++ TypeJava TypePython Type[2]Go TypeRuby TypeC# TypePHP TypeDart Typedoubledoubledoublefloatfloat64Floatdoublefloatdoublefloatfloatfloatfloatfloat32Floatfloatfloatdoubleint32int32intintint32Fixnum or Bignum (as required)intintegerintint64int64longint/long[3]int64Bignumlonginteger/string[5]Int64uint32uint32int[1]int/long[3]uint32Fixnum or Bignum (as required)uintintegerintuint64uint64long[1]int/long[3]uint64Bignumulonginteger/string[5]Int64sint32int32intintint32Fixnum or Bignum (as required)intintegerintsint64int64longint/long[3]int64Bignumlonginteger/string[5]Int64fixed32uint32int[1]int/long[3]uint32Fixnum or Bignum (as required)uintintegerintfixed64uint64long[1]int/long[3]uint64Bignumulonginteger/string[5]Int64sfixed32int32intintint32Fixnum or Bignum (as required)intintegerintsfixed64int64longint/long[3]int64Bignumlonginteger/string[5]Int64boolboolbooleanboolboolTrueClass/FalseClassboolbooleanboolstringstringStringstr/unicode[4]stringString (UTF-8)stringstringStringbytesstringByteStringstr[]byteString (ASCII-8BIT)ByteStringstringList&lt;int&gt; Protobuf 安装 下载地址:https://github.com/protocolbuffers/protobuf 安装1234567tar -xvf protobufcd protobuf./configure --prefix=/usr/local/protobufmake &amp;&amp; make install proto文件123456789101112131415161718syntax = &quot;proto3&quot;; //协议package pb; //生成的文件所在包// 服务Greeter定义service Greeter &#123; //方法 rpc SayHello (HelloRequest) returns (HelloReply) &#123;&#125;&#125;// 请求参数message HelloRequest &#123; string name = 1;&#125;// 响应参数message HelloReply &#123; string message = 1;&#125; 生成对应语言文件1protoc --go_out=plugins=grpc:. test.proto","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Golang","slug":"后端/Golang","permalink":"http://xuchen.youtuc.cn/categories/后端/Golang/"}],"tags":[],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Golang","slug":"后端/Golang","permalink":"http://xuchen.youtuc.cn/categories/后端/Golang/"}]},{"title":"前后端开发规范","slug":"前后端开发规范","date":"2019-07-08T11:39:15.000Z","updated":"2020-05-18T05:44:56.000Z","comments":true,"path":"2019/07/08/前后端开发规范/","link":"","permalink":"http://xuchen.youtuc.cn/2019/07/08/前后端开发规范/","excerpt":"","text":"前后端API对接规范 版本 编写人 编写时间 更新内容 1.0.0 Abner 2019年7月8日 初稿 由前端(APP端)和后端一起协定接口规范的内容, 确定每一个接口的地址(URL), 输入(request)和输出(response), 必要的时候详细注释每一个字段的含义和数据类型. 具体需要定义哪些接口, 可以按照下面的思路来整理 资源接口：系统涉及到哪些资源, 按照 RESTful 方式定义的细粒度接口 操作接口：页面涉及的操作，比如抽奖，领取奖品等，也可以RESTFul 方式定义 页面接口：页面涉及到接口太多，如果是一个个调用会增加频繁请求，对影响用户感知（首屏加载）和性能的尽量做成聚合接口,对并发量较大的接口，建议采用随机延迟加载方式。 接口协商要点 返回统一的数据结构 查询不到时，即空数据情况下的返回的数据格式 接口调用业务失败的常用错误码 接口是否有需要授权 接口是否有Nginx缓存或者CDN缓存 返回数据中包含图片，是否包含完整的URL图片地址 部分:/path/default.jpg 完整:http://res.kelala.com/path/default.jpg 返回数据中的日期格式，是使用时间戳还是格式化好的文字 一些语言unix时间戳是千分位，需要注意 返回给前端的格式化时间应该统一标准，如：2019年7月8日 13:31:24 或者 2019-07-08 13:31:24 长整型，如Java的long,mongodb的自增id等，返回给前端产生的数字溢出，建议采用字符串类型 分页信息定义 分页参数page 分页大小page_size 总记录数 total 当前页 current_page 后端接口通用规范接口文档标准接口数据文档必须包含以下内容 接口URL地址 HTTP Method(GET\\POST\\PUT等) 请求参数名称、类型、描述、必选、可选标识 接口返回数据格式、数据字段的意义、类型 接口正常响应格式 接口异常响应内容格式（如果有） 特别注意事项： 服务端接口出现任何变更开发负责人必须通知对应的接口使用人，接口变更未及时通知使用方; 接口文档中，除声明HTTP METHOD方法外，还需要区分标明QueryString参数和POST参数，防止调用方出现浏览器缓存、服务端缓存问题。 如果接口有缓存设计（CDN缓存、Nginx缓存等），需要在接口文档中标明有缓存，调用方不可使用诸如加随机数参数等参数方式形成缓存穿透，避免此方式造成服务端性能问题和出现故障的。 数据基础格式标准数据输出格式如下，所有接口必须按照次格式 12345&#123; error:0,//错误码 ,error=0 表示无错误，error&gt;0表示有错误 message:\"\",// 错误详细可读信息 data:&#123;&#125;// 数据字段，内容由接口提供人定义&#125; 关于错误码取值范围定义 错误码固定方法： 如小于1000以下为保留位数，400错误，500错误，419错误等; 大于1000的表示公共API调用失败，比如授权1401，第三方系统调用失败1690等; 大于10000的表示业务或者项目区分，比如模块A 1000019999 区分错误码，模块B 2000029999区分 关于状态位的定义不允许要求数据使用方在代码里面写死映射关系，应该采取后端返回，例如： 1234567891011121314151617181920&#123; \"data\": &#123; \"status\": 0, \"status_text\": \"未审核\" &#125;&#125;&#123; \"data\": &#123; \"status\": 1, \"status_text\": \"审核中\" &#125;&#125;&#123; \"data\": &#123; \"status\": 2, \"status_text\": \"审核通过\" &#125;&#125; 数据字段内容规范 ：安全警告 包含html代码的数据，为了防止跨站攻击，服务端默认对数据内容全部进行HTML编码，编码标准请参考：转码说明，数据使用方需要对相关数据进行对应编码字符进行显示处理 过滤涉及业务安全和数据敏感的字段，例如参与人数，中奖概率，中奖限制等字段 样板示例 接口名称：获取分类用户(标准请求) URL: http://www.youdomain.com/v1/user/getCategoryUserList HTTP METHOD: GET （Content-Type: application/x-www-form-urlencoded） 缓存：无 鉴权：无 请求参数: 请求字段 类型 是否必须 描述 cate_id int 是 分类id 响应： 成功 1234567891011121314151617&#123; \"error\": 0, \"message\": \"校验通过\", \"data\": &#123; \"cate\": &#123; \"1\": &#123; \"cate_id\": \"1\", // 分类id \"cate_name\": \"二次元爱好者\", // 分类名称 \"short_name\": \"erciy\", // 分类url名称 \"orderdisplay\": \"2\", // 分类排序 \"update_time\": \"1484550058\", // 创建时间 &#125;, ...... &#125; &#125;&#125; 失败： 12345&#123; \"error\": 10001, \"message\": \"参数错误\", \"data\": &#123;&#125;&#125; 接口名称：新增用户（json对象提交） URL: http://www.youdomain.com/v1/user/addUser HTTP METHOD: POST （Content-Type: application/json; charset=utf-8） 缓存：无 鉴权：有 请求字段 类型 是否必须 描述 x-csrf-token string 是 鉴权参数 请求参数: 请求字段 类型 是否必须 描述 username string 是 用户名 password string 是 用户密码 响应： 成功 12345&#123; \"error\": 0, \"message\": \"提交成功\", \"data\": &#123;&#125;&#125;","categories":[{"name":"前端","slug":"前端","permalink":"http://xuchen.youtuc.cn/categories/前端/"},{"name":"API规范","slug":"前端/API规范","permalink":"http://xuchen.youtuc.cn/categories/前端/API规范/"}],"tags":[],"keywords":[{"name":"前端","slug":"前端","permalink":"http://xuchen.youtuc.cn/categories/前端/"},{"name":"API规范","slug":"前端/API规范","permalink":"http://xuchen.youtuc.cn/categories/前端/API规范/"}]},{"title":"Docker-Compose详解","slug":"Tools/Docker/Docker-compose","date":"2019-06-05T14:23:51.000Z","updated":"2020-05-18T05:44:56.000Z","comments":true,"path":"2019/06/05/Tools/Docker/Docker-compose/","link":"","permalink":"http://xuchen.youtuc.cn/2019/06/05/Tools/Docker/Docker-compose/","excerpt":"","text":"Compose中有两个重要的概念： 服务(service)：一个应用的容器，实际上可以包括若干个运行相同镜像的容器实例。 项目(project)：由一组关联的应用容器组成的一个完整的业务单元，在docker-compose.yml文件中定义。 安装和卸载123456789pip install -U docker-compose二进制包安装方法curl -L https://github.com/docker/compose/releases/download/1.23.0/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-composechmod +x /usr/local/bin/docker-compose官方安装方法curl -L https://github.com/docker/compose/releases/download/1.23.0/run.sh &gt; /usr/local/bin/docker-composechmod +x /usr/local/bin/docker-compose 命令说明123456789101112131415161718192021222324252627282930313233343536373839404142434445464748$ docker-composeDefine and run multi-container applications with Docker.Usage: docker-compose [-f &lt;arg&gt;...] [options] [COMMAND] [ARGS...] docker-compose -h|--helpOptions: -f, --file FILE Specify an alternate compose file (default: docker-compose.yml) -p, --project-name NAME Specify an alternate project name (default: directory name) --verbose Show more output -v, --version Print version and exit -H, --host HOST Daemon socket to connect to --tls Use TLS; implied by --tlsverify --tlscacert CA_PATH Trust certs signed only by this CA --tlscert CLIENT_CERT_PATH Path to TLS certificate file --tlskey TLS_KEY_PATH Path to TLS key file --tlsverify Use TLS and verify the remote --skip-hostname-check Don't check the daemon's hostname against the name specified in the client certificate (for example if your docker host is an IP address)Commands: build Build or rebuild services bundle Generate a Docker bundle from the Compose file config Validate and view the compose file create Create services down Stop and remove containers, networks, images, and volumes events Receive real time events from containers exec Execute a command in a running container help Get help on a command kill Kill containers logs View output from containers pause Pause services port Print the public port for a port binding ps List containers pull Pulls service images push Push service images restart Restart services rm Remove stopped containers run Run a one-off command scale Set number of containers for a service start Start services stop Stop services unpause Unpause services up Create and start containers version Show the Docker-Compose version information docker-compose.yml参考每个docker-compose.yml必须定义image或者build中的一个，其它的是可选的。 image指定镜像tag或者ID。示例： 12345image: redisimage: ubuntu:14.04image: tutum/influxdbimage: example-registry.com:4000/postgresqlimage: a4bc65fd 注意，在version 1里同时使用image和build是不允许的，version 2则可以，如果同时指定了两者，会将build出来的镜像打上名为image标签。 build用来指定一个包含Dockerfile文件的路径。一般是当前目录.。Fig将build并生成一个随机命名的镜像。 注意，在version 1里bulid仅支持值为字符串。version 2里支持对象格式。 1234567build: ./dirbuild: context: ./dir dockerfile: Dockerfile-alternate args: buildno: 1 context为路径，dockerfile为需要替换默认docker-compose的文件名，args为构建(build)过程中的环境变量，用于替换Dockerfile里定义的ARG参数，容器中不可用。示例：Dockerfile: 12345ARG buildnoARG passwordRUN echo &quot;Build number: $buildno&quot;RUN script-requiring-password.sh &quot;$password&quot; docker-compose.yml: 1234567891011build: context: . args: buildno: 1 password: secretbuild: context: . args: - buildno=1 - password=secret command用来覆盖缺省命令。示例： 1command: bundle exec thin -p 3000 command也支持数组形式： 1command: [bundle, exec, thin, -p, 3000] links用于链接另一容器服务，如需要使用到另一容器的mysql服务。可以给出服务名和别名；也可以仅给出服务名，这样别名将和服务名相同。同docker run –link。示例： 1234links: - db - db:mysql - redis 使用了别名将自动会在容器的/etc/hosts文件里创建相应记录： 123172.17.2.186 db172.17.2.186 mysql172.17.2.187 redis 所以我们在容器里就可以直接使用别名作为服务的主机名。 ports用于暴露端口。同docker run -p。示例： 12345ports: - &quot;3000&quot; - &quot;8000:8000&quot; - &quot;49100:22&quot; - &quot;127.0.0.1:8001:8001&quot; exposeexpose提供container之间的端口访问，不会暴露给主机使用。同docker run –expose。 123expose: - &quot;3000&quot; - &quot;8000&quot; volumes挂载数据卷。同docker run -v。示例： 1234volumes: - /var/lib/mysql - cache/:/tmp/cache - ~/configs:/etc/configs/:ro volumes_from挂载数据卷容器，挂载是容器。同docker run –volumes-from。示例： 12345volumes_from: - service_name - service_name:ro - container:container_name - container:container_name:rw container:container_name格式仅支持version 2。 environment添加环境变量。同docker run -e。可以是数组或者字典格式： 1234567environment: RACK_ENV: development SESSION_SECRET:environment: - RACK_ENV=development - SESSION_SECRET depends_on用于指定服务依赖，一般是mysql、redis等。指定了依赖，将会优先于服务创建并启动依赖。 links也可以指定依赖。 external_links链接搭配docker-compose.yml文件或者Compose之外定义的服务，通常是提供共享或公共服务。格式与links相似： 1234external_links: - redis_1 - project_db_1:mysql - project_db_1:postgresql 注意，external_links链接的服务与当前服务必须是同一个网络环境。 extra_hosts添加主机名映射。 123extra_hosts: - &quot;somehost:162.242.195.82&quot; - &quot;otherhost:50.31.209.229&quot; 将会在/etc/hosts创建记录： 12162.242.195.82 somehost50.31.209.229 otherhost extends继承自当前yml文件或者其它文件中定义的服务，可以选择性的覆盖原有配置。 123extends: file: common.yml service: webapp service必须有，file可选。service是需要继承的服务，例如web、database。 net设置网络模式。同docker的–net参数。 1234net: &quot;bridge&quot;net: &quot;none&quot;net: &quot;container:[name or id]&quot;net: &quot;host&quot; dns自定义dns服务器。 1234dns: 8.8.8.8dns: - 8.8.8.8 - 9.9.9.9 其他1234567cpu_shares, cpu_quota,cpuset, domainname,hostname, ipc, mac_address, mem_limit, memswap_limit, privileged, read_only, restart, shm_size, stdin_open, tty, user, working_dir 这些命令都是单个值，含义请参考docker run 1234567891011121314151617181920212223cpu_shares: 73cpu_quota: 50000cpuset: 0,1user: postgresqlworking_dir: /codedomainname: foo.comhostname: fooipc: hostmac_address: 02:42:ac:11:65:43mem_limit: 1000000000mem_limit: 128Mmemswap_limit: 2000000000privileged: truerestart: alwaysread_only: trueshm_size: 64Mstdin_open: truetty: true","categories":[{"name":"工具","slug":"工具","permalink":"http://xuchen.youtuc.cn/categories/工具/"},{"name":"Docker","slug":"工具/Docker","permalink":"http://xuchen.youtuc.cn/categories/工具/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://xuchen.youtuc.cn/tags/Docker/"}],"keywords":[{"name":"工具","slug":"工具","permalink":"http://xuchen.youtuc.cn/categories/工具/"},{"name":"Docker","slug":"工具/Docker","permalink":"http://xuchen.youtuc.cn/categories/工具/Docker/"}]},{"title":"ssh常用脚本","slug":"ssh-script","date":"2019-05-28T22:15:11.000Z","updated":"2021-05-04T08:26:08.000Z","comments":true,"path":"2019/05/28/ssh-script/","link":"","permalink":"http://xuchen.youtuc.cn/2019/05/28/ssh-script/","excerpt":"","text":"ssh登陆脚本1.main.sh12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576#!/bin/bashdirec=`dirname $0`function color()&#123; blue=\"\\033[0;36m\" red=\"\\033[0;31m\" green=\"\\033[0;32m\" close=\"\\033[m\" case $1 in blue) echo -e \"$blue $2 $close\" ;; red)AA echo -e \"$red $2 $close\" ;; green) echo -e \"$green $2 $close\" ;; *) echo \"Input color error!!\" ;; esac&#125;function copyright()&#123; echo \"#####################\" color blue \" SSH Login Platform \" echo \"#####################\" echo&#125;function underline()&#123; echo \"-----------------------------------------\"&#125;function main()&#123;while [ True ];do echo \"序号 | 主机 | 说明\" underline awk 'BEGIN &#123;FS=\":\"&#125; &#123;printf(\"\\033[0;31m% 3s \\033[m | %15s | %s\\n\",$1,$2,$6)&#125;' $direc/config.lst underline read -p '[*] 选择主机: ' number pw=\"$direc/config.lst\" ipaddr=$(awk -v num=$number 'BEGIN &#123;FS=\":\"&#125; &#123;if($1 == num) &#123;print $2&#125;&#125;' $pw) port=$(awk -v num=$number 'BEGIN &#123;FS=\":\"&#125; &#123;if($1 == num) &#123;print $3&#125;&#125;' $pw) username=$(awk -v num=$number 'BEGIN &#123;FS=\":\"&#125; &#123;if($1 == num) &#123;print $4&#125;&#125;' $pw) passwd=$(awk -v num=$number 'BEGIN &#123;FS=\":\"&#125; &#123;if($1 == num) &#123;print $5&#125;&#125;' $pw) case $number in [0-9]|[0-9][0-9]|[0-9][0-9][0-9]) echo $passwd | grep -q \".pem$\" RETURN=$? if [[ $RETURN == 0 ]];then ssh -i $direc/keys/$passwd $username@$ipaddr -p $port echo \"ssh -i $direc/$passwd $username@$ipaddr -p $port\" else expect -f $direc/login.exp $ipaddr $username $passwd $port fi ;; \"q\"|\"quit\") exit ;; *) echo \"Input error!!\" ;; esacdone&#125;copyrightmain 2.login.exp12345678910111213#!/usr/bin/expect -fset TARGET [lindex $argv 0]set USER [lindex $argv 1]set PASSWD [lindex $argv 2]set PORT [lindex $argv 3]set timeout 10spawn ssh $USER@$TARGET -p $PORTexpect &#123; \"*yes/no\" &#123;send \"yes\\r\"; exp_continue&#125; \"*password:\" &#123;send \"$PASSWD\\r\"&#125;&#125;interact 3.config.lst12&#123;1序号&#125;:&#123;2服务器ip&#125;:&#123;3端口号&#125;:&#123;4用户名&#125;:&#123;5密码&#125;：&#123;6标签&#125;1:ip_address:port:username:password:tag_name 查询日志访问topN的请求1awk '&#123;urls[$7]++&#125; END&#123;for (i in urls)&#123;print i,urls[i]&#125;&#125;' ccbhd.kerlala.com_access.log | sort -k2rn | head -30","categories":[{"name":"工具","slug":"工具","permalink":"http://xuchen.youtuc.cn/categories/工具/"},{"name":"shell","slug":"工具/shell","permalink":"http://xuchen.youtuc.cn/categories/工具/shell/"}],"tags":[],"keywords":[{"name":"工具","slug":"工具","permalink":"http://xuchen.youtuc.cn/categories/工具/"},{"name":"shell","slug":"工具/shell","permalink":"http://xuchen.youtuc.cn/categories/工具/shell/"}]},{"title":"go modules 详解","slug":"Go/mod详解","date":"2019-05-22T10:05:09.000Z","updated":"2021-05-04T08:26:08.000Z","comments":true,"path":"2019/05/22/Go/mod详解/","link":"","permalink":"http://xuchen.youtuc.cn/2019/05/22/Go/mod详解/","excerpt":"","text":"go mod的介绍我们以前用 go get 获取依赖其实是有潜在危险的，因为我们不确定最新版依赖是否会破坏掉我们项目对依赖包的使用方式，即当前项目可能会出现不兼容最新依赖包的问题。随着 go1.11 的发布，go 给我们带来了 module 新特性，这是 Go 语言新的一套依赖管理系统。 在默认情况下，$GOPATH 默认情况下是不支持 go mudules 的，我们需要在项目目录下手动执行以下命令：$ export GO111MODULE=on,这也表明了 go 要利用 modules 机制消灭 $GOPATH 的决心啊！ GO111MODULE可以设置为三个字符串值之一：off，on或auto（默认值） off : go命令从不使用新模块支持。它查找vendor 目录和GOPATH以查找依赖关系;也就是继续使用“GOPATH模式”。 on : go命令需要使用模块，go 会忽略 $GOPATH 和 vendor 文件夹，只根据go.mod下载依赖。 auto 或未设置: go命令根据当前目录启用或禁用模块支持。仅当当前目录位于$GOPATH/src之外并且其本身包含go.mod文件或位于包含go.mod文件的目录下时，才启用模块支持。 演示使用教程 创建项目,为了配合 go modules 机制，我们 $GOPATH 以外的目录创建一个 testmod 的包： 12345678$ mkdir testmod$ cd testmod$ echo &apos;package testmod import &quot;fmt&quot; func Hi(name string) string &#123; return fmt.Sprintf(&quot;Hi, %s&quot;, name)&#125;&apos; &gt;&gt; testmod.go 初始化module 123$ go mod init github.com/objcoding/testmod#这里如果是从git下来的，可以直接进入项目里面执行go initgo: creating new go.mod: module github.com/objcoding/testmod 推送到 github 仓库 1234$ git init$ git add *$ git commit -am &quot;First commit&quot;$ git push -u origin master go mudules 版本规则go modules 是一个版本化依赖管理系统，版本需要遵循一些规则，比如版本号需要遵循以下格式： 1234vX.Y.Z-pre.0.yyyymmddhhmmss-abcdefabcdefvX.0.0-yyyymmddhhmmss-abcdefabcdefvX.Y.(Z+1)-0.yyyymmddhhmmss-abcdefabcdefvX.Y.Z vX.Y.Z 是我们仓库打的标签版本，也就是 go modules 是根据仓库标签来确定版本号的，因此我们发布版本时，需要给我们的仓库打上一个标签版本号。 也就是版本号 + 时间戳 +hash，我们自己指定版本时只需要指定版本号即可，没有版本 tag 的则需要找到对应 commit 的时间和 hash 值。 还有一个重要的规则是，版本 0 和 1，最好需要有不同的依赖路径，如：v1.0.0 和 v2.0.0 是有不同的依赖路径，下面会详细介绍一下这个版本规则。 发布版本了解了 go modules 的版本规则后，现在我们发布一下该项目的版本： 12$ git tag v1.0.0$ git push --tags 这时我们最好还需要创建一条 v1 分支，以便我们在其它分支写代码不会影响到 v1.0.0 版本： 12$ git checkout -b v1$ git push -u origin v1 升级版本123$ git commit -m &quot;update testmod&quot; testmod.go$ git tag v1.0.1$ git push --tags origin v1 现在我们的 项目已经升级到 v1.0.1 版本了，我们可以有多种方式获取这个版本依赖，go1.11 中，go get 拥有了很多新特性，我们可以直接通过以下命令获取 v1.01 版本依赖： 1234$ go get github.com/objcoding/testmod@v1.0.1或者$ go mod edit -require=&quot;github.com/objcoding/testmod@v1.0.1&quot;$ go mod tidy go mod edit -require 可以主动修改 go.md 文件中依赖的版本号，然后通过 go mod tidy 对版本进行更新，它会自动清理掉不需要的依赖项，同时可以将依赖项更新到当前版本。 主要版本升级上面版本规则说了，版本 0 和 1，即大版本更新，最好需要有不同的依赖路径，如：v1.0.0 和 v2.0.0 是有不同的依赖路径，那么用 go modules 怎么实现呢，我们可以通过修改 go.mod 文件第一行添加新路径： 12$ cd testmod$ echo &apos;module github.com/objcoding/testmod/v2&apos; &gt;&gt; go.mod 然后我们修改 testmod 函数 Hi()： 123456789101112131415$ cd testmod$ echo &apos;package testmodimport ( &quot;fmt&quot; &quot;errors&quot;)func Hi(name, lang string) (string, error) &#123; switch lang &#123; case &quot;en&quot;: return fmt.Sprintf(&quot;Hi, %s!&quot;, name), nil default: return &quot;&quot;, errors.New(&quot;unknown language&quot;) &#125;&#125;&apos; &gt;&gt; testmod.go 这时，Hi() 方法将不兼容 v1 版本，我们需要新建一个 v2.0.0 版本，还是老样子，我们最好在 v2.0.0 版本新建一条 v2 分分支，将 v2.0.0 版本的代码写到这条分支中（这只是一个规范，实际上你将代码也写到任何分支中都行，go并没有这个规范）： 12345$ git add *$ git checkout -b v2$ git commit testmod.go -m &quot;v2.0.0&quot;$ git tag v2.0.0$ git push --tags origin v2 然后我们修改代码中的版本import,为v2 12345678package mainimport ( &quot;fmt&quot; &quot;github.com/objcoding/testmod/v2&quot;)func main() &#123; fmt.Println(testmod.Hi(&quot;zch&quot;, &quot;en&quot;))&#125; 然后执行go mod tidy，go mod 会自动更新到v2.0.0版本 go modules 命令大全12345678910111213141516go help modulesgo mod命令download download modules to local cache (下载依赖的module到本地cache))edit edit go.mod from tools or scripts (编辑go.mod文件)graph print module requirement graph (打印模块依赖图))init initialize new module in current directory (再当前文件夹下初始化一个新的module, 创建go.mod文件))tidy add missing and remove unused modules (增加丢失的module，去掉未用的module)vendor make vendored copy of dependencies (将依赖复制到vendor下)verify verify dependencies have expected content (校验依赖)why explain why packages or modules are needed (解释为什么需要依赖)初始化modgo mod init [module]可以创建一个go.mod，只有一行信息module。 goland支持go mod go 翻墙swag安装为例 mac/linux swag 安装 12345678## 127.0.0.1:1087 是 ssr的hhtp代理$ git config --global http.proxy &quot;127.0.0.1:1087&quot;$ http_proxy=127.0.0.1:1087 go get -u -v github.com/swaggo/swag/cmd/swag$ git config --global --unset-all http.proxy$ git config --global --unset-all https.proxy$ cd $GOPATH/src/github.com/swaggo/swag/cmd/swag$ go install$ swag -v #验证是否安装成功 window goget.bat文件 12345678910@echo offset http_proxy=socks5://127.0.0.1:1080set https_proxy=socks5://127.0.0.1:1080go get -u -v %*echo ...pause git bash上用goget.bat url就行了~ 自建GOPROXY server项目地址 https://github.com/gomods/athensAthens可以用来在公司内部建立自己的私有go mod服务器，或者在公网建立一个对外公开的GOPROXY server。 可用镜像 阿里云:https://mirrors.aliyun.com/goproxy/ go代理:https://goproxy.io go代理:https://goproxy.cn","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Golang","slug":"后端/Golang","permalink":"http://xuchen.youtuc.cn/categories/后端/Golang/"}],"tags":[],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Golang","slug":"后端/Golang","permalink":"http://xuchen.youtuc.cn/categories/后端/Golang/"}]},{"title":"基于Scratch创建最小且安全的golang docker镜像","slug":"Go/项目打包发布","date":"2019-05-18T10:40:58.000Z","updated":"2021-05-04T08:26:08.000Z","comments":true,"path":"2019/05/18/Go/项目打包发布/","link":"","permalink":"http://xuchen.youtuc.cn/2019/05/18/Go/项目打包发布/","excerpt":"","text":"golang打包镜像对比从docker官方下载了镜像以后，发现一个运行go的环境需要779\b\bM,我得项目才3~4M，这是不可以接受的 12$ docker image listgolang latest 1c1309ff8e0d 10 days ago 779MB 就算使用alpine镜像也有269M 12$ docker image listgolang alpine bbab7aea1231 7 weeks ago 269MB 于是打算自己构建golang运行的最小镜像. docker的Multi-stage builds多阶段构建是需要Docker 17.05或更高版本的新功能。在此之前，我们将看到docker scratch image，Zero Bytes Image。非常适合嵌入我们的静态二进制文件。 先上代码,例子说明 1234567891011121314151617181920212223FROM golang:alpine AS builderMAINTAINER Chen Xu &lt;abner510@126.com&gt;RUN apk update &amp;&amp; apk add --no-cache git ca-certificates tzdata &amp;&amp; update-ca-certificates &amp;&amp; adduser -D -g '' appuserENV GOPROXY https://mirrors.aliyun.com/goproxy/ENV GO111MODULE onWORKDIR /go/cacheADD go.mod .ADD go.sum .RUN go mod downloadWORKDIR /go/src/ginxADD . /go/src/ginxRUN CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -a -installsuffix cgo -ldflags=\"-w -s\" -o server#容器构建FROM scratch AS prodCOPY --from=builder /etc/passwd /etc/passwdCOPY --from=builder /usr/share/zoneinfo /usr/share/zoneinfoCOPY --from=builder /etc/ssl/certs/ca-certificates.crt /etc/ssl/certs/COPY --from=builder /go/src/ginx/config /app/configCOPY --from=builder /go/src/ginx/server /appUSER appuserEXPOSE 9000CMD [\"/app/server\", \"-e=prod\"] 代码示例说明添加SSL证书支持HTTPS和时区1apk add --no-cache git ca-certificates tzdata &amp;&amp; update-ca-certificates 添加运行golang的用户1adduser -D -g &apos;&apos; appuser go mod模式项目包管理，加快构建速度123456ENV GOPROXY https://goproxy.io #设置代理，国内的墙你懂的ENV GO111MODULE on #开启go mod 模式 ，老版本GO111MODULE=auto 默认是自动WORKDIR /go/cache # 设置包的下载目录ADD go.mod .ADD go.sum .RUN go mod download CGO编译使用由于scratch是空镜像， 1CGO_ENABLED=0 GOOS=linux GOARCH=amd64 go build -a -installsuffix cgo -ldflags=&quot;-w -s&quot; -o server CGO_ENABLED=0 ，CGO_ENABLED 是因为 交叉编译不支持 CGO，我们这里禁用它 -a -installsuffix cgo , -a:强制重新编译，简单来说，就是不利用缓存或已编译好的部分文件，直接所有包都是最新的代码重新编译和关联; installsuffix:在软件包安装的目录中增加后缀标识，以保持输出与默认版本分开 制作golang运行的容器123456789FROM scratch AS prod #镜像版本COPY --from=builder /etc/passwd /etc/passwd #这里需要使用appuer账号信息COPY --from=builder /usr/share/zoneinfo /usr/share/zoneinfo #时区COPY --from=builder /etc/ssl/certs/ca-certificates.crt /etc/ssl/certs/ #SSL证书文件COPY --from=builder /go/src/ginx/config /app/config #应用配置文件COPY --from=builder /go/src/ginx/server /app #应用二进制文件USER appuser #运行用户EXPOSE 9000 #暴露端口CMD [&quot;/app/server&quot;, &quot;-e=prod&quot;] #运行应用，传入运行参数 阿里云加速翻墙速度1、创建镜像仓库2、填写仓库信息3、选择仓库管理，进行配置仓库4、选择git仓库版本，这里本人是放在github上，所以选择github，进行授权，选择自己的仓库和项目，配置如下具体dockerfile文件根据自己仓库路径配置5、选择构建即可","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Golang","slug":"后端/Golang","permalink":"http://xuchen.youtuc.cn/categories/后端/Golang/"}],"tags":[],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Golang","slug":"后端/Golang","permalink":"http://xuchen.youtuc.cn/categories/后端/Golang/"}]},{"title":"Go相对路径问题","slug":"Go/相对路径问题","date":"2019-05-10T10:44:58.000Z","updated":"2020-05-18T05:44:55.000Z","comments":true,"path":"2019/05/10/Go/相对路径问题/","link":"","permalink":"http://xuchen.youtuc.cn/2019/05/10/Go/相对路径问题/","excerpt":"","text":"问题1、 go run 我们上移目录层级，到 $GOPATH/src 下，执行 go run gin-blog/main.go 123[$]# go run gin-blog/main.goFail to parse &apos;conf/app.yam&apos;: open conf/app.ini: no such file or directoryexit status 1 2、 go build，执行 ./gin-blog/main 12[$]# ./gin-blog/main Fail to parse &apos;conf/app.ini&apos;: open conf/app.ini: no such file or directory 测试编写获取当前路径的方法 1234567891011121314import ( &quot;path/filepath&quot; &quot;os&quot; &quot;os/exec&quot; &quot;string&quot;)func GetAppPath() string &#123; file, _ := exec.LookPath(os.Args[0]) path, _ := filepath.Abs(file) index := strings.LastIndex(path, string(os.PathSeparator)) return path[:index]&#125; 执行go run 得到 12$ go run main.goC:\\Users\\abner（~1\\AppData\\Local\\Temp\\go-build536365654\\b001\\exe 剖析我们聚焦在 go run 的输出结果上，发现它是一个临时文件的地址，这是为什么呢？ 在go help run中，我们可以看到 12A Go source file is defined to be a file ending in a literal &quot;.go&quot; suffix.也就是 go run 执行时会将文件放到 /tmp/go-build... 目录下，编译并运行 因此go run main.go出现/tmp/go-build536365654/b001/exe结果也不奇怪了，因为它已经跑到临时目录下去执行可执行文件了 这就已经很清楚了，那么我们想想，会出现哪些问题呢 依赖相对路径的文件，出现路径出错的问题 go run 和 go build 不一样，一个到临时目录下执行，一个可手动在编译后的目录下执行，路径的处理方式会不同 不断go run，不断产生新的临时文件这其实就是根本原因了，因为 go run 和 go build 的编译文件执行路径并不同，执行的层级也有可能不一样，自然而然就出现各种读取不到的奇怪问题了 解决方案一、获取编译后可执行文件路径 1. 将配置文件的相对路径与GetAppPath()的结果相拼接，可解决go build main.go的可执行文件跨目录执行的问题（如：./src/gin-blog/main） 2. 通过传递参数指定绝对路径，可解决go run的问题二、增加os.Getwd()进行多层判断参见 beego 读取 app.conf 的代码 该写法可兼容 go build 和在项目根目录执行 go run ，但是若跨目录执行 go run 就不行三、配置全局系统变量我们可以通过os.Getenv来获取系统全局变量，然后与相对路径进行拼接 1、 设置项目工作区 简单来说，就是设置项目（应用）的工作路径，然后与配置文件、日志文件等相对路径进行拼接，达到相对的绝对路径来保证路径一致 参见 gogs 读取GOGS_WORK_DIR进行拼接的代码 2、 利用系统自带变量 简单来说就是通过系统自带的全局变量，例如$HOME等，将配置文件存放在$HOME/conf或/etc/conf下 这样子就能更加固定的存放配置文件，不需要额外去设置一个环境变量 拓展go test 在一些场景下也会遇到路径问题，因为go test只能够在当前目录执行，所以在执行测试用例的时候，你的执行目录已经是测试目录了 需要注意的是，如果采用获取外部参数的办法，用 os.args 时，go test -args 和 go run、go build 会有命令行参数位置的不一致问题","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Golang","slug":"后端/Golang","permalink":"http://xuchen.youtuc.cn/categories/后端/Golang/"}],"tags":[],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Golang","slug":"后端/Golang","permalink":"http://xuchen.youtuc.cn/categories/后端/Golang/"}]},{"title":"php错误和异常处理总结","slug":"php错误和异常处理","date":"2019-03-10T13:23:27.000Z","updated":"2020-05-18T05:44:56.000Z","comments":true,"path":"2019/03/10/php错误和异常处理/","link":"","permalink":"http://xuchen.youtuc.cn/2019/03/10/php错误和异常处理/","excerpt":"","text":"1. 异常1.1 抛出异常当一个异常被抛出后代码会立即停止执行，其后的代码将不会继续执行，PHP 会尝试查找匹配的 “catch” 代码块。如果一个异常没有被捕获，而且又没用使用set_exception_handler()作相应的处理的话，那么 PHP 将会产生一个严重的错误，并且输出未能捕获异常(Uncaught Exception …)的提示信息。 1throw new Exception(\"this is a exception\");//使用throw抛出异常 1.2 捕获异常123456789101112try &#123; throw new Exception(\"Error Processing Request\"); $pdo = new PDO(\"mysql://host=wrong_host;dbname=wrong_name\");&#125; catch (PDOException $e) &#123; echo \"pdo error!\";&#125; catch(Exception $e)&#123; echo \"exception!\";&#125;finally&#123; echo \"end!\";//finally是在捕获到任何类型的异常后都会运行的一段代码&#125;//运行结果：exception！end！ 1.3 异常处理那么我们应该如何捕获每个可能抛出的异常呢？PHP允许我们注册一个全局异常处理程序，捕获所有未被捕获的异常。异常处理程序使用set_exception_handler()函数注册（这里使用匿名函数）。 1234567set_exception_handler(function (Exception $e)&#123; echo \"我自己定义的异常处理\".$e-&gt;getMessage();&#125;);throw new Exception(\"this is a exception\"); //运行结果：我自己定义的异常处理this is a exception 2. 错误2.1 错误处理与异常处理程序一样，我们也可以使用set_error_handler()注册全局错误处理程序，使用自己的逻辑方式拦截并处理PHP错误。我们要在错误处理程序中调用die()或exit()函数。如果不调用，PHP脚本会从出错的地方继续向下执行。如下： 123456789101112131415set_error_handler(function ($errno,$errstr,$errfile,$errline)//常用的四个参数&#123; echo \"错误等级：\".$errno.\"&lt;br&gt;错误信息：\".$errstr.\"&lt;br&gt;错误的文件名：\".$errfile.\"&lt;br&gt;错误的行号：\".$errline; exit();&#125;); trigger_error(\"this is a error\");//手动触发的错误 echo '正常'; // 运行结果：// 错误等级：1024// 错误信息：this is a error// 错误的文件名：/Users/toby/Desktop/www/Exception.php// 错误的行号：33 2.2 错误转成异常我们可以把PHP错误转换为异常（并不是所有的错误都可以转换,只能转换php.ini文件中error_reporting指令设置的错误），使用处理异常的现有流程处理错误。这里我们使用set_error_handler()函数将错误信息托管至ErrorException（它是Exception的子类），进而交给现有的异常处系统处理。如下： 1234567891011set_exception_handler(function (Exception $e)&#123; echo \"我自己定义的异常处理\".$e-&gt;getMessage();&#125;); set_error_handler(function ($errno, $errstr, $errfile, $errline )&#123; throw new ErrorException($errstr, 0, $errno, $errfile, $errline);//转换为异常&#125;); trigger_error(\"this is a error\");//自行触发错误","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"PHP","slug":"后端/PHP","permalink":"http://xuchen.youtuc.cn/categories/后端/PHP/"}],"tags":[{"name":"PHP异常","slug":"PHP异常","permalink":"http://xuchen.youtuc.cn/tags/PHP异常/"},{"name":"面试","slug":"面试","permalink":"http://xuchen.youtuc.cn/tags/面试/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"PHP","slug":"后端/PHP","permalink":"http://xuchen.youtuc.cn/categories/后端/PHP/"}]},{"title":"php垃圾回收引发的一些底层了解","slug":"php垃圾回收","date":"2019-03-09T13:47:23.000Z","updated":"2021-05-04T08:26:08.000Z","comments":true,"path":"2019/03/09/php垃圾回收/","link":"","permalink":"http://xuchen.youtuc.cn/2019/03/09/php垃圾回收/","excerpt":"","text":"底层的运行原理和机制四层体系架构图 Zend引擎：Zend整体用纯C实现，是PHP的内核部分，它将php代码翻译(词法、语法解析等一系列编译过程)为可执行opcode的 处理并实现相应的处理方法、实现了基本的数据结构(如hashtable、oo)、内存分配及管理、提供了相应的api方法供外部调用，是一切的核心，所 有的外围功能均围绕Zend实现。 Extensions：围绕着Zend引擎，extensions通过组件式的方式提供各种基础服务，我们常见的各种内置函数(如array 系列)、标准库等都是通过extension来实现，用户也可以根据需要实现自己的extension以达到功能扩展、性能优化等目的(如贴吧正在使用的 PHP中间层、富文本解析就是extension的典型应用)。 Sapi：Sapi全称是Server Application Programming Interface，也就是服务端应用编程接口，Sapi通过一系列钩子函数，使得PHP可以和外围交互数据，这是PHP非常优雅和成功的一个设计，通过 sapi成功的将PHP本身和上层应用解耦隔离，PHP可以不再考虑如何针对不同应用进行兼容，而应用本身也可以针对自己的特点实现不同的处理方式。 上层应用：这就是我们平时编写的PHP程序，通过不同的sapi方式得到各种各样的应用模式，如通过webserver实现web应用、在命令行下以脚本方式运行等等。 PHP执行的几个阶段 PHP 是一门托管型语言，在 PHP 编程中，程序员不需要手工处理内存资源的分配与释放（使用 C 编写 PHP 或 Zend 扩展除外），这就意味着 PHP 本身实现了垃圾回收机制（Garbage Collection）。在PHP官方网站可以看到对垃圾回收机制的介绍。 引用计数基本知识PHP在内核中是通过zval这个结构体来存储变量的，在Zend/zend.h文件中找到了其定义：PHP5定义如下 12345678910111213141516struct _zval_struct &#123; union &#123; long lval; double dval; struct &#123; char *val; int len; &#125; str; HashTable *ht; zend_object_value obj; zend_ast *ast; &#125; value; zend_uint refcount__gc; zend_uchar type; zend_uchar is_ref__gc;&#125;; PHP7定义如下 12345678910111213141516171819202122232425262728293031323334353637383940struct _zval_struct &#123; union &#123; zend_long lval; /* long value */ double dval; /* double value */ zend_refcounted *counted; zend_string *str; zend_array *arr; zend_object *obj; zend_resource *res; zend_reference *ref; zend_ast_ref *ast; zval *zv; void *ptr; zend_class_entry *ce; zend_function *func; struct &#123; uint32_t w1; uint32_t w2; &#125; ww; &#125; value; union &#123; struct &#123; ZEND_ENDIAN_LOHI_4( zend_uchar type, /* active type */ zend_uchar type_flags, zend_uchar const_flags, zend_uchar reserved) /* call info for EX(This) */ &#125; v; uint32_t type_info; &#125; u1; union &#123; uint32_t var_flags; uint32_t next; /* hash collision chain */ uint32_t cache_slot; /* literal cache slot */ uint32_t lineno; /* line number (for ast nodes) */ uint32_t num_args; /* arguments number for EX(This) */ uint32_t fe_pos; /* foreach position */ uint32_t fe_iter_idx; /* foreach iterator index */ &#125; u2;&#125;; 我们定义一个PHP变量如下： 123$var = &quot;laruence&quot;;$var_dup = $var;unset($var); 第一行代码创建了一个字符串变量，申请了一个大小为9字节的内存，保存了字符串”laruence”和一个NULL(\\0)的结尾。 第二行定义了一个新的字符串变量，并将变量var的值”复制”给这个新的变量。 第三行unset了变量var这样的代码在我们平时的脚本中是很常见的，如果PHP对于每一个变量赋值都重新分配内存，copy数据的话，那么上面的这段代码公要申请18个字节的内存空间，而我们也很容易的看出来，上面的代码其实根本没有必要申请俩份空间，PHP的开发者也看出来了： PHP中的变量是用一个存储在symbol_table中的符号名，对应一个zval来实现的，比如对于上面的第一行代码，会在symbol_table中存储一个值”var”, 对应的有一个指针指向一个zval结构，变量值”laruence”保存在这个zval中，所以不难想象，对于上面的代码来说，我们完全可以让”var”和”var_dup”对应的指针都指向同一个zval就可以了。 PHP也是这样做的，这个时候就需要介绍过zval结构中的refcount字段了。 refcount,顾名思义，记录了当前的zval被引用的计数。 不准确但却通俗的说： refcount：多少个变量是一样的用了相同的值，这个数值就是多少。 is_ref：bool类型，当refcount大于2的时候，其中一个变量用了地址&amp;的形式进行赋值，好了，它就变成1了。 在 PHP 中可以通过 xdebug 扩展中提供的方法来查看变量的计数变化： 第一步：查看内部结构 1234$name = &quot;这是一段内存测试&quot;; xdebug_debug_zval(&apos;name&apos;);会得到name:(refcount=1, is_ref=0),string &apos;这是一段内存测试&apos; (length=18) 第二步：查看内部结构 123456$name = &quot;这是一段内存测试&quot;;$temp_name = $name;xdebug_debug_zval(&apos;name&apos;);会得到name:(refcount=2, is_ref=0),string &apos;这是一段内存测试&apos; (length=18)看到了吧，refcount＋1了。 第三步：引用赋值 1234567$name = &quot;这是一段内存测试&quot;;$temp_name = &amp;$name;xdebug_debug_zval(&apos;name&apos;);会得到name:(refcount=2, is_ref=0),string &apos;这是一段内存测试&apos; (length=18)看到了吧，refcount＋1了。引用赋值会导致zval通过is_ref来标记是否存在引用的情况。 第四步：数组型的变量 123456789$name = [&apos;a&apos;=&gt;&apos;这是一段&apos;, &apos;b&apos;=&gt;&apos;内存测试&apos;];xdebug_debug_zval(&apos;name&apos;);会得到name:(refcount=1, is_ref=0),array (size=2) &apos;a&apos; =&gt; (refcount=1, is_ref=0),string &apos;这是一段&apos; (length=9) &apos;b&apos; =&gt; (refcount=1, is_ref=0),string &apos;内存测试&apos; (length=9)还挺好理解的，对于数组来看是一个整体，对于内部kv来看又是分别独立的整体，各自都维护着一套zval的refount和is_ref。 第五步：销毁变量 123456789$name = &quot;这是一段内存测试&quot;;$temp_name = $name;xdebug_debug_zval(&apos;name&apos;);unset($temp_name);xdebug_debug_zval(&apos;name&apos;);会得到name:(refcount=2, is_ref=0),string &apos;这是一段内存测试&apos; (length=18)name:(refcount=1, is_ref=0),string &apos;这是一段内存测试&apos; (length=18)refcount计数减1，说明unset并非一定会释放内存，当有两个变量指向的时候，并非会释放变量占用的内存，只是refcount减1. PHP的内存管理机制通过上面的案例，知道了zval的原理以后，接下来通过PHP来看一下内存管理机制是怎么样的 外在的内存变换代码示例A： 123456//获取内存方法，加上true返回实际内存，不加则返回表现内存var_dump(memory_get_usage());$name = &quot;这是一段内存测试&quot;;var_dump(memory_get_usage());unset($name);var_dump(memory_get_usage()); 会得到： int 1593248 int 1593384 int 1593248大致过程：定义变量-&gt;内存增加-&gt;清除变量-&gt;内存恢复 潜在的内存变化当执行：$name=”这是一段内存测试”; 的时候，内存的分配做了2件事情： 为变量名分配内存，存入符号表 为变量分配内存 代码示例B： 12345678910111213var_dump(memory_get_usage());for($i=0;$i&lt;100;$i++)&#123; $a = &quot;test&quot;.$i; $$a = &quot;hello&quot;; &#125;var_dump(memory_get_usage());for($i=0;$i&lt;100;$i++)&#123; $a = &quot;test&quot;.$i; unset($$a); &#125;var_dump(memory_get_usage()); 会得到： int 1596864 int 1612080 int 1597680这里可以发现内存并没有全部收回来 这里由于PHP核心数据Hashtable来说，由于未知性，定义的时候不可能一次性分配足够的内存块，所以初始分配的内存使用完成以后，进行扩容，而HashTable只扩容不减少，所以就出现了上面的情况：当存入100个变量的时候，符号表不够用了就进行一次扩容，当unset的时候只释放了”为变量值分配的内存“，而”为变量名分配的内存“是在符号表的，符号表并没有缩减，所以没有收回来的内存是被符号表占去了 潜在的内存申请与释放设计php和C语言一样，也是需要进行内存申请，只不过这些操作都封装在底层了，php使用者无感知。 首先我们要打破一个思维：php不像C语言那样，只有你显示的调用内存分配API才会有相关的内存分配。也就是说，在PHP中，我们看不到内存分配。 比如说 1$a=\"laruence\"; 隐式的内存分配点就有： 为变量名分配内存，存入符号表 为变量值分配内存 所以不能看表象 别怀疑php的unset确实能是否内存（当然还要结合引用和计数），导致这个释放不是C语言意义上的释放，不是交回给OS，对于PHP来说，它自身提供了一套和C语言对内存分配相似的内存管理API 123456emalloc(size_t size);efree(void *ptr);ecalloc(size_t nmemb, size_t size);erealloc(void *ptr, size_t size);estrdup(const char *s);estrndup(const char *s, unsigned int length); 这些API和C的API意义对应， 在PHP内部都是通过这些API来管理内存的。 当我们调用emalloc申请内存的时候，PHP并不是简单的向OS要内存， 而是会像OS要一个大块的内存, 然后把其中的一块分配给申请者，这样当再有逻辑来申请内存的时候， 就不再需要向OS申请内存了， 避免了频繁的系统调用。 比如如下的例子: 123456789var_dump(memory_get_usage(TRUE)); //注意获取的是real_size$a = \"laruence\";var_dump(memory_get_usage(TRUE));unset($a);var_dump(memory_get_usage(TRUE));//输出int(262144)int(262144)int(262144) 也就是我们在定义变量$a的时候, PHP并没有向系统申请新内存. 同样的, 在我们调用efree释放内存的时候, PHP也不会把内存还给OS, 而会把这块内存, 归入自己维护的空闲内存列表. 而对于小块内存来说, 更可能的是, 把它放到内存缓存列表中去(后记, 某些版本的PHP, 比如我验证过的PHP7.2, 在调用get_memory_usage()的时候, 不会减去内存缓存列表中的可用内存块大小, 导致看起来, unset以后内存不变). php中垃圾是如何定义的？首先我们需要定义一下“垃圾”的概念，GC负责清理的垃圾是指变量的容器zval还存在，但是又没有任何变量名指向此zval。因此GC判断是否为垃圾的一个重要标准是有没有变量名指向变量容器zval。 假设我们有一段PHP代码，使用了一个临时变量$tmp存储了一个字符串，在处理完字符串之后，就不需要这个$tmp变量了，$tmp变量对于我们来说可以算是一个“垃圾”了，但是对于GC来说，$tmp其实并不是一个垃圾，$tmp变量对我们没有意义，但是这个变量实际还存在，$tmp符号依然指向它所对应的zval，GC会认为PHP代码中可能还会使用到此变量，所以不会将其定义为垃圾。 那么如果我们在PHP代码中使用完$tmp后，调用unset删除这个变量，那么$tmp是不是就成为一个垃圾了呢。很可惜，GC仍然不认为$tmp是一个垃圾，因为$tmp在unset之后，refcount减少1变成了0(这里假设没有别的变量和$tmp指向相同的zval),这个时候GC会直接将$tmp对应的zval的内存空间释放，$tmp和其对应的zval就根本不存在了。此时的$tmp也不是新的GC所要对付的那种“垃圾”。 PHP垃圾回收的相关配置可以通过修改配置文件 php.ini 中的 zend.enable_gc 来打开或关闭 PHP 的垃圾回收机制，也可以通过调用 gc_enable() 或 gc_disable() 打开或关闭 PHP 的垃圾回收机制。 在 PHP5.3 中即使关闭了垃圾回收机制，PHP 仍然会记录可能根到根缓冲区，只是当根缓冲区满额时，不会自动运行垃圾回收，当然，任何时候您都可以通过手工调用 gc_collect_cycles() 函数强制执行内存回收。","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"PHP","slug":"后端/PHP","permalink":"http://xuchen.youtuc.cn/categories/后端/PHP/"}],"tags":[{"name":"面试","slug":"面试","permalink":"http://xuchen.youtuc.cn/tags/面试/"},{"name":"PHPGC垃圾","slug":"PHPGC垃圾","permalink":"http://xuchen.youtuc.cn/tags/PHPGC垃圾/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"PHP","slug":"后端/PHP","permalink":"http://xuchen.youtuc.cn/categories/后端/PHP/"}]},{"title":"微服务治理","slug":"微服务治理","date":"2019-03-04T23:14:26.000Z","updated":"2021-05-04T08:26:08.000Z","comments":true,"path":"2019/03/04/微服务治理/","link":"","permalink":"http://xuchen.youtuc.cn/2019/03/04/微服务治理/","excerpt":"","text":"","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"架构","slug":"后端/架构","permalink":"http://xuchen.youtuc.cn/categories/后端/架构/"}],"tags":[{"name":"面试","slug":"面试","permalink":"http://xuchen.youtuc.cn/tags/面试/"},{"name":"微服务","slug":"微服务","permalink":"http://xuchen.youtuc.cn/tags/微服务/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"架构","slug":"后端/架构","permalink":"http://xuchen.youtuc.cn/categories/后端/架构/"}]},{"title":"nginx总结","slug":"nginx总结","date":"2019-03-01T15:47:07.000Z","updated":"2020-05-25T09:27:53.000Z","comments":true,"path":"2019/03/01/nginx总结/","link":"","permalink":"http://xuchen.youtuc.cn/2019/03/01/nginx总结/","excerpt":"","text":"nginx的特性 非阻塞、高并发连接：处理2-3万并发连接数，官方监测能支持5万并发 内存消耗小：开启10个nginx才占150M内存，Nginx采取了分阶段资源分配技术 内置的健康检查功能 master/worker结构：一个master进程(管理work进程)，生成一个或者多个worker进程（处理请求） 事件驱动：通信机制采用epoll模型 nginx 的 upstream目前支持 4 种方式的分配 轮询默认的方式 ：每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。 权重weight ： 指定轮询几率，weight和访问比率成正比，用于后端服务器性能不均的情况。 ip_hash ： 每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题。 fair（第三方） ：按后端服务器的响应时间来分配请求，响应时间短的优先分配。 url_hash（第三方）： 惊群效应主进程（master 进程）首先通过 socket() 来创建一个 sock 文件描述符用来监听，然后fork生成子进程（workers 进程），子进程将继承父进程的 sockfd（socket 文件描述符），之后子进程 accept() 后将创建已连接描述符（connected descriptor），然后通过已连接描述符来与客户端通信。 那么，由于所有子进程都继承了父进程的 sockfd，那么当连接进来时，所有子进程都将收到通知并“争着”与它建立连接，这就叫“惊群现象”。大量的进程被激活又挂起，只有一个进程可以accept() 到这个连接，这当然会消耗系统资源。 惊群现象的处理Nginx 提供了一个 accept_mutex 这个东西，这是一个加在accept上的一把共享锁。即每个 worker 进程在执行 accept 之前都需要先获取锁，获取不到就放弃执行 accept()。有了这把锁之后，同一时刻，就只会有一个进程去 accpet()，这样就不会有惊群问题了。 accept_mutex 是一个可控选项，我们可以显示地关掉，默认是打开的。 master进程作用 接收来自外界的信号 向各worker进程发送信号 监控worker进程的运行状态，当worker进程退出后(异常情况下)，会自动重新启动新的worker进程 Nginx采用的 IO多路复用模型epollepoll通过在Linux内核中申请一个简易的文件系统（文件系统一般用什么数据结构实现？B+树），其工作流程分为三部分： 调用 int epoll_create(int size) 建立一个epoll对象，内核会创建一个eventpoll结构体，用于存放通过epoll_ctl()向 epoll 对象中添加进来的事件，这些事件都会挂载在红黑树中。 调用 int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event) 在 epoll 对象中为 fd 注册事件，所有添加到epoll中的事件都会与设备驱动程序建立回调关系，也就是说，当相应的事件发生时会调用这个sockfd的回调方法，将sockfd添加到 eventpoll 中的双链表 调用 int epoll_wait(int epfd, struct epoll_event * events, int maxevents, int timeout) 来等待事件的发生，timeout 为 -1 时，该调用会阻塞直到有事件发生 这样，注册好事件之后，只要有 fd 上事件发生，epoll_wait() 就能检测到并返回给用户，用户就能”非阻塞“地进行 I/O 了。 epoll() 中内核则维护一个链表， epoll_wait 直接检查链表是不是空就知道是否有文件描述符准备好了。（epoll 与 select 相比最大的优点是不会随着 sockfd 数目增长而降低效率，使用 select() 时，内核采用轮训的方法来查看是否有 fd 准备好，其中的保存 sockfd 的是类似数组的数据结构 fd_set，key 为 fd ，value 为 0 或者 1。） 能达到这种效果，是因为在内核实现中 epoll 是根据每个 sockfd 上面的与设备驱动程序建立起来的回调函数实现的。那么，某个 sockfd 上的事件发生时，与它对应的回调函数就会被调用，来把这个 sockfd 加入链表，其他处于“空闲的”状态的则不会。在这点上， epoll 实现了一个”伪”AIO。但是如果绝大部分的 I/O 都是“活跃的”，每个 socket 使用率很高的话，epoll效率不一定比 select 高（可能是要维护队列复杂）。 可以看出，因为一个进程里只有一个线程，所以一个进程同时只能做一件事，但是可以通过不断地切换来“同时”处理多个请求。","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"NGINX","slug":"后端/NGINX","permalink":"http://xuchen.youtuc.cn/categories/后端/NGINX/"}],"tags":[{"name":"面试","slug":"面试","permalink":"http://xuchen.youtuc.cn/tags/面试/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"NGINX","slug":"后端/NGINX","permalink":"http://xuchen.youtuc.cn/categories/后端/NGINX/"}]},{"title":"单线程的redis为什么快","slug":"Redis/单线程的redis为什么快","date":"2019-02-28T20:49:03.000Z","updated":"2021-05-04T08:26:08.000Z","comments":true,"path":"2019/02/28/Redis/单线程的redis为什么快/","link":"","permalink":"http://xuchen.youtuc.cn/2019/02/28/Redis/单线程的redis为什么快/","excerpt":"","text":"基本概念Redis性能如此高的原因，我总结了如下几点： 纯内存操作 单线程 高效的数据结构 合理的数据编码 其他方面的优化 在 Redis 中，常用的几种数据结构和应用场景如下： String：缓存、计数器、分布式锁等。 List：链表、队列、微博关注人时间轴列表等。 Hash：用户信息、Hash 表等。 Set：去重、赞、踩、共同好友等。 Zset：访问量排行榜、点击量排行榜等。 HyperLogLog: 网站UV,独立IP计算等，主要也是一些去重计算，对数据精度要求不高，主要由于计算数据空间是固定的 Geo：GEO(地理位置)的支持，主要是对经纬度一个位置计算等特性 内部数据结构redis的底层数据结构有以下7种，包括简单动态字符串(SDS)，链表、字典、跳跃表、整数集合、压缩列表、对象。 简单动态字符串(SDS)Redis 是用 C 语言开发完成的，但在 Redis 字符串中，并没有使用 C 语言中的字符串，而是用一种称为 SDS（Simple Dynamic String）的结构体来保存字符串。在redis数据库里，包含字符串值的键值对在底层都是由SDS实现的。除了用来保存数据库中的字符串值之外，sds还被用来作缓冲区（buffer）：AOF（一种持久化策略）模块中的AOF缓冲区，以及客户端状态中的输入缓冲区，都是由SDS实现的。 12345struct __attribute__ ((__packed__)) sdshdr64 &#123; uint64_t len; /* 记录buff数组中已使用字节的数量 */ uint64_t free; /* 记录未使用字节数量*/ char buf[]; /*存储实际内容*/&#125;; 例如：执行命令 set key value，key 和 value 都是一个 SDS 类型的结构存储在内存中。 SDS 与 C 字符串的区别 常数时间内获得字符串长度:C 字符串本身不记录长度信息，每次获取长度信息都需要遍历整个字符串，复杂度为 O(n)；C 字符串遍历时遇到’\\0‘ 时结束。SDS 中 len 字段保存着字符串的长度，所以总能在常数时间内获取字符串长度，复杂度是 O(1)。 避免缓冲区溢出假设在内存中有两个紧挨着的两个字符串，s1=”xxxxx”和 s2=”yyyyy”由于在内存上紧紧相连，当我们对 s1 进行扩充的时候，将 s1=“xxxxxzzzzz”后，由于没有进行相应的内存重新分配，导致 s1 把 s2 覆盖掉，导致 s2 被莫名其妙的修改。但 SDS 的 API 对 zfc 修改时首先会检查空间是否足够，若不充足则会分配新空间，避免了缓冲区溢出问题。 减少字符串修改时带来的内存重新分配的次数由于C语言修改字符需要重新分配空间而SDS实现了预分配和惰性释放预分配规则：SDS空间进行扩充时，会分配足够的内存空间还会分配额外未使用的空间。如果对 SDS 修改后，len 的长度小于 1M，那么程序将分配和 len 相同长度的未使用空间。举个例子，如果 len=10，重新分配后，buf 的实际长度会变为 10(已使用空间)+10(额外空间)+1(空字符)=21。如果对 SDS 修改后 len 长度大于 1M，那么程序将分配 1M 的未使用空间。 惰性空间释放：当对 SDS 进行缩短操作时，程序并不会回收多余的内存空间，而是使用 free 字段将这些字节数量记录下来不释放，后面如果需要 append 操作，则直接使用 free 中未使用的空间，减少了内存的分配。 3.字典(Hash)Redis底层hash结构如下： 123456789101112131415161718typedef struct dict&#123; dictType *type; void *privdata; dictht ht[2]; int trehashidx;&#125;typedef struct dictht&#123; //哈希表数组 dectEntrt **table; //哈希表大小 unsigned long size; // unsigned long sizemask; //哈希表已有节点数量 unsigned long used;&#125; 重要的两个字段是 dictht 和 trehashidx Rehash Rehash解释：随着操作的不断执行， 哈希表保存的键值对会逐渐地增多或者减少， 为了让哈希表的负载因子（load factor）维持在一个合理的范围之内， 当哈希表保存的键值对数量太多或者太少时， 程序需要对哈希表的大小进行相应的扩展或者收缩。扩展和收缩哈希表的工作可以通过执行 rehash （重新散列）操作来完成 由上段代码，我们可知 dict 中存储了一个 dictht 的数组，长度为 2，表明这个数据结构中实际存储着两个哈希表 ht[0] 和 ht[1]，为什么要存储两张 hash 表呢？当然是为了Rehash,Rehash的过程 为 ht[1] 分配空间。如果是扩容操作，ht[1] 的大小为第一个大于等于 ht[0].used*2 的 2^n；如果是缩容操作，ht[1] 的大小为第一个大于等于 ht[0].used 的 2^n。 将 ht[0] 中的键值 Rehash 到 ht[1] 中。 当 ht[0] 全部迁移到 ht[1] 中后，释放 ht[0]，将 ht[1] 置为 ht[0]，并为 ht[1] 创建一张新表，为下次 Rehash 做准备。 渐进式 Rehash上面提到的如果ht[0]全部移动到ht[1]中，如果数据量小很快，如果数据量很大则会有影响使用所以redis采用了分多次、渐进式的迁移策略 为 ht[1] 分配空间，让字典同时拥有 ht[0] 和 ht[1] 两个哈希表。 字典中维护一个 rehashidx，并将它置为 0，表示 Rehash 开始。 在 Rehash 期间，每次对字典操作时，程序还顺便将 ht[0] 在 rehashidx 索引上的所有键值对 rehash 到 ht[1] 中，当 Rehash 完成后，将 rehashidx 属性+1。当全部 rehash 完成后，将 rehashidx 置为 -1，表示 rehash 完成。注意，由于维护了两张 Hash 表，所以在 Rehash 的过程中内存会增长。另外，在 Rehash 过程中，字典会同时使用 ht[0] 和 ht[1]。 所以在删除、查找、更新时会在两张表中操作，在查询时会先在第一张表中查询，如果第一张表中没有，则会在第二张表中查询。但新增时一律会在 ht[1] 中进行，确保 ht[0] 中的数据只会减少不会增加。 4. Zset底层zset底层的存储结构包括ziplist或skiplist，在同时满足以下两个条件的时候使用ziplist，其他时候使用skiplist，两个条件如下： 有序集合保存的元素数量小于128个 有序集合保存的所有元素的长度小于64字节 当ziplist作为zset的底层存储结构时候，每个集合元素使用两个紧挨在一起的压缩列表节点来保存，第一个节点保存元素的成员，第二个元素保存元素的分值。 当skiplist作为zset的底层存储结构的时候，使用skiplist按序保存元素及分值，使用dict来保存元素和分值的映射关系。 ziplist数据结构 skiplist数据结构 skiplist作为zset的存储结构，整体存储结构如下图，核心点主要是包括一个dict对象和一个skiplist对象。dict保存key/value，key为元素，value为分值；skiplist保存的有序的元素列表，每个元素包括元素和分值。两种数据结构下的元素指向相同的位置。 5. Set底层set的底层存储intset和hashtable是存在编码转换的，使用intset存储必须满足下面两个条件，否则使用hashtable，条件如下： 结合对象保存的所有元素都是整数值 集合对象保存的元素数量不超过512个 12345678typedef struct intset &#123; // 编码方式 uint32_t encoding; // 集合包含的元素数量 uint32_t length; // 保存元素的数组 int8_t contents[];&#125; intset; set的单个元素的添加过程，首先如果已经是hashtable的编码，那么我们就走正常的hashtable的元素添加，如果原来是intset的情况，那么我们就需要进行如下判断： 如果能够转成int的对象（isObjectRepresentableAsLongLong），那么就用intset保存。 如果用intset保存的时候，如果长度超过512（REDIS_SET_MAX_INTSET_ENTRIES）就转为hashtable编码。 List底层redis list数据结构底层采用压缩列表ziplist或linkedlist两种数据结构进行存储，首先以ziplist进行存储，在不满足ziplist的存储要求后转换为linkedlist列表。 当列表对象同时满足以下两个条件时，列表对象使用ziplist进行存储，否则用linkedlist存储。 列表对象保存的所有字符串元素的长度小于64字节 列表对象保存的元素数量小于512个。 编码转化Redis 使用对象（redisObject）来表示数据库中的键值，当我们在 Redis 中创建一个键值对时，至少创建两个对象，一个对象是用做键值对的键对象，另一个是键值对的值对象。 例如我们执行 SET MSG XXX 时，键值对的键是一个包含了字符串“MSG“的对象，键值对的值对象是包含字符串”XXX”的对象。 redisObject 的结构如下： 123456789typedef struct redisObject&#123; //类型 unsigned type:4; //编码 unsigned encoding:4; //指向底层数据结构的指针 void *ptr; //... &#125;robj; 其中 type 字段记录了对象的类型，包含字符串对象、列表对象、哈希对象、集合对象、有序集合对象。ptr 指针字段指向对象底层实现的数据结构，而这些数据结构是由 encoding 字段决定的，每种对象至少有两种数据编码： 可以通过 object encoding key 来查看对象所使用 String 对象的编码转化String 对象的编码可以是 int 或 raw，对于 String 类型的键值，如果我们存储的是纯数字，Redis 底层采用的是 int 类型的编码，如果其中包括非数字，则会立即转为 raw 编码： 123456789127.0.0.1:6379&gt; set str 1OK127.0.0.1:6379&gt; object encoding str\"int\"127.0.0.1:6379&gt; set str 1aOK127.0.0.1:6379&gt; object encoding str\"raw\"127.0.0.1:6379&gt; List 对象的编码转化List 对象的编码可以是ziplist 或 linkedlist，对于 List 类型的键值，当列表对象同时满足以下两个条件时，采用 ziplist 编码： 列表对象保存的所有字符串元素的长度都小于 64 字节。 列表对象保存的元素个数小于 512 个。如果不满足这两个条件的任意一个，就会转化为 linkedlist 编码。注意：这两个条件是可以修改的，在 redis.conf 中：12list-max-ziplist-entries 512list-max-ziplist-value 64 Set 类型的编码转化Set 对象的编码可以是 intset 或 hashtable，intset 编码的结构对象使用整数集合作为底层实现，把所有元素都保存在一个整数集合里面。 12345127.0.0.1:6379&gt; sadd set 1 2 3(integer) 3127.0.0.1:6379&gt; object encoding set\"intset\"127.0.0.1:6379&gt; 如果 set 集合中保存了非整数类型的数据时，Redis 会将 intset 转化为 hashtable： 123456789127.0.0.1:6379&gt; sadd set 1 2 3(integer) 3127.0.0.1:6379&gt; object encoding set\"intset\"127.0.0.1:6379&gt; sadd set a(integer) 1127.0.0.1:6379&gt; object encoding set\"hashtable\" 127.0.0.1:6379&gt; 当 Set 对象同时满足以下两个条件时，对象采用 intset 编码： 保存的所有元素都是整数值（小数不行）。 Set 对象保存的所有元素个数小于 512 个。不能满足这两个条件的任意一个，Set 都会采用 hashtable 存储。注意：第两个条件是可以修改的，在 redis.conf 中：1set-max-intset-entries 512 Hash 对象的编码转化Hash 对象的编码可以是 ziplist 或 hashtable，当 Hash 以 ziplist 编码存储的时候，保存同一键值对的两个节点总是紧挨在一起，键节点在前，值节点在后：当 Hash 对象同时满足以下两个条件时，Hash 对象采用 ziplist 编码： Hash 对象保存的所有键值对的键和值的字符串长度均小于 64 字节。 Hash 对象保存的键值对数量小于 512 个。如果不满足以上条件的任意一个，ziplist 就会转化为 hashtable 编码。注意：这两个条件是可以修改的，在 redis.conf 中：12hash-max-ziplist-entries 512hash-max-ziplist-value 64 Zset 对象的编码转化Zset 对象的编码可以是 ziplist 或 zkiplist，当采用 ziplist 编码存储时，每个集合元素使用两个紧挨在一起的压缩列表来存储。 第一个节点存储元素的成员，第二个节点存储元素的分值，并且按分值大小从小到大有序排列。 当 Zset 对象同时满足一下两个条件时，采用 ziplist 编码： Zset 保存的元素个数小于 128。 Zset 元素的成员长度都小于 64 字节。如果不满足以上条件的任意一个，ziplist 就会转化为 zkiplist 编码。注意：这两个条件是可以修改的，在 redis.conf 中：12zset-max-ziplist-entries 128zset-max-ziplist-value 64","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Redis","slug":"后端/Redis","permalink":"http://xuchen.youtuc.cn/categories/后端/Redis/"}],"tags":[{"name":"面试","slug":"面试","permalink":"http://xuchen.youtuc.cn/tags/面试/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Redis","slug":"后端/Redis","permalink":"http://xuchen.youtuc.cn/categories/后端/Redis/"}]},{"title":"redis总结","slug":"Redis/redis总结","date":"2019-02-27T20:49:03.000Z","updated":"2021-05-04T08:26:08.000Z","comments":true,"path":"2019/02/27/Redis/redis总结/","link":"","permalink":"http://xuchen.youtuc.cn/2019/02/27/Redis/redis总结/","excerpt":"","text":"Redis为什么那么快 纯内存操作 单线程操作，避免了频繁的上下文切换 采用了非阻塞I/O多路复用机制 我们的redis-client在操作的时候，会产生具有不同事件类型的socket。在服务端，有一段I/0多路复用程序，将其置入队列之中。然后，文件事件分派器，依次去队列中取，转发到不同的事件处理器中。 Redis数据类型([底层数据]) String,Hash,List,Set,SortedSet Pub/Sub HyperLogLog(2.8.9版本新增):用来做基数统计的算法，HyperLogLog 的优点是，在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定 的、并且是很小的。使用场景最常见的就是计算网站UV等，对数据精度要求不高 Geo（3.2版本新增）：GEO(地理位置)的支持，主要是对经纬度一个位置计算等特性 BitMap BloomFilter Redis的过期策略以及内存淘汰机制 三种过期策略 定时删除：在设置键的过期时间的同时，创建一个定时器(timer)，让定时器在键的过期时间来临时，立即执行对键的删除操作； 惰性删除：放任键过期不管，但是每次从键空间中获取键时，都检查取得的键是否过期，如果过期的话，就删除该键；如果没有过期，那就返回该键； 定期删除：每隔一段时间，程序就对数据库进行一次检查，删除里面的过期键。至于删除多少过期键，以及要检查多少个数据库，则由算法决定。 Redis采用的是定期删除+惰性删策略。 为什么不用定时删除策略？定时删除策略需要定时器来监视key，过期则自动删除。虽然内存及时释放了，但是CPU消耗大。在大并发的情况下，这一策略得不偿失Redis采用的是定期删除+惰性删策略工作机制。 定期删除，redis默认每100ms检查一次是否存在过期key，有则删除。需要说明的是redis并不是100ms检查所有的key一次，而是随机进行抽取检查。因此，惰性删除派上用处。惰性删策略延伸出来的问题就是，redis缓存淘汰机制 Redis(3.0版本)6种缓存淘汰机制 no-enviction(驱逐)：禁止驱逐数据（不删除数据策略，达到最大的内存限制时，如果有更多的数据写入，返回错误给客户端） allkeys-lru：所有key通用，优先删除最少使用的key（less recently used,LRU算法） allkeys-random ：所有key通用，随机删除一部分key volatile-lru：只限于设置了expire的部分，优先删除最少使用的key（less recently used,LRU算法） volatile-random：只限于设置了 expire 的部分; 随机删除一部分key volatile-ttl：只限于设置了 expire 的部分; 优先删除剩余时间(time to live,TTL) 短的key。 注意：如果没有设置 expire 的key, 不满足先决条件(prerequisites); 那么 volatile-lru, volatile-random 和 volatile-ttl 策略的行为, 和 noeviction(不删除) 基本上一致。 一般来说：如果分为热数据与冷数据, 推荐使用allkeys-lru策略。 也就是, 其中一部分key经常被读写. 如果不确定具体的业务特征, 那么allkeys-lru是一个很好的选择。 如果需要循环读写所有的key, 或者各个key的访问频率差不多, 可以使用allkeys-random策略, 即读写所有元素的概率差不多。 假如要让 Redis 根据 TTL 来筛选需要删除的key, 请使用volatile-ttl策略。 Redis持久化原理 快照（特点：bgsave做镜像全量持久化）缺省情况下，Redis把数据快照存放在磁盘上的二进制文件中，文件名为dump.rdb。你可以配置Redis的持久化策略，例如数据集中每N秒钟有超过M次更新，就将数据写入磁盘；或者你可以手工调用命令SAVE或BGSAVE。工作原理: 主进程开启一个 Redis forks（子进程）. 子进程开始将数据写到临时RDB文件中。 当子进程完成写RDB文件，用新文件替换老文件。 bgsave的原理是什么？你给出两个词汇就可以了，fork和cow。fork是指redis通过创建子进程来进行bgsave操作，cow指的是copy on write，子进程创建后，父子进程共享数据段，父进程继续提供读写服务，写脏的页面数据会逐渐和子进程分离开来。 AOF（特点：AOF增量持久化） AOF持久化以日志的形式记录服务器所处理的每一个写、删除操作，查询操作不会记录，以文本的方式记录，可以打开文件看到详细的操作记录。 Redis主从复制(3.0开始支持)原理 全量同步 当启动一个slave node的时候，它会发送一个PSYNC命令给master 如果这是slave node重新链接master，master会将缺少的数据发送给slave，如果是第一次链接master，则会触发一次full resynchronization,开始 full resynchronization的时候，master启动一个后台线程，先将现有数据生成一个零时的rdb文件，生成文件后，master会将这个rdb文件发送给slave，slave会先把这个rdb文件存放到本地磁盘，然后在加载到内存，然后master会将生成rdb这段时间内接收到的在内存中的数据发送给slave，slave也会接收这份数据。 slave如果跟master网络故障，断开了，当重新连接上以后，master发现有多个slave都来重新连接，master会生成一个rdb文件，将这个文件同时发送个多个slave node 主从复制的断点续传 redis从2.8开始就支持断点续传功能，即当slave与master断开后，重新连接时，会继续从上一次断开的点继续传送数据，而不是full resynchronization。 master会在内存中创建一个backlog，master和slave都会保存一个offset,slave还有一个master id,offset就是保存在backlog中的，如果slave和master网络断开，重新连接后slave会让master从replica offset开始续传。但是如果没有找到offset，则会触发full resynchronization。 无磁盘化复制 master在内存中直接创建rdb,然后直接发送给slave,不会存入本地磁盘 参数配置repl-diskless-syncrepl-diskless-sync-delay, 等待一定时长在复制，因为要等更多的slave重新连接 过期key处理 slave不会有过期Key,只有master有过期key,如果master过期了一个可以或者通过LRU算法淘汰了一个key，那么master会模拟发送一个del命令给slave Redis-Cluster集群 所有的redis节点彼此互联(PING-PONG机制),内部使用二进制协议优化传输速度和带宽。 节点的fail是通过集群中超过半数的节点检测失效时才生效。 客户端与redis节点直连,不需要中间proxy层.客户端不需要连接集群所有节点,连接集群中任何一个可用节点即可。 redis-cluster把所有的物理节点映射到[0-16383]slot上（不一定是平均分配）,cluster 负责维护node&lt;-&gt;slot&lt;-&gt;value。 Redis集群预分好16384个桶，当需要在 Redis 集群中放置一个 key-value 时，根据 CRC16(key) mod 16384的值，决定将一个key放到哪个桶中。 为什么是16384（2^14）个？在redis节点发送心跳包时需要把所有的槽放到这个心跳包里，以便让节点知道当前集群信息，16384=16k，在发送心跳包时使用char进行bitmap压缩后是2k（2 * 8 (8 bit) * 1024(1k) = 2K），也就是说使用2k的空间创建了16k的槽数。 虽然使用CRC16算法最多可以分配65535（2^16-1）个槽位，65535=65k，压缩后就是8k（8 * 8 (8 bit) * 1024(1k) = 8K），也就是说需要需要8k的心跳包，作者认为这样做不太值得；并且一般情况下一个redis集群不会有超过1000个master节点，所以16k的槽位是个比较合适的选择。 Redis哨兵 在Server1 掉线后： 升级Server2 为新的主服务器： Sentinel的作用： Master 状态监测 如果Master 异常，则会进行Master-slave 转换，将其中一个Slave作为Master，将之前的Master作为Slave Master-Slave切换后，master_redis.conf、slave_redis.conf和sentinel.conf的内容都会发生改变，即master_redis.conf中会多一行slaveof的配置，sentinel.conf的监控目标会随之调换 Sentinel的工作方式: 每个Sentinel以每秒钟一次的频率向它所知的Master，Slave以及其他 Sentinel 实例发送一个 PING 命令 如果一个实例（instance）距离最后一次有效回复 PING 命令的时间超过 down-after-milliseconds 选项所指定的值， 则这个实例会被 Sentinel 标记为主观下线。 如果一个Master被标记为主观下线，则正在监视这个Master的所有 Sentinel 要以每秒一次的频率确认Master的确进入了主观下线状态。 当有足够数量的 Sentinel（大于等于配置文件指定的值）在指定的时间范围内确认Master的确进入了主观下线状态， 则Master会被标记为客观下线 在一般情况下， 每个 Sentinel 会以每 10 秒一次的频率向它已知的所有Master，Slave发送 INFO 命令 当Master被 Sentinel 标记为客观下线时，Sentinel 向下线的 Master 的所有 Slave 发送 INFO 命令的频率会从 10 秒一次改为每秒一次 若没有足够数量的 Sentinel 同意 Master 已经下线， Master 的客观下线状态就会被移除。 若 Master 重新向 Sentinel 的 PING 命令返回有效回复， Master 的主观下线状态就会被移除。 Redis和数据库双写一致性问题一致性问题是分布式系统常见问题，可以分为最终一致性和强一致性。所以弄清诉求数据库强一致性，不放缓存，我们所做的一切只是保证最终一致性，另外无法完全避免，讨论三种更新策略： 先更新数据库，再更新缓存 先删除缓存，再更新数据库 先更新数据库，再删除缓存 先更新数据库，再更新缓存这套方案，大家是普遍反对的，为什么呢？有如下两点原因： 原因一、线程安全问题，同时有请求A和请求B进行更新操作，那么会出现： 线程A更新了数据库 线程B更新了数据库 线程B更新了缓存 线程A更新了缓存 这就出现请求A更新缓存应该比请求B更新缓存早才对，但是因为网络等原因，B比A更早更新了缓存。这就导致了脏数据，因此不考虑！原因二、业务场景考虑 1）如果是写数据库场景比较多，读数据库场景比较少业务需求。&quot;先更新数据库，再更新缓存&quot;这种方案会导致，数据压根还没读到，缓存就被频繁的更新浪费性能 2）如果写入数据库是经过复杂计算以后再更新数据库，那么每次写入数据库后更新缓存，性能存在浪费 先删除缓存，再更新数据库 该方案会导致不一致的原因：同时有一个请求A进行更新操作，另一个请求B进行查询操作。那么就会出现以下情形： 情况一：多进程读写原因 123456请求A进行写操作，删除缓存请求B查询发现缓存不存在请求B去数据库查询得到旧值请求B将旧值写入缓存请求A将新值写入数据库上诉请求出现不一致的情况，如果没采用缓存过期策略。则缓存数据一直是脏数据。 情况二：MYSQL主从分离原因 123456请求A进行写操作，删除缓存；请求A将数据写入数据库了；请求B查询缓存发现，缓存没有值；请求B去从库查询，这时，还没有完成主从同步，因此查询到的是旧值；请求B将旧值写入缓存；数据库完成主从同步，从库变为新值； 解决方案：采用延迟双删策略。先删除缓存，再删除数据库，进程休眠1秒再次删除缓存 先更新数据库，再删除缓存这种情况不存在并发问题么？1234567不是的。假设这会有两个请求，一个请求A做查询操作，一个请求B做更新操作，那么会有如下情形产生：（1）缓存刚好失效；（2）请求A查询数据库，得一个旧值；（3）请求B将新值写入数据库；（4）请求B删除缓存；（5）请求A将查到的旧值写入缓存；ok，如果发生上述情况，确实是会发生脏数据。 解决方案：发生上述情况有一个先天性条件，就是6.1中步骤（3）的写数据库操作比步骤（2）的读数据库操作耗时更短，才有可能使得步骤（4）先于步骤（5）。可是，大家想想，数据库的读操作的速度远快于写操作的（不然做读写分离干嘛，做读写分离的意义就是因为读操作比较快，耗资源少），因此步骤（3）耗时比步骤（2）更短，这一情形很难出现。 首先，给缓存设有效时间是一种方案。其次，采用策略2（先删除缓存，再更新数据库）里给出的异步延时删除策略，保证读请求完成以后，再进行删除操作。 如何解决redis的并发竞争key问题分析:这个问题大致就是，同时有多个子系统去set一个key。这个时候要注意什么呢？大家思考过么。需要说明一下，博主提前百度了一下，发现答案基本都是推荐用redis事务机制。博主不推荐使用redis的事务机制。因为我们的生产环境，基本都是redis集群环境，做了数据分片操作。你一个事务中有涉及到多个key操作的时候，这多个key不一定都存储在同一个redis-server上。因此，redis的事务机制，十分鸡肋。 解决方案 如果对key操作不要求顺序 这种情况下，准备一个分布式锁，谁抢到锁谁set即可 如果对key操作要求顺序 假设有一个key1,系统A需要将key1设置为valueA,系统B需要将key1设置为valueB,系统C需要将key1设置为valueC. 期望按照key1的value值按照 valueA–&gt;valueB–&gt;valueC的顺序变化。这种时候我们在数据写入数据库的时候，需要保存一个时间戳。假设时间戳如下 系统A key 1 {valueA 3:00} 系统B key 1 {valueB 3:05} 系统C key 1 {valueC 3:10} 那么，假设这会系统B先抢到锁，将key1设置为{valueB 3:05}。接下来系统A抢到锁，发现自己的valueA的时间戳早于缓存中的时间戳，那就不做set操作了。以此类推。 或者使用队列，将set操作进行串联即可 redis常见性能问题和解决方案 Master写内存快照，save命令调度rdbSave函数，会阻塞主线程的工作，当快照比较大时对性能影响是非常大的，会间断性暂停服务，所以Master最好不要写内存快照。 Master AOF持久化，如果不重写AOF文件，这个持久化方式对性能的影响是最小的，但是AOF文件会不断增大，AOF文件过大会影响Master重启的恢复速度。Master最好不要做任何持久化工作，包括内存快照和AOF日志文件，特别是不要启用内存快照做持久化,如果数据比较关键，某个Slave开启AOF备份数据，策略为每秒同步一次。 Master调用BGREWRITEAOF重写AOF文件，AOF在重写的时候会占大量的CPU和内存资源，导致服务load过高，出现短暂服务暂停现象。 Redis主从复制的性能问题，为了主从复制的速度和连接的稳定性，Slave和Master最好在同一个局域网内 Redis6.0 多线程其实本质只是在网络IO上面实现了多线程读取和写入，然后进行执行队列，执行还是单线程加入多线程 IO 之后，整体的读流程如下: 主线程负责接收建连请求，读事件到来(收到请求)则放到一个全局等待读处理队列 主线程处理完读事件之后，通过 RR(Round Robin) 将这些连接分配给这些 IO 线程，然后主线程忙等待(spinlock 的效果)状态 IO 线程将请求数据读取并解析完成(这里只是读数据和解析并不执行) 主线程执行所有命令并清空整个请求等待读处理队列(执行部分串行) 上面的这个过程是完全无锁的，因为在 IO 线程处理的时主线程会等待全部的 IO 线程完成，所以不会出现data race的场景。 Redis新特性 Redis Module 任何C/C++程序现在都可以运行在Redis上 Modules是用一种本地的方式来扩展Redis的新用例和功能 使用现有的或者添加新的数据结构 享受简单，无限可扩展性和高可用性的同时保持着redis的本机的速度 Redis Search 高性能的全文搜索引擎（Faster, in-memory, highly available full text search），可作为Redis Module运行在Redis上。但是它与其他Redis搜索库不同的是，它不使用Redis内部数据结构，例如：集合、排序集（ps.后面会写一篇基于Redis的数据结构来设计搜索引擎），Redis原声的搜索还是有很大的局限性，简单的分词搜索是可以满足，但是应用到复杂的场景就不太适合。 Redis ML 机器学习模型服务器","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Redis","slug":"后端/Redis","permalink":"http://xuchen.youtuc.cn/categories/后端/Redis/"}],"tags":[{"name":"面试","slug":"面试","permalink":"http://xuchen.youtuc.cn/tags/面试/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Redis","slug":"后端/Redis","permalink":"http://xuchen.youtuc.cn/categories/后端/Redis/"}]},{"title":"golang的pprof使用技巧","slug":"Go/pprof","date":"2019-02-26T23:12:01.000Z","updated":"2020-05-18T05:44:55.000Z","comments":true,"path":"2019/02/26/Go/pprof/","link":"","permalink":"http://xuchen.youtuc.cn/2019/02/26/Go/pprof/","excerpt":"","text":"1.安装易用的pprofgolang自带的prof包是runtime/pprof，这个是低级别的，需要你手动做一些设置等等周边工作，不利于我们快速上手，利用pprof帮助我们解决实际的问题。这里推荐davecheney封装的pprof，它可以1行代码，让你用上pprof，专心解决自己的代码问题，下载： 1go get github.com/pkg/profile 2.安装graphvizpprof生成的prof文件时二进制的，需要把这个二进制的文件转换为我们人类可读的，graphviz可以帮助我们把二进制的prof文件转换为图像。Mac安装： 1brew install graphviz 3.修改main函数只需要为hi.go增加这一行，defer profile.Start().Stop()，程序运行时，默认就会记录cpu数据 4.编译运行你的函数12345678910111213141516171819202122232425262728package mainimport ( \"fmt\" \"github.com/pkg/profile\")func main() &#123; defer profile.Start().Stop() sl:=makeSlice() fmt.Printf(\"sum=%d\\n\",sumSlice(sl))&#125;func makeSlice() []int &#123; sl := make([]int, 10000000) for idx := range sl &#123; sl[idx] = idx &#125; return sl&#125;func sumSlice(sl []int) int &#123; sum := 0 for _, x := range sl &#123; sum += x &#125; return sum&#125; 运行代码 12go build hi.go./hi 应当看到类似的结果，它输出了生成的cpu.pprof的路径： 1232019/02/26 23:24:22 profile: cpu profiling enabled, /var/folders/zy/d8yskqjj09q21y7jnc0vbsqh0000gn/T/profile152894194/cpu.pprof sum=49999995000000 2019/02/26 23:24:22 profile: cpu profiling disabled, /var/folders/zy/d8yskqjj09q21y7jnc0vbsqh0000gn/T/profile152894194/cpu.pprof 5.可视化prof可视化有多种方式，可以转换为text、pdf、svg等等。text命令是 1go tool pprof --text /path/to/yourbinary /var/path/to/cpu.pprof 123456789101112131415161718192021go tool pprof --text ./hi /var/folders/zy/d8yskqjj09q21y7jnc0vbsqh0000gn/T/profile626723859/cpu.pprofFile: hiType: cpuTime: Feb 26, 2019 at 11:29pm (CST)Duration: 203.53ms, Total samples = 100ms (49.13%)Showing nodes accounting for 100ms, 100% of 100ms total flat flat% sum% cum cum% 60ms 60.00% 60.00% 60ms 60.00% runtime.usleep 30ms 30.00% 90.00% 30ms 30.00% main.makeSlice 10ms 10.00% 100% 10ms 10.00% runtime.nanotime 0 0% 100% 30ms 30.00% main.main 0 0% 100% 10ms 10.00% runtime.gcBgMarkWorker 0 0% 100% 70ms 70.00% runtime.gcBgMarkWorker.func2 0 0% 100% 70ms 70.00% runtime.gcDrain 0 0% 100% 30ms 30.00% runtime.main 0 0% 100% 70ms 70.00% runtime.markroot 0 0% 100% 70ms 70.00% runtime.markroot.func1 0 0% 100% 60ms 60.00% runtime.mstart 0 0% 100% 60ms 60.00% runtime.osyield 0 0% 100% 70ms 70.00% runtime.scang 0 0% 100% 70ms 70.00% runtime.systemstack 生成pdf图 1go tool pprof --pdf ./hi /var/folders/zy/d8yskqjj09q21y7jnc0vbsqh0000gn/T/profile626723859/cpu.pprof &gt; cpu.pdf 6.获取内存ppfo如果你掌握了cpu pprof，mem pprof轻而易举就能拿下，只需要改1行代码： 1defer profile.Start(profile.MemProfile).Stop()","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Golang","slug":"后端/Golang","permalink":"http://xuchen.youtuc.cn/categories/后端/Golang/"}],"tags":[],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Golang","slug":"后端/Golang","permalink":"http://xuchen.youtuc.cn/categories/后端/Golang/"}]},{"title":"缓存穿透、雪崩、击穿的解决方法","slug":"Redis/缓存穿透-雪崩-击穿的解决方法","date":"2019-02-20T15:08:31.000Z","updated":"2021-05-04T08:26:08.000Z","comments":true,"path":"2019/02/20/Redis/缓存穿透-雪崩-击穿的解决方法/","link":"","permalink":"http://xuchen.youtuc.cn/2019/02/20/Redis/缓存穿透-雪崩-击穿的解决方法/","excerpt":"","text":"1.缓存穿透缓存穿透是指查询一个一定不存在的数据，由于缓存是不命中时需要从数据库查询，查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到数据库查询，失去了缓存的意义。在流量大时，可能DB就挂掉了，要是有人利用不存在的key频繁攻击我们的应用，这就是漏洞。例如下图: 1.1解决办法 将不存在的key设置默认的值 如果有人利用ID攻击应用，可以将这个key预先设置一个null或者程序可判断的值，决定应用是否进行下面的执行。当缓存失效或者缓存key经过轮训以后不再为空，则进行程序的后续执行 布隆过滤器 简单的说，bloom算法类似一个hash set,用来判断某个元素的key是否存在集合中。和一般的hash set不同的是，这个算法无需存储key的值，值需要k个比特位，每个存在一个标志，用来判断key是否存在集合中。 算法： 首先需要k个hasn函数，每个函数可以把key散列成为1个整数 初始化时，需要一个长度为n比特的数组，每个比特位初始化为0 某个key加入集合时，用k个hash函数计算出k个散列值，并把数组中对应的比特位设置为1 判断某个key是否在集合时，用k个hash函数计算出k个散列值，并查询数组中对应的比特位，如果所有的比特位都是1，则认为在集合中 优点:不需要存储key，节省空间 缺点： 算法判断key在集合时，有一定的概率key其实不在集合中 无法删除 2.缓存雪崩大量的key设置了相同的过期时间，导致在缓存在同一时刻失效，造成DB的请求大、压力大，引起雪崩 2.1解决办法从业务层面。可以给缓存设置过期时间上加上一个随机值，使得每个key的过期时间分布开来，不会集中在同一时刻 3. 缓存击穿（并发）一个存在的key，在缓存过期的一刻，同时有大量的请求，这些请求都会击穿到DB，造成瞬时DB请求量大、压力骤增。 3.1解决办法 使用互斥锁：让一个线程构建缓存，其他线程等待等待构建缓存的线程执行完，从新从缓存中获取数据就行（如下图）如果是单机，可以用synchronize或者lock来处理，如果是分布式环境可以使用分布式锁（memcached的add、redis的setnx,zookeeper的添加节点）,当缓存构建完成以后释放分布式锁 后台刷新：定义个Job专门主动刷新缓存，比如缓存30分钟，那么Job可以设置每隔29分钟定时将DB数据刷新缓存中。这种方案适合key相对固定，cache粒度较大 检查更新：将缓存的过期时间（绝对时间）一起保存到缓存中（可以是key拼接，或者value中存放字段），在每次只需get操作以后都将get出来的缓存与当前系统时间进行比较，缓存时间-当前时间&lt;=1分钟（自定义时间阈值），则主动更新缓存 4. 如何解决缓存单机热点问题分布式缓存一致性hash算法解决简单概述： 一致性hash算法通过构造一个长度为2^32的整数环 根据节点名（或者服务器IP等信息）的hash值将缓存服务器节点放置在这个环上 计算需要缓存的key的hash值，顺时针找到最近的的服务器节点，将数据存放在该节点上","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Redis","slug":"后端/Redis","permalink":"http://xuchen.youtuc.cn/categories/后端/Redis/"}],"tags":[{"name":"面试","slug":"面试","permalink":"http://xuchen.youtuc.cn/tags/面试/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Redis","slug":"后端/Redis","permalink":"http://xuchen.youtuc.cn/categories/后端/Redis/"}]},{"title":"Go基础-信道","slug":"Go/base5.channel","date":"2019-01-21T22:20:39.000Z","updated":"2020-06-21T14:01:35.000Z","comments":true,"path":"2019/01/21/Go/base5.channel/","link":"","permalink":"http://xuchen.youtuc.cn/2019/01/21/Go/base5.channel/","excerpt":"","text":"信道是协程之间通信的管道，从一端发送数据，另一端接收数据。 信道声明 var c chan int,声明了 nil 信道。nil 信道没什么作用，既不能发送数据也不能接受数据 c:=make(chan int),使用 make 函数创建了可用的信道 c。 读写数据1234567c := make(chan int)// 写数据c &lt;- data // 读数据variable &lt;- c // 方式一&lt;- c // 方式二 解决生产环境使用timeSleep1234567891011121314func printHello(c chan bool) &#123; fmt.Println(\"hello world goroutine\") &lt;- c // 读取信道的数据&#125; func main() &#123; c := make(chan bool) go printHello(c) c &lt;- true // main 协程阻塞 fmt.Println(\"main goroutine\")&#125;//outputhello world goroutinemain goroutine 死锁（只读不写或者只读不写）12345func main() &#123; c := make(chan bool) c &lt;- true // 只写不读 fmt.Println(\"main goroutine\")&#125; 关闭信道与 for loop12345678910111213141516171819func printNums(ch chan int) &#123; for i := 0; i &lt; 10; i++ &#123; ch &lt;- i &#125; close(ch)&#125;func main() &#123; ch := make(chan int) go printNums(ch) for &#123; v, ok := &lt;-ch if ok == false &#123; // 通过 ok 判断信道是否关闭 fmt.Println(v, ok) break &#125; fmt.Println(v, ok) &#125;&#125; 缓冲信道和普通信道普通信道是无缓冲的，读写信道会立马阻塞当前协程。对于缓冲信道，写不会阻塞当前信道直到信道满了，同理，读操作也不会阻塞当前信道除非信道没数据 总结[channel总结]","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Golang","slug":"后端/Golang","permalink":"http://xuchen.youtuc.cn/categories/后端/Golang/"}],"tags":[{"name":"go基础","slug":"go基础","permalink":"http://xuchen.youtuc.cn/tags/go基础/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Golang","slug":"后端/Golang","permalink":"http://xuchen.youtuc.cn/categories/后端/Golang/"}]},{"title":"Go基础-接口","slug":"Go/base4.接口","date":"2019-01-20T22:20:39.000Z","updated":"2020-06-14T05:06:11.000Z","comments":true,"path":"2019/01/20/Go/base4.接口/","link":"","permalink":"http://xuchen.youtuc.cn/2019/01/20/Go/base4.接口/","excerpt":"","text":"什么是接口在一些面向对象的编程语言中，例如 Java、PHP 等，接口定义了对象的行为，只指定了对象应该做什么。行为的具体实现取决于对象。 在 Go 语言中，接口是一组方法的集合，但不包含方法的实现、是抽象的，接口中也不能包含变量。当一个类型 T 提供了接口中所有方法的定义时，就说 T 实现了接口。接口指定类型应该有哪些方法，类型决定如何去实现这些方法。 接口声明123type Shape interface &#123; Area() float32&#125; 上面的代码定义了接口类型 Shape，接口中包含了一个不带参数、返回值为 float32 的方法 Area()。任何实现了方法 Area() 的类型 T，我们就说它实现了接口 Shape。 123456789func main() &#123; var s Shape fmt.Println(\"value of s is\", s) fmt.Printf(\"type of s is %T\\n\", s)&#125;//outputvalue of s is &lt;nil&gt;type of s is &lt;nil&gt; 接口的类型值静态类型和动态类型 变量的类型在声明时指定、且不能改变，称为静态类型。 接口类型的静态值就是接口本身。 接口没有静态值，它指向的是动态值。 接口类型的变量存的是实现接口的类型的值。该值就是接口的动态值，实现接口的类型就是接口的动态类型。12345678910111213141516171819202122type Iname interface &#123; Mname()&#125;type St1 struct &#123;&#125;func (St1) Mname() &#123;&#125;type St2 struct &#123;&#125;func (St2) Mname() &#123;&#125;func main() &#123; var i Iname = St1&#123;&#125; fmt.Printf(\"type is %T\\n\",i) fmt.Printf(\"value is %v\\n\",i) i = St2&#123;&#125; fmt.Printf(\"type is %T\\n\",i) fmt.Printf(\"value is %v\\n\",i)&#125;//output type is main.St1value is &#123;&#125;type is main.St2value is &#123;&#125; 变量i的静态类型是Iname,是不能改变的。动态类型却是不固定的。第一次分配是 St1 第二次是St2,动态值都是空结构体有时候，接口的动态类型又称为具体类型，当访问的时候，返回的是底层的动态值类型 nil值1234567891011121314151617181920212223242526type Iname interface &#123; Mname()&#125;type St struct &#123;&#125;func (St) Mname() &#123;&#125;func main() &#123; var t *St if t == nil &#123; fmt.Println(\"t is nil\") &#125; else &#123; fmt.Println(\"t is not nil\") &#125; var i Iname = t fmt.Printf(\"%T\\n\", i) if i == nil &#123; fmt.Println(\"i is nil\") &#125; else &#123; fmt.Println(\"i is not nil\") &#125; fmt.Printf(\"i is nil pointer:%v\",i == (*St)(nil))&#125;//outputt is nil*main.Sti is not nili is nil pointer:true 当且仅当动态值和动态类型都为 nil 时，接口类型值才为 nil。上面的代码，给变量 i 赋值之后，i 的动态值是 nil，但是动态类型却是 *St， i 是一个 nil 指针，所以条件不成立。 Go语言规范： 1234var x interface&#123;&#125; // x is nil and has static type interface&#123;&#125;var v *T // v has value nil, static type *Tx = 42 // x has value 42 and dynamic type intx = v // x has value (*T)(nil) and dynamic type *T 实现接口123456789101112131415161718192021222324252627type Shape interface &#123; Area() float32&#125;type Rect struct &#123; width float32 height float32&#125;//结构体实现了接口func (r Rect) Area() float32 &#123; return r.width * r.height&#125;func main() &#123; var s Shape s = Rect&#123;5.0, 4.0&#125; r := Rect&#123;5.0, 4.0&#125; fmt.Printf(\"type of s is %T\\n\", s) fmt.Printf(\"value of s is %v\\n\", s) fmt.Println(\"area of rectange s\", s.Area()) fmt.Println(\"s == r is\", s == r)&#125;//outputtype of s is main.Rectvalue of s is &#123;5 4&#125;area of rectange s 20s == r is true 空接口1func Println(a ...interface&#123;&#125;) (n int, err error) &#123;&#125; 例如： 123456789101112131415161718192021type MyString stringtype Rect struct &#123; width float32 height float32&#125;func explain(i interface&#123;&#125;) &#123; fmt.Printf(\"type of s is %T\\n\", i) fmt.Printf(\"value of s is %v\\n\\n\", i)&#125;func main() &#123; ms := MyString(\"Seekload\") r := Rect&#123;5.0, 4.0&#125; explain(ms) explain(r)&#125;//outputtype of s is main.MyStringvalue of s is Seekloadtype of s is main.Rectvalue of s is &#123;5 4&#125; 上面的代码，创建了自定义的字符串类型 MyString 、结构体 Rect 和 explain() 函数。explain() 函数的形参是空接口，所以可以接收任意类型的值。 实现多个接口123456789101112131415161718192021222324252627282930type Shape interface &#123; Area() float32&#125; type Object interface &#123; Perimeter() float32&#125;type Circle struct &#123; radius float32&#125;func (c Circle) Area() float32 &#123; return math.Pi * (c.radius * c.radius)&#125;func (c Circle) Perimeter() float32 &#123; return 2 * math.Pi * c.radius&#125;func main() &#123; c := Circle&#123;3&#125; var s Shape = c var p Object = c fmt.Println(\"area: \", s.Area()) fmt.Println(\"perimeter: \", p.Perimeter())&#125;//outputarea: 28.274334perimeter: 18.849556 如果修改 12345fmt.Println(\"area: \", p.Area())fmt.Println(\"perimeter: \", s.Perimeter())//outputp.Area undefined (type Object has no field or method Area)s.Perimeter undefined (type Shape has no field or method Perimeter) 因为 s 的静态类型是 Shape，而 p 的静态类型是 Object，此问题可以使用类型断言 类型断言类型断言可以用来获取接口的底层值，通常的语法：i.(Type)，其中 i 是接口，Type 是类型或接口。编译时会自动检测 i 的动态类型与 Type 是否一致。 12345678910111213141516171819202122232425262728293031323334type Shape interface &#123; Area() float32&#125; type Object interface &#123; Perimeter() float32&#125;type Circle struct &#123; radius float32&#125;func (c Circle) Area() float32 &#123; return math.Pi * (c.radius * c.radius)&#125;func (c Circle) Perimeter() float32 &#123; return 2 * math.Pi * c.radius&#125;func main() &#123; var s Shape = Circle&#123;3&#125; c := s.(Circle) var p Object = c fmt.Printf(\"%T\\n\",c) fmt.Printf(\"%v\\n\",c) fmt.Println(\"area: \", c.Area()) fmt.Println(\"perimeter: \", c.Perimeter())&#125;//outputmain.Circle&#123;3&#125;area: 28.274334perimeter: 18.849556 上面的代码，我们可以通过 c 访问接口 s 的底层值，也可以通过 c 分别调用方法 Area() 和 Perimeter()，这就解决了上面遇到的问题。在语法 i.(Type) 中，如果 Type 没有实现 i 所属的接口，编译的时候会报错；或者 i 的动态值不是 Type，则会报 panic 错误。怎么解决呢？可以使用下面的语法:value, ok := i.(Type) 类型选择12345678910111213141516171819func switchType(i interface&#123;&#125;) &#123; switch i.(type) &#123; case string: fmt.Printf(\"string and value is %s\\n\", i.(string)) case int: fmt.Printf(\"int and value is %d\\n\", i.(int)) default: fmt.Printf(\"Unknown type\\n\") &#125;&#125;func main() &#123; switchType(\"Seekload\") switchType(27) switchType(true)&#125;//outputstring and value is Seekloadint and value is 27Unknown type 注意：只有接口类型才可以进行类型选择。其他类型，例如 int、string等是不能 接口嵌套Go 语言中，接口不能去实现别的接口也不能继承，但是可以通过嵌套接口创建新接口 1234567891011121314151617181920212223242526272829303132333435type Math interface &#123; Shape Object&#125;type Shape interface &#123; Area() float32&#125;type Object interface &#123; Perimeter() float32&#125;type Circle struct &#123; radius float32&#125;func (c Circle) Area() float32 &#123; return math.Pi * (c.radius * c.radius)&#125;func (c Circle) Perimeter() float32 &#123; return 2 * math.Pi * c.radius&#125;func main() &#123; c := Circle&#123;3&#125; var m Math = c fmt.Printf(\"%T\\n\", m ) fmt.Println(\"area: \", m.Area()) fmt.Println(\"perimeter: \", m.Perimeter())&#125;//outputmain.Circlearea: 28.274334perimeter: 18.849556 上面的代码，通过嵌套接口 Shape 和 Object，创建了新的接口 Math。任何类型如果实现了接口 Shape 和 Object 定义的方法，则说类型也实现了接口 Math，例如我们创建的结构体 Circle。主函数里面，定义了接口类型的变量 m，动态类型是结构体 Circle，注意下方法 Area 和 Perimeter 的调用方式，类似与访问嵌套结构体的成员。 使用指针接收者和值接收者实现接口12345678910111213141516171819202122232425262728293031type Shape interface &#123; Area() float32&#125;type Circle struct &#123; radius float32&#125;type Square struct &#123; side float32&#125;func (c Circle) Area() float32 &#123; return math.Pi * (c.radius * c.radius)&#125;func (s *Square) Area() float32 &#123; return s.side*s.side&#125;func main() &#123; var s Shape c1 := Circle&#123;3&#125; s = c1 fmt.Printf(\"%v\\n\",s.Area()) c2 := Circle&#123;4&#125; s = &amp;c2 fmt.Printf(\"%v\\n\",s.Area()) c3 := Square&#123;3&#125; //s = c3 s = &amp;c3 fmt.Printf(\"%v\\n\",s.Area())&#125; 上面的代码，结构体 Circle 通过值接收者实现了接口 Shape。值接收者的方法可以使用值或者指针调用，所以上面的 c1 和 c2 的调用方式是合法的。 结构体 Square 通过指针接收者实现了接口 Shape。如果将上方注释部分打开的话，编译就会出错： 12cannot use c3 (type Square) as type Shape in assignment:Square does not implement Shape (Area method has pointer receiver)","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Golang","slug":"后端/Golang","permalink":"http://xuchen.youtuc.cn/categories/后端/Golang/"}],"tags":[{"name":"go基础","slug":"go基础","permalink":"http://xuchen.youtuc.cn/tags/go基础/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Golang","slug":"后端/Golang","permalink":"http://xuchen.youtuc.cn/categories/后端/Golang/"}]},{"title":"Go基础-切片","slug":"Go/base3.切片","date":"2019-01-18T22:20:39.000Z","updated":"2020-06-13T13:19:52.000Z","comments":true,"path":"2019/01/18/Go/base3.切片/","link":"","permalink":"http://xuchen.youtuc.cn/2019/01/18/Go/base3.切片/","excerpt":"","text":"内部实现切片是基于数组实现的，它的底层是数组，它自己本身非常小，可以理解为对底层数组的抽象切片对象非常小，是因为它是只有3个字段的数据结构：一个是指向底层数组的指针，一个是切片的长度，一个是切片的容量 声明和初始化1slice:=make([]int,5) 使用内置的make函数时，需要传入一个参数，指定切片的长度，例子中我们使用的时5，这时候切片的容量也是5。当然我们也可以单独指定切片的容量。 1slice:=make([]int,5,10) 创建的切片长度是5，容量是10,需要注意的这个容量10其实对应的是切片底层数组的。 因为切片的底层是数组，所以创建切片时，如果不指定字面值的话，默认值就是数组的元素的零值。这里我们所以指定了容量是10，但是我们只能访问5个元素，因为切片的长度是5，剩下的5个元素，需要切片扩充后才可以访问。 容量必须&gt;=长度，我们是不能创建长度大于容量的切片的。 1slice:=[]int&#123;1,2,3,4,5&#125; 与创建数组非常像，只不过不用指定[]中的值，这时候切片的长度和容量是相等的，并且会根据我们指定的字面量推导出来 1slice:=[]int&#123;4:1&#125; 这是指定了第5个元素为1，其他元素都是默认值0。这时候切片的长度和容量也是一样的 数组和切片的微小差别12345678910//数组var arr [5]int//切片var slice []int//数组array:=[5]int&#123;4:1&#125;//切片slice:=[]int&#123;4:1&#125; nil切片和空切片1234//nil切片var nilSlice []int//空切片slice:=[]int&#123;&#125; 基于现有切片或者数组创建1234slice := []int&#123;1, 2, 3, 4, 5&#125;slice1 := slice[:]slice2 := slice[0:]slice3 := slice[:5] 使用[i:j]这样的操作符即可，她表示以i索引开始，到j索引结束,截取原数组或者切片，创建而成的新切片，新切片的值包含原切片的i索引，但是不包含j索引。slice[i:j)包含i,不包含j第3个用来限定新切片的容量，其用法为slice[i:j:k],k用来限定切片的容量。 12slice := []int&#123;1, 2, 3, 4, 5&#125;newSlice := slice[1:2:3] 一个长度为2-1=1，容量为3-1=2的新切片,不过第三个索引，不能超过原切片的最大索引值5 在函数间传递切片123456789101112131415func main() &#123; slice := []int&#123;1, 2, 3, 4, 5&#125; fmt.Printf(\"%p\\n\", &amp;slice) modify(slice) fmt.Println(slice)&#125;func modify(slice []int) &#123; fmt.Printf(\"%p\\n\", &amp;slice) slice[1] = 10&#125;0xc4200820600xc420082080[1 10 3 4 5] 观察发现，这两个切片的地址不一样，所以可以确认切片在函数间传递是复制的。而我们修改一个索引的值后，发现原切片的值也被修改了，说明它们共用一个底层数组。","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Golang","slug":"后端/Golang","permalink":"http://xuchen.youtuc.cn/categories/后端/Golang/"}],"tags":[{"name":"go基础","slug":"go基础","permalink":"http://xuchen.youtuc.cn/tags/go基础/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Golang","slug":"后端/Golang","permalink":"http://xuchen.youtuc.cn/categories/后端/Golang/"}]},{"title":"Go基础-字符串高效拼","slug":"Go/base2.字符串高效拼接","date":"2019-01-17T22:19:39.000Z","updated":"2020-06-13T12:05:41.000Z","comments":true,"path":"2019/01/17/Go/base2.字符串高效拼接/","link":"","permalink":"http://xuchen.youtuc.cn/2019/01/17/Go/base2.字符串高效拼接/","excerpt":"","text":"+号拼接这种拼接最简单，也最容易被我们使用，因为它是不限编程语言的，比如Go语言有，Java也有，它们是+号运算符，在运行时计算的。现在演示下这种拼接的代码，虽然比较简单。 1234567func StringPlus() string&#123; var s string s+=&quot;昵称&quot;+&quot;:&quot;+&quot;飞雪无情&quot;+&quot;\\n&quot; s+=&quot;博客&quot;+&quot;:&quot;+&quot;http://www.flysnow.org/&quot;+&quot;\\n&quot; s+=&quot;微信公众号&quot;+&quot;:&quot;+&quot;flysnow_org&quot; return s&#125; 我们可以自己写个用例测试下，可以打印出和我们例子中一样的内容。那么这种最常见的字符串拼接的方式性能怎么样的呢，我们测试下： 12345func BenchmarkStringPlus(b *testing.B) &#123; for i:=0;i&lt;b.N;i++&#123; StringPlus() &#125;&#125; 运行go test -bench=. -benchmem 查看性能输出如下： 1BenchmarkStringPlus-8 20000000 108 ns/op 144 B/op 2 allocs/op 每次操作需要108ns,进行2次内存分配，分配114字节的内存。 fmt 拼接这种拼接，借助于fmt.Sprint系列函数进行拼接，然后返回拼接的字符串。 123456789func StringFmt() string&#123; return fmt.Sprint(&quot;昵称&quot;,&quot;:&quot;,&quot;飞雪无情&quot;,&quot;\\n&quot;,&quot;博客&quot;,&quot;:&quot;,&quot;http://www.flysnow.org/&quot;,&quot;\\n&quot;,&quot;微信公众号&quot;,&quot;:&quot;,&quot;flysnow_org&quot;)&#125;func BenchmarkStringFmt(b *testing.B) &#123; for i:=0;i&lt;b.N;i++&#123; StringFmt() &#125;&#125; 运行查看测试结果： 1BenchmarkStringFmt-8 5000000 385 ns/op 80 B/op 1 allocs/op 虽然每次操作内存分配只有1次，分配80字节也不多，但是每次操作耗时太长，性能远没有+号操作快。 Join 拼接这个是利用strings.Join函数进行拼接，接受一个字符串数组，转换为一个拼接好的字符串。 12345678910func StringJoin() string&#123; s:=[]string&#123;&quot;昵称&quot;,&quot;:&quot;,&quot;飞雪无情&quot;,&quot;\\n&quot;,&quot;博客&quot;,&quot;:&quot;,&quot;http://www.flysnow.org/&quot;,&quot;\\n&quot;,&quot;微信公众号&quot;,&quot;:&quot;,&quot;flysnow_org&quot;&#125; return strings.Join(s,&quot;&quot;)&#125;func BenchmarkStringJoin(b *testing.B) &#123; for i:=0;i&lt;b.N;i++&#123; StringJoin() &#125;&#125; 为了方便，把性能测试的代码放一起了，现在看看性能测试的效果。 1BenchmarkStringJoin-8 10000000 177 ns/op 160 B/op 2 allocs/op 整体和+操作相差不了太多，大概低0.5倍的样子。 buffer 拼接这种被用的也很多，使用的是bytes.Buffer进行的字符串拼接，它是非常灵活的一个结构体，不止可以拼接字符串，还是可以byte,rune等，并且实现了io.Writer接口，写入也非常方便。 123456789101112131415161718192021func StringBuffer() string &#123; var b bytes.Buffer b.WriteString(&quot;昵称&quot;) b.WriteString(&quot;:&quot;) b.WriteString(&quot;飞雪无情&quot;) b.WriteString(&quot;\\n&quot;) b.WriteString(&quot;博客&quot;) b.WriteString(&quot;:&quot;) b.WriteString(&quot;http://www.flysnow.org/&quot;) b.WriteString(&quot;\\n&quot;) b.WriteString(&quot;微信公众号&quot;) b.WriteString(&quot;:&quot;) b.WriteString(&quot;flysnow_org&quot;) return b.String()&#125;func BenchmarkStringBuffer(b *testing.B) &#123; for i:=0;i&lt;b.N;i++&#123; StringBuffer() &#125;&#125; 看看他的性能，运行输出即可： 1BenchmarkStringBuffer-8 5000000 291 ns/op 336 B/op 3 allocs/op 好像并不是太好,和最差的fmt拼接差不多，和+号，Join拼接差好远，内存分配也比较多。每次操作耗时也很长。 builder 拼接为了改进buffer拼接的性能，从go 1.10 版本开始，增加了一个builder类型，用于提升字符串拼接的性能。它的使用和buffer几乎一样。 123456789101112131415161718192021func StringBuilder() string &#123; var b strings.Builder b.WriteString(&quot;昵称&quot;) b.WriteString(&quot;:&quot;) b.WriteString(&quot;飞雪无情&quot;) b.WriteString(&quot;\\n&quot;) b.WriteString(&quot;博客&quot;) b.WriteString(&quot;:&quot;) b.WriteString(&quot;http://www.flysnow.org/&quot;) b.WriteString(&quot;\\n&quot;) b.WriteString(&quot;微信公众号&quot;) b.WriteString(&quot;:&quot;) b.WriteString(&quot;flysnow_org&quot;) return b.String()&#125;func BenchmarkStringBuilder(b *testing.B) &#123; for i:=0;i&lt;b.N;i++&#123; StringBuilder() &#125;&#125; 官方都说比buffer性能好了，我们看看性能测试的结果。 1BenchmarkStringBuilder-8 10000000 170 ns/op 232 B/op 4 allocs/op 的确提升了，提升了一倍，虽然每次分配的内存次数有点多，但是每次分配的内存大小比buffer要少。 性能对比以上就是常用的字符串拼接的方式，现在我们把这些测试结果，汇总到一起，对比下看看,因为Benchmark的测试，对于性能只显示，我把测试的时间设置为3s（秒），把时间拉长便于对比测试，同时生成了cpu profile文件，用于性能分析。 运行go test xx.go -bench=. -benchmem -benchtime=3s -cpuprofile=profile.out得到如下测试结果： 12345StringPlus-8 50000000 112 ns/op 144 B/op 2 allocs/opStringFmt-8 20000000 344 ns/op 80 B/op 1 allocs/opStringJoin-8 30000000 171 ns/op 160 B/op 2 allocs/opStringBuffer-8 20000000 302 ns/op 336 B/op 3 allocs/opStringBuilder-8 30000000 171 ns/op 232 B/op 4 allocs/op 我们通过go tool pprof profile.out 看下我们输出的cpu profile信息。这里主要使用top命令。 1234567891011121314151617Showing top 15 nodes out of 89 flat flat% sum% cum cum% 11.99s 42.55% 42.55% 11.99s 42.55% runtime.kevent 6.30s 22.36% 64.90% 6.30s 22.36% runtime.pthread_cond_wait 1.65s 5.86% 70.76% 1.65s 5.86% runtime.pthread_cond_signal 1.11s 3.94% 74.70% 1.11s 3.94% runtime.usleep 1.10s 3.90% 78.60% 1.10s 3.90% runtime.pthread_cond_timedwait_relative_np 0.58s 2.06% 80.66% 0.62s 2.20% runtime.wbBufFlush1 0.51s 1.81% 82.47% 0.51s 1.81% runtime.memmove 0.44s 1.56% 84.03% 1.81s 6.42% fmt.(*pp).printArg 0.39s 1.38% 85.42% 2.36s 8.37% fmt.(*pp).doPrint 0.36s 1.28% 86.69% 0.70s 2.48% fmt.(*buffer).WriteString (inline) 0.34s 1.21% 87.90% 0.93s 3.30% runtime.mallocgc 0.20s 0.71% 88.61% 1.20s 4.26% fmt.(*fmt).fmtS 0.18s 0.64% 89.25% 0.18s 0.64% fmt.(*fmt).truncate 0.16s 0.57% 89.82% 0.16s 0.57% runtime.memclrNoHeapPointers 0.15s 0.53% 90.35% 1.35s 4.79% fmt.(*pp).fmtString 前15个，可以看到fmt拼接的方式是最差的，因为fmt里很多方法耗时排在了最前面。buffer的WriteString方法也比较耗时。 以上的TOP可能还不是太直观，如果大家看火焰图的话，就会更清晰。性能最好的是+号拼接、Join拼接，最慢的是fmt拼接，这里的builder和buffer拼接差不多，并没有发挥出其能力。 疑问从整个性能的测试和分析来看，我们期待的builder并没有发挥出来，这是不是意味着builder不实用了呢？还不如+号和Join拼接呢？继续接着分析,猜测可能原因如下： 拼接的字符串大小 拼接的字符串数量 拼接函数改造前面提到了2种可能的猜测，拼接字符串的数量和拼接字符串的大小，现在我们就开始证明这两种情况，为了演示方便，我们把原来的拼接函数修改一下，可以接受一个[]string类型的参数，这样我们就可以对切片数组进行字符串拼接，这里直接给出所有的拼接方法的改造后实现。 12345678910111213141516171819202122232425262728293031323334func StringPlus(p []string) string&#123; var s string l:=len(p) for i:=0;i&lt;l;i++&#123; s+=p[i] &#125; return s&#125;func StringFmt(p []interface&#123;&#125;) string&#123; return fmt.Sprint(p...)&#125;func StringJoin(p []string) string&#123; return strings.Join(p,&quot;&quot;)&#125;func StringBuffer(p []string) string &#123; var b bytes.Buffer l:=len(p) for i:=0;i&lt;l;i++&#123; b.WriteString(p[i]) &#125; return b.String()&#125;func StringBuilder(p []string) string &#123; var b strings.Builder l:=len(p) for i:=0;i&lt;l;i++&#123; b.WriteString(p[i]) &#125; return b.String()&#125; 测试用例以上的字符串拼接函数修改后，我们就可以构造不同大小的切片进行字符串拼接测试了。为了模拟上次的效果，我们先用10个切片大小的字符串进行拼接测试。 1234567891011121314151617const BLOG = &quot;http://www.flysnow.org/&quot;func initStrings(N int) []string&#123; s:=make([]string,N) for i:=0;i&lt;N;i++&#123; s[i]=BLOG &#125; return s;&#125;func initStringi(N int) []interface&#123;&#125;&#123; s:=make([]interface&#123;&#125;,N) for i:=0;i&lt;N;i++&#123; s[i]=BLOG &#125; return s;&#125; 这是两个构建测试用例切片数组的函数，可以生成N个大小的切片。第二个initStringi函数返回的是[]interface{}，这是专门为StringFmt(p []interface{})拼接函数准备的，减少类型之间的转换。 有了这两个生成测试用例的函数，我们就可以构建我们的Go语言性能测试了，我们先测试10个大小的切片。 123456789101112131415161718192021222324252627282930313233343536373839func BenchmarkStringPlus10(b *testing.B) &#123; p:= initStrings(10) b.ResetTimer() for i:=0;i&lt;b.N;i++&#123; StringPlus(p) &#125;&#125;func BenchmarkStringFmt10(b *testing.B) &#123; p:= initStringi(10) b.ResetTimer() for i:=0;i&lt;b.N;i++&#123; StringFmt(p) &#125;&#125;func BenchmarkStringJoin10(b *testing.B) &#123; p:= initStrings(10) b.ResetTimer() for i:=0;i&lt;b.N;i++&#123; StringJoin(p) &#125;&#125;func BenchmarkStringBuffer10(b *testing.B) &#123; p:= initStrings(10) b.ResetTimer() for i:=0;i&lt;b.N;i++&#123; StringBuffer(p) &#125;&#125;func BenchmarkStringBuilder10(b *testing.B) &#123; p:= initStrings(10) b.ResetTimer() for i:=0;i&lt;b.N;i++&#123; StringBuilder(p) &#125;&#125; 在每个性能测试函数中，我们都会调用b.ResetTimer()，这是为了避免测试用例准备时间不同，带来的性能测试效果偏差问题我们运行go test -bench=. -run=NONE -benchmem 查看结果。 12345BenchmarkStringPlus10-8 3000000 593 ns/op 1312 B/op 9 allocs/opBenchmarkStringFmt10-8 5000000 335 ns/op 240 B/op 1 allocs/opBenchmarkStringJoin10-8 10000000 200 ns/op 480 B/op 2 allocs/opBenchmarkStringBuffer10-8 3000000 452 ns/op 864 B/op 4 allocs/opBenchmarkStringBuilder10-8 10000000 231 ns/op 480 B/op 4 allocs/op 通过这次我们可以看到，+号拼接不再具有优势，因为string是不可变的，每次拼接都会生成一个新的string,也就是会进行一次内存分配，我们现在是10个大小的切片，每次操作要进行9次进行分配，占用内存，所以每次操作时间都比较长，自然性能就低下。 文章上面关于+拼接还有印象，+加号拼接的性能测试中显示的只有2次内存分配，但是我们用了好多个+的。 1234567func StringPlus() string&#123; var s string s+=&quot;昵称&quot;+&quot;:&quot;+&quot;飞雪无情&quot;+&quot;\\n&quot; s+=&quot;博客&quot;+&quot;:&quot;+&quot;http://www.flysnow.org/&quot;+&quot;\\n&quot; s+=&quot;微信公众号&quot;+&quot;:&quot;+&quot;flysnow_org&quot; return s&#125; 再来回顾下这段代码，的确是有很多+的，但是只有2次内存分配，我们可以大胆猜测,是3次s+=导致的，正常和我们今天测试的10个长度的切片，只有9次内存分配一样。下面我们通过运行如下命令看下Go编译器对这段代码的优化：go build -gcflags=&quot;-m -m&quot; main.go,输出中有如下内容： 1can inline StringPlus as: func() string &#123; var s string; s = &lt;N&gt;; s += &quot;昵称:飞雪无情\\n&quot;; s += &quot;博客:http://www.flysnow.org/\\n&quot;; s += &quot;微信公众号:flysnow_org&quot;; return s &#125; 现在一目了然了，其实是编译器帮我们把字符串做了优化，只剩下3个s+= 这次，采用长度为10个切片进行测试，也很明显测试出了Builder要比Buffer性能好很多，这个问题原因主要还是[]byte和string之间的转换，Builder恰恰解决了这个问题。 123func (b *Builder) String() string &#123; return *(*string)(unsafe.Pointer(&amp;b.buf))&#125; 很高效的解决方案。 100个字符串现在我们测试下100个字符串拼接的情况，对于我们上面的代码，要改造非常容易，这里直接给出测试代码。 123456789101112131415161718192021222324252627282930313233343536373839func BenchmarkStringPlus100(b *testing.B) &#123; p:= initStrings(100) b.ResetTimer() for i:=0;i&lt;b.N;i++&#123; StringPlus(p) &#125;&#125;func BenchmarkStringFmt100(b *testing.B) &#123; p:= initStringi(100) b.ResetTimer() for i:=0;i&lt;b.N;i++&#123; StringFmt(p) &#125;&#125;func BenchmarkStringJoin100(b *testing.B) &#123; p:= initStrings(100) b.ResetTimer() for i:=0;i&lt;b.N;i++&#123; StringJoin(p) &#125;&#125;func BenchmarkStringBuffer100(b *testing.B) &#123; p:= initStrings(100) b.ResetTimer() for i:=0;i&lt;b.N;i++&#123; StringBuffer(p) &#125;&#125;func BenchmarkStringBuilder100(b *testing.B) &#123; p:= initStrings(100) b.ResetTimer() for i:=0;i&lt;b.N;i++&#123; StringBuilder(p) &#125;&#125; 现在运行性能测试，看看100个字符串连接的性能怎么样，哪个函数最高效。 12345BenchmarkStringPlus100-8 100000 19711 ns/op 123168 B/op 99 allocs/opBenchmarkStringFmt100-8 500000 2615 ns/op 2304 B/op 1 allocs/opBenchmarkStringJoin100-8 1000000 1516 ns/op 4608 B/op 2 allocs/opBenchmarkStringBuffer100-8 500000 2333 ns/op 8112 B/op 7 allocs/opBenchmarkStringBuilder100-8 1000000 1714 ns/op 6752 B/op 8 allocs/op +号和我们上面分析得一样，这次是99次内存分配，性能体验越来越差，在后面的测试中，会排除掉。 fmt和bufrer已经的性能也没有提升，继续走低。剩下比较坚挺的是Join和Builder。 1000 个字符串。测试用力和上面章节的大同小异，所以我们直接看测试结果。 12345BenchmarkStringPlus1000-8 1000 1611985 ns/op 12136228 B/op 999 allocs/opBenchmarkStringFmt1000-8 50000 28510 ns/op 24590 B/op 1 allocs/opBenchmarkStringJoin1000-8 100000 15050 ns/op 49152 B/op 2 allocs/opBenchmarkStringBuffer1000-8 100000 23534 ns/op 122544 B/op 11 allocs/opBenchmarkStringBuilder1000-8 100000 17996 ns/op 96224 B/op 16 allocs/op 整体和100个字符串的时候差不多，表现好的还是Join和Builder。这两个方法的使用侧重点有些不一样， 如果有现成的数组、切片那么可以直接使用Join,但是如果没有，并且追求灵活性拼接，还是选择Builder。 Join还是定位于有现成切片、数组的（毕竟拼接成数组也要时间），并且使用固定方式进行分解的，比如逗号、空格等，局限比较大。 小结至于10000个字符串拼接我这里就不做测试了，大家可以自己试试，看看是不是大同小异的。 从最近的这两篇文章的分析来看，我们大概可以总结出。 连接适用于短小的、常量字符串（明确的，非变量），因为编译器会给我们优化。 Join是比较统一的拼接，不太灵活 fmt和buffer基本上不推荐 builder从性能和灵活性上，都是上佳的选择。 Builder 慢在哪在前面可以看出来少量拼接，builder并不明显，那么到底慢在哪里呢？既然要优化Builder拼接，那么我们起码知道他慢在哪，我们继续使用我们上篇文章的测试用例，运行看下性能。 1234Builder10-8 5000000 258 ns/op 480 B/op 4 allocs/opBuilder100-8 1000000 2012 ns/op 6752 B/op 8 allocs/opBuilder1000-8 100000 21016 ns/op 96224 B/op 16 allocs/opBuilder10000-8 10000 195098 ns/op 1120226 B/op 25 allocs/op 针对既然要优化Builder拼接,采取了10、100、1000、10000四种不同数量的字符串进行拼接测试。我们发现每次操作都有不同次数的内存分配，内存分配越多，越慢，如果引起GC，就更慢了，首先我们先优化这个，减少内存分配的次数。 内存分配优化通过cpuprofile，查看生成的火焰图可以得知，runtime.growslice函数会被频繁的调用，并且时间占比也比较长。我们查看Builder.WriteString的源代码： 12345func (b *Builder) WriteString(s string) (int, error) &#123; b.copyCheck() b.buf = append(b.buf, s...) return len(s), nil&#125; 可以肯定是append方法触发了runtime.growslice，因为b.buf的容量cap不足，所以需要调用runtime.growslice扩充b.buf的容量，然后才可以追加新的元素s...。扩容容量自然会涉及到内存的分配，而且追加的内容越多，内存分配的次数越多，这和我们上面性能测试的数据是一样的。 既然问题的原因找到了，那么我们就可以优化了，核心手段就是减少runtime.growslice调用，甚至不调用。照着这个思路的话，我们就要提前为b.buf分配好容量cap。幸好Builder为我们提供了扩充容量的方法Grow，我们在进行WriteString之前，先通过Grow方法，扩充好容量即可。 现在开始改造我们的StringBuilder函数。 123456789func StringBuilder(p []string,cap int) string &#123; var b strings.Builder l:=len(p) b.Grow(cap) for i:=0;i&lt;l;i++&#123; b.WriteString(p[i]) &#125; return b.String()&#125; 增加一个参数cap，让使用者告诉我们需要的容量大小。Grow方法的实现非常简单，就是一个通过make函数，扩充b.buf大小，然后再拷贝b.buf的过程。 12345func (b *Builder) grow(n int) &#123; buf := make([]byte, len(b.buf), 2*cap(b.buf)+n) copy(buf, b.buf) b.buf = buf&#125; 那么现在我们的性能测试用例变成如下： 1234567891011121314151617func BenchmarkStringBuilder10(b *testing.B) &#123; p:= initStrings(10) cap:=10*len(BLOG) b.ResetTimer() for i:=0;i&lt;b.N;i++&#123; StringBuilder(p,cap) &#125;&#125;func BenchmarkStringBuilder1000(b *testing.B) &#123; p:= initStrings(1000) cap:=1000*len(BLOG) b.ResetTimer() for i:=0;i&lt;b.N;i++&#123; StringBuilder(p,cap) &#125;&#125; 为了说明情况和简短代码，这里只有10和1000个元素的用例，其他类似。为了把性能优化到极致，我一次性把需要的容量分配足够。现在我们再运行性能（Benchmark）测试代码。 1234Builder10-8 10000000 123 ns/op 352 B/op 1 allocs/opBuilder100-8 2000000 898 ns/op 2688 B/op 1 allocs/opBuilder1000-8 200000 7729 ns/op 24576 B/op 1 allocs/opBuilder10000-8 20000 78678 ns/op 237568 B/op 1 allocs/op 性能足足翻了1倍多，只有1次内存分配，每次操作占用的内存也减少了一半多，降低了GC。 总结背后的原理也非常清楚，就是预先分配内存，减少append过程中的内存重新分配和数据拷贝，这样我们就可以提升很多的性能。所以对于可以预见的长度的切，都可以提前申请申请好内存。 本文收集来源：https://www.flysnow.org","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Golang","slug":"后端/Golang","permalink":"http://xuchen.youtuc.cn/categories/后端/Golang/"}],"tags":[],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Golang","slug":"后端/Golang","permalink":"http://xuchen.youtuc.cn/categories/后端/Golang/"}]},{"title":"Go基础-iota","slug":"Go/base1.iota","date":"2019-01-16T22:00:40.000Z","updated":"2020-06-13T12:05:36.000Z","comments":true,"path":"2019/01/16/Go/base1.iota/","link":"","permalink":"http://xuchen.youtuc.cn/2019/01/16/Go/base1.iota/","excerpt":"","text":"iota-go语言中的常量计数器，只能在常量表达式中使用 iota只能在常量的表达式中使用。12fmt.Println(iota) 编译错误： undefined: iota 每次 const 出现时，都会让 iota 初始化为0.【自增长】12345const a = iota // a=0const ( b = iota //b=0 c //c=1) 枚举类型定义12345678910111213type Weekday intconst ( Sunday Weekday = iota Monday Tuesday Wednesday Thursday Friday Saturday)//可以类似调用枚举类一样调用println(Weekday(Saturday)) 可跳过的值123456789type AudioOutput intconst ( OutMute AudioOutput = iota // 0 OutMono // 1 OutStereo // 2 _ _ OutSurround // 5) 位掩码表达式iota 可以做更多事情，而不仅仅是 increment。更精确地说，iota 总是用于 increment，但是它可以用于表达式，在常量中的存储结果值。 1234567const ( IgEggs Allergen = 1 &lt;&lt; iota // 1 &lt;&lt; 0 which is 00000001 IgChocolate // 1 &lt;&lt; 1 which is 00000010 IgNuts // 1 &lt;&lt; 2 which is 00000100 IgStrawberries // 1 &lt;&lt; 3 which is 00001000 IgShellfish // 1 &lt;&lt; 4 which is 00010000) 定义bit单位123456789101112type ByteSize float64const ( _ = iota // ignore first value by assigning to blank identifier KB ByteSize = 1 &lt;&lt; (10 * iota) // 1 &lt;&lt; (10*1) MB // 1 &lt;&lt; (10*2) GB // 1 &lt;&lt; (10*3) TB // 1 &lt;&lt; (10*4) PB // 1 &lt;&lt; (10*5) EB // 1 &lt;&lt; (10*6) ZB // 1 &lt;&lt; (10*7) YB // 1 &lt;&lt; (10*8)) 定义在一行的情况(iota 在下一行增长，而不是立即取得它的引用)注意他们是逗号分隔常量，并不是换行 场景一 12345678const ( Apple, Banana = iota , iota Cherimoya, Durian Elderberry, Fig)// Apple: 0, Banana: 0,// Cherimoya: 1, Durian: 1, // Elderberry: 2, Fig: 2 场景二,每一换行都按照前一行的表达式进行增加 12345678const ( Apple, Banana = iota+1 , iota+1 Cherimoya, Durian Elderberry, Fig)// Apple: 1, Banana: 1,// Cherimoya: 2, Durian: 2, // Elderberry: 3, Fig: 3 中间插队1234567const ( i = iota j = 3.14 k = iota l)那么打印出来的结果是 i=0,j=3.14,k=2,l=3","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Golang","slug":"后端/Golang","permalink":"http://xuchen.youtuc.cn/categories/后端/Golang/"}],"tags":[{"name":"go基础","slug":"go基础","permalink":"http://xuchen.youtuc.cn/tags/go基础/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Golang","slug":"后端/Golang","permalink":"http://xuchen.youtuc.cn/categories/后端/Golang/"}]},{"title":"Go基础-基本类型","slug":"Go/base0.基础概念","date":"2019-01-15T22:00:39.000Z","updated":"2021-05-04T08:26:08.000Z","comments":true,"path":"2019/01/15/Go/base0.基础概念/","link":"","permalink":"http://xuchen.youtuc.cn/2019/01/15/Go/base0.基础概念/","excerpt":"","text":"内建类型种类 bool：布尔类型,可选 true|false,默认初始化零值 false 整型8bit=1字节，int(8)表示8个bit位 类型 字节 取值 (u)int(8) 2^0=1 2^8=-127~128 (u)int(16) 2^1=2 2^16 (u)int(32) 2^2=4 2^32 (u)int(64) 2^3=8 2^64 (u)int 跟随操作系统位数(32or64位) - uintptr:一个足够大的无符号整型， 用来表示任意地址;一个uintptr是一个整数，不是一个引用。把一个Pointer转换为uintptr后，实际是剥离了原有的指针的语义，只取了地址的整数值。p = unsafe.Pointer( uintptr ( p ) + offset ) byte(uint8) , rune(int32)，string byte :最基础字节类型,是 uint8 类型的别名 rune : Go 中的字符类型,是 int32 的别名 string值用 “” 或者 `` 包括, `` 可包含多行字符串,字符串的内容在初始化后，不能被修改，但可重新完全赋值，字符串的操作与数组相同 float32 , float64 , complex64 , complex1288bit=1字节，float32表示32个bit位，刚好4个字节 类型 字节 取值 float32 4 - float64 8 - complex64 8 - complex128 16 - 内建类型特点 类型转换只有显示转换,不存在任何形式的隐式类型转换 虽然提供指针类型,但指针本身不能进行任何形式的计算 变量声明后有默认初始化零值,变量零值视具体类型而定 init函数特点 主要作用 初始化不能采用初始化表达式初始化的变量。 程序运行前的注册。 实现sync.Once功能。 其他 特点 init() 函数是用于程序执行前做包的初始化的函数，比如初始化包里的变量等; 一个包可以出线多个 init() 函数,一个源文件也可以包含多个 init() 函数； 同一个包中多个 init() 函数的执行顺序没有明确定义，但是不同包的init函数是根据包导入的依赖关系决定的（看下图）; init() 函数在代码中不能被显示调用、不能被引用（赋值给函数变量），否则出现编译错误; 一个包被引用多次，如 A import B,C import B,A import C，B 被引用多次，但 B 包只会初始化一次； 引入包，不可出现死循坏。即 A import B,B import A，这种情况编译失败； .(type)的使用类型选择，类型选择的语法形如：i.(type)，其中 i 是接口，type 是固定关键字，需要注意的是，只有接口类型才可以使用类型选择","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Golang","slug":"后端/Golang","permalink":"http://xuchen.youtuc.cn/categories/后端/Golang/"}],"tags":[{"name":"go基础","slug":"go基础","permalink":"http://xuchen.youtuc.cn/tags/go基础/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"Golang","slug":"后端/Golang","permalink":"http://xuchen.youtuc.cn/categories/后端/Golang/"}]},{"title":"栈和队列","slug":"LeetCode/Data/Link-栈和队列","date":"2018-11-23T19:45:14.000Z","updated":"2021-05-04T08:26:08.000Z","comments":true,"path":"2018/11/23/LeetCode/Data/Link-栈和队列/","link":"","permalink":"http://xuchen.youtuc.cn/2018/11/23/LeetCode/Data/Link-栈和队列/","excerpt":"","text":"栈概念 栈（英语：stack）又称为堆栈或堆叠，栈作为一种数据结构，是一种只能在一端进行插入和删除操作的特殊线性表。它按照先进后出的原则存储数据，先进入的数据被压入栈底，最后的数据在栈顶，需要读数据的时候从栈顶开始弹出数据（最后一个数据被第一个读出来）。栈具有记忆作用，对栈的插入与删除操作中，不需要改变栈底指针。 栈是允许在同一端进行插入和删除操作的特殊线性表。允许进行插入和删除操作的一端称为栈顶(top)，另一端为栈底(bottom)；栈底固定，而栈顶浮动；栈中元素个数为零时称为空栈。插入一般称为进栈（PUSH），删除则称为退栈（POP）。 由于堆叠数据结构只允许在一端进行操作，因而按照后进先出（LIFO, Last In First Out）的原理运作。栈也称为后进先出表。 这里以羽毛球筒为例，羽毛球筒就是一个栈，刚开始羽毛球筒是空的，也就是空栈，然后我们一个一个放入羽毛球，也就是一个一个push进栈，当我们需要使用羽毛球的时候，从筒里面拿，也就是pop出栈，但是第一个拿到的羽毛球是我们最后放进去的。 操作流程示意图 完整代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455type Stack struct &#123; Array []interface&#123;&#125; //栈切片存储&#125;func (stack *Stack) Push(value ...interface&#123;&#125;) &#123; stack.Array = append(stack.Array, value...)&#125;//返回下一个元素func (stack *Stack) Top() (value interface&#123;&#125;) &#123; if stack.Size() &gt; 0 &#123; return stack.Array[stack.Size()-1] &#125; return nil //read empty stack&#125;//返回下一个元素,并从Stack移除元素func (stack *Stack) Pop() interface&#123;&#125; &#123; if stack.Size() &gt; 0 &#123; value := stack.Array[stack.Size()-1] stack.Array = stack.Array[:stack.Size()-1] return value &#125; panic(\"Stack为空.\") //read empty stack&#125;//交换值func (stack *Stack) Swap(other *Stack) &#123; switch &#123; case stack.Size() == 0 &amp;&amp; other.Size() == 0: return case other.Size() == 0: other.Array = stack.Array[:stack.Size()] stack.Array = nil case stack.Size() == 0: stack.Array = other.Array other.Array = nil default: stack.Array, other.Array = other.Array, stack.Array &#125; return&#125;//返回指定索引的元素func (stack *Stack) Get(idx int) (value interface&#123;&#125;) &#123; if idx &gt;= 0 &amp;&amp; stack.Size() &gt; 0 &amp;&amp; stack.Size() &gt; idx &#123; return stack.Array[idx] &#125; return nil&#125;//Stack的sizefunc (stack *Stack) Size() int &#123; return len(stack.Array)&#125; 栈-反转字符串12345678str := \"hello,word\"ss := &amp;stack.Stack&#123;&#125;for _, v := range str &#123; ss.Push(string(v))&#125;for ss.Size() &gt; 0 &#123; fmt.Print(ss.Pop())&#125; 共享栈1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586package stackimport &quot;fmt&quot;//共享栈const MaxDoubleSize = 20 //存储空间初始分配量type DoubleStack struct &#123; data [MaxDoubleSize]int //数组最大值 top1 int //栈1栈顶指针 top2 int //栈2栈顶指针&#125;// 初始化一个空栈func (d *DoubleStack) InitStack() &#123; d.top1 = -1 d.top2 = MaxDoubleSize&#125;// 把d置为空栈func (d *DoubleStack) ClearStack() &#123; d.top1 = -1 d.top2 = MaxDoubleSize&#125;// 若栈l为空栈，则返回true 否则返回falsefunc (d *DoubleStack) IsEmpty() bool &#123; if d.top1 == -1 &amp;&amp; d.top2 == MaxDoubleSize &#123; return true &#125; else &#123; return false &#125;&#125;// 返回s的元素个数，即栈的长度func (d *DoubleStack) Length() int &#123; return (d.top1 + 1) + (MaxDoubleSize - 1 - d.top2)&#125;/**value 插入元素e为新的栈顶元素stackNum 选择插入的栈*/func (d *DoubleStack) Push(value int, stackNum int) error &#123; if d.top1+1 == d.top2 &#123; panic(&quot;stack is full&quot;) &#125; // 栈1有元素进栈 if stackNum == 1 &#123; d.top1++ d.data[d.top1] = value &#125; else if stackNum == 2 &#123; // 栈2有元素进栈 d.top2-- d.data[d.top2] = value &#125; return nil&#125;// 若栈不空，则删除d的栈顶元素 用e返回其值,否则返回errorfunc (d *DoubleStack) Pop(stackNum int) (value int) &#123; if stackNum == 1 &#123; if d.top1 == -1 &#123; fmt.Errorf(&quot;stack is empty&quot;) //栈1为空，已溢出 &#125; value = d.data[d.top1] d.top1-- &#125; else if stackNum == 2 &#123; if d.top2 == MaxDoubleSize &#123; fmt.Errorf(&quot;stack is empty&quot;) //栈2为空，已溢出 &#125; value = d.data[d.top2] d.top2++ &#125; return value&#125;//遍历栈func (d *DoubleStack) Traverse() &#123; for i := 0; i &lt;= d.top1; i++ &#123; fmt.Println(d.data[i]) &#125; for i := d.top2; i &lt; MaxDoubleSize; i++ &#123; fmt.Println(d.data[i]) &#125;&#125; 队列实现队列其实和栈一样，只是队列是先进先出，那么只需要每次弹出第一个元素即可 123456789//返回下一个元素,并从Stack移除元素func (stack *Stack) Pop() interface&#123;&#125; &#123; if stack.Size() &gt; 0 &#123; value := stack.Array[0] stack.Array = stack.Array[1:] return value &#125; panic(\"Stack为空.\") //read empty stack&#125; 总结 栈、队列（单向队列）、优先级队列通常是用来简化某些程序操作的数据结构，而不是主要作为存储数据的。 在这些数据结构中，只有一个数据项可以被访问。 栈允许在栈顶压入（插入）数据，在栈顶弹出（移除）数据，但是只能访问最后一个插入的数据项，也就是栈顶元素。 队列（单向队列）只能在队尾插入数据，对头删除数据，并且只能访问对头的数据。而且队列还可以实现循环队列，它基于数组，数组下标可以从数组末端绕回到数组的开始位置。 优先级队列是有序的插入数据，并且只能访问当前元素中优先级别最大（或最小）的元素。 这些数据结构都能由数组实现，但是可以用别的机制（链表、堆等数据结构）实现。","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"数据结构","slug":"后端/数据结构","permalink":"http://xuchen.youtuc.cn/categories/后端/数据结构/"}],"tags":[{"name":"栈和队列","slug":"栈和队列","permalink":"http://xuchen.youtuc.cn/tags/栈和队列/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"数据结构","slug":"后端/数据结构","permalink":"http://xuchen.youtuc.cn/categories/后端/数据结构/"}]},{"title":"双向链表","slug":"LeetCode/Data/Link-双向链表","date":"2018-11-21T17:45:14.000Z","updated":"2021-05-04T08:26:08.000Z","comments":true,"path":"2018/11/21/LeetCode/Data/Link-双向链表/","link":"","permalink":"http://xuchen.youtuc.cn/2018/11/21/LeetCode/Data/Link-双向链表/","excerpt":"","text":"示意图 双向链表：只有一个指针指向最开始的结点。 双端(双向)链表：有两个指针分别指向两端的节点。 循环(双向)链表：指向形成一个闭环。：有两个指针分别指向两端的节点。 完整代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176type DobuleNode struct &#123; Prev *DobuleNode Data int Next *DobuleNode&#125;type DoubleLinkList struct &#123; first *DobuleNode last *DobuleNode&#125;func (this *DoubleLinkList) DoubleLinkList() &#123; this.first = nil this.last = nil&#125;func (this *DoubleLinkList) IsEmpty() bool &#123; return this.first == nil&#125;func (this *DoubleLinkList) GetHead() *DobuleNode &#123; return this.first&#125;func (this *DoubleLinkList) SetHead(head *DobuleNode) &#123; this.first = head&#125;/**头部添加*/func (this *DoubleLinkList) AddHead(data int) &#123; node := &amp;DobuleNode&#123;Data: data&#125; if this.IsEmpty() &#123; this.last = node &#125; else &#123; this.first.Prev = node node.Next = this.first &#125; this.first = node&#125;/**头部删除*/func (this *DoubleLinkList) DelHead() *DobuleNode &#123; if this.IsEmpty() &#123; return nil &#125; tmp := this.first if this.first.Next == nil &#123; this.first.Next.Prev = nil &#125; this.first = this.first.Next return tmp&#125;/**尾部添加*/func (this *DoubleLinkList) Append(data int) &#123; node := &amp;DobuleNode&#123;Data: data&#125; if this.IsEmpty() &#123; this.first = node &#125; else &#123; this.last.Next = node node.Prev = this.last &#125; this.last = node&#125;/**获取数据*/func (this *DoubleLinkList) Get(i int) int &#123; currentNode := this.first //当前节点指向首节点 j := 0 for currentNode != nil &amp;&amp; j &lt; i &#123; j++ currentNode = currentNode.Next &#125; if i &lt; 0 || currentNode == nil &#123; panic(fmt.Sprintf(\"第%d个元素不存在\", i)) &#125; return currentNode.Data&#125;func (this *DoubleLinkList) Length() int &#123; cur := this.first length := 0 for cur != nil &#123; length++ cur = cur.Next &#125; return length&#125;func (this *DoubleLinkList) Insert(i int, data int) &#123; node := &amp;DobuleNode&#123;Data: data&#125; if i &lt;= 0 &#123; this.AddHead(data) &#125; else if i &gt; this.Length() &#123; this.Append(data) &#125; else &#123; cur := this.first j := 0 for j &lt; i-1 &#123; j++ cur = cur.Next &#125; next := cur.Next cur.Next = node node.Prev = cur node.Next = next next.Prev = node &#125;&#125;func (this *DoubleLinkList) Remove(data int) bool &#123; if this.IsEmpty() &#123; panic(\"链表数据为空\") return false &#125; cur := this.first for cur != nil &#123; if cur.Data == data &#123; pre := cur.Prev next := cur.Next pre.Next = next next.Prev = pre return true &#125; cur = cur.Next &#125; return false&#125;/**链表翻转倒置链表的方法reversed()：把每个节点的左右节点交换，并且把链表的首尾节点也交换，就可以了。这里需要考虑的是循环的终止条件。*/func (this *DoubleLinkList) reverse() &#123; head := this.first if head == nil &#123; panic(\"链表数据为空\") &#125; for &#123; //左右节点指针交互即可 tmp := head.Prev head.Prev = head.Next head.Next = tmp if head.Prev == nil &#123; break &#125; else &#123; head = head.Prev &#125; &#125; this.first = head&#125;/**打印数据*/func (this *DoubleLinkList) Display() &#123; head := this.first sb := &amp;strings.Builder&#123;&#125; sb.WriteString(\"[\") for head != nil &#123; sb.WriteString(strconv.Itoa(head.Data) + \"-&gt;\") head = head.Next &#125; sb.WriteString(\"]\") fmt.Println(sb.String())&#125; 遍历法-反转倒置链表的方法reversed()：把每个节点的左右节点交换，并且把链表的首尾节点也交换，就可以了。这里需要考虑的是循环的终止条件。 1234567891011121314151617181920func (this *DoubleLinkList) reverse() &#123; head := this.first if head == nil &#123; panic(\"链表数据为空\") &#125; for &#123; //左右节点指针交互即可 tmp := head.Prev head.Prev = head.Next head.Next = tmp if head.Prev == nil &#123; break &#125; else &#123; head = head.Prev &#125; &#125; this.first = head&#125;","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"数据结构","slug":"后端/数据结构","permalink":"http://xuchen.youtuc.cn/categories/后端/数据结构/"}],"tags":[{"name":"链表","slug":"链表","permalink":"http://xuchen.youtuc.cn/tags/链表/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"数据结构","slug":"后端/数据结构","permalink":"http://xuchen.youtuc.cn/categories/后端/数据结构/"}]},{"title":"单向链表","slug":"LeetCode/Data/Link-单向链表","date":"2018-11-21T17:45:14.000Z","updated":"2021-05-04T08:26:08.000Z","comments":true,"path":"2018/11/21/LeetCode/Data/Link-单向链表/","link":"","permalink":"http://xuchen.youtuc.cn/2018/11/21/LeetCode/Data/Link-单向链表/","excerpt":"","text":"操作流程示意图 完整代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141type Node struct &#123; Data int Next *Node&#125;type SingleLinkedList struct &#123; head *Node&#125;func (this *SingleLinkedList) SingleLinkedList() &#123; this.head = nil&#125;func (this *SingleLinkedList) SetHead(head *Node) &#123; this.head = head&#125;func (this *SingleLinkedList) GetHead() *Node &#123; return this.head&#125;func (this *SingleLinkedList) IsEmpty() bool &#123; return this.head == nil&#125;/**获取链表长度*/func (this *SingleLinkedList) Length() int &#123; currentNode := this.head length := 0 for currentNode != nil &#123; length++ currentNode = currentNode.Next &#125; return length&#125;/**清空链表*/func (this *SingleLinkedList) Clean() &#123; this.head = nil&#125;/**获取数据*/func (this *SingleLinkedList) Get(i int) int &#123; currentNode := this.head //当前节点指向首节点 j := 0 for currentNode != nil &amp;&amp; j &lt; i &#123; j++ currentNode = currentNode.Next &#125; if i &lt; 0 || currentNode == nil &#123; panic(fmt.Sprintf(\"第%d个元素不存在\", i)) &#125; return currentNode.Data&#125;/**头部插入*/func (this *SingleLinkedList) AddHead(data int) &#123; node := &amp;Node&#123;Data: data, Next: nil&#125; node.Next = this.head this.head = node&#125;/**头部删除*/func (this *SingleLinkedList) DelHead() &#123; this.head = this.head.Next&#125;/**从尾部追加*/func (this *SingleLinkedList) Append(data int) &#123; node := &amp;Node&#123;Data: data, Next: nil&#125; currentNode := this.head //当前节点指向首节点 for currentNode.Next != nil &#123; currentNode = currentNode.Next &#125; currentNode.Next = node&#125;/**打印数据*/func (this *SingleLinkedList) Display() &#123; head := this.head sb := &amp;strings.Builder&#123;&#125; sb.WriteString(\"[\") for head != nil &#123; sb.WriteString(strconv.Itoa(head.Data) + \"-&gt;\") head = head.Next &#125; sb.WriteString(\"]\") fmt.Println(sb.String())&#125;func (this *SingleLinkedList) insert(i int, data int) &#123; if i &lt; 0 &#123; this.AddHead(data) &#125; else if i &gt; this.Length() &#123; this.Append(data) &#125; else &#123; pre := this.head count := 0 for count &lt; i &#123; pre = pre.Next count++ &#125; node := &amp;Node&#123;Data: data&#125; node.Next = pre.Next pre.Next = node &#125;&#125;/**移除数据*/func (this *SingleLinkedList) remove(data int) &#123; curr := this.head if curr.Data == data &#123; this.head = curr.Next &#125; else &#123; for curr.Next != nil &#123; if curr.Next.Data == data &#123; curr.Next = curr.Next.Next &#125; else &#123; curr = curr.Next &#125; &#125; &#125; 递归法-反转递归反转法：在反转当前节点之前先反转后续节点。这样从头结点开始，层层深入直到尾结点才开始反转指针域的指向。简单的说就是从尾结点开始，逆向反转各个结点的指针域指向，其过程图如下所示： head：是前一结点的指针域（PS：前一结点的指针域指向当前结点） head.getNext()：是当前结点的指针域（PS：当前结点的指针域指向下一结点） reHead：是反转后新链表的头结点（即原来单链表的尾结点） 12345678910func (this *SingleLinkedList) reverse(head *Node) *Node &#123; if head == nil || head.Next == nil &#123; return head &#125; next := head.Next new_head := this.reverse(next) next.Next = head head.Next = nil return new_head&#125; 结果 123456newHead := l.reverse(l.GetHead())l.SetHead(newHead)l.Display()//output[69-&gt;3-&gt;97-&gt;171-&gt;118-&gt;122-&gt;][122-&gt;118-&gt;171-&gt;97-&gt;3-&gt;69-&gt;] 遍历法-反转1234567891011121314151617func (this *SingleLinkedList) reverse2(head *Node) *Node &#123; if head == nil || head.Next == nil &#123; return head &#125; var pre *Node //前一节点 cur := head //当前节点 var next *Node // 下一结点 for cur != nil &#123; // 当前结点为null，说明位于尾结点 next = cur.Next //nextNode 指向下一个节点 cur.Next = pre //将当前节点next域指向前一个节点 pre = cur //preNode 指针向后移动 cur = next //curNode指针向后移动 &#125; return pre&#125;","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"数据结构","slug":"后端/数据结构","permalink":"http://xuchen.youtuc.cn/categories/后端/数据结构/"}],"tags":[{"name":"链表","slug":"链表","permalink":"http://xuchen.youtuc.cn/tags/链表/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"数据结构","slug":"后端/数据结构","permalink":"http://xuchen.youtuc.cn/categories/后端/数据结构/"}]},{"title":"mysql总结","slug":"Mysql/mysql总结","date":"2018-08-24T15:23:09.000Z","updated":"2021-05-04T08:26:08.000Z","comments":true,"path":"2018/08/24/Mysql/mysql总结/","link":"","permalink":"http://xuchen.youtuc.cn/2018/08/24/Mysql/mysql总结/","excerpt":"","text":"宏观了解 查询缓存我们先通过show variables like &#39;%query_cache%&#39;来看一下默认的数据库配置，query_cache_type=ON 原理：MYSQL的查询缓存实质上是缓存SQL的hash值和该SQL的查询结果，如果运行相同的SQL,服务器直接从缓存中去掉结果，而不再去解析，优化，寻找最低成本的执行计划等一系列操作，大大提升了查询速度。 弊端：执行的SQL语句必须一样（大小写，间隔等），如果不一样将会产生不同的hash值 场景：通过观察云厂商，大部分情况下都是关闭查询缓存 引擎 MyISAM存储引擎 MyISAM基于ISAM存储引擎，并对其进行扩展。使用MyISAM引擎创建数据库，将产生3个文件,文件的名字以表名字开始，扩展名之处文件类型：frm文件存储表定义、数据文件的扩展名为.MYD（MYData）、索引文件的扩展名时.MYI（MYIndex）。MyISAM拥有较高的插入、查询速度，但不支持事物。MyISAM主要特性有： 大文件（达到63位文件长度）在支持大文件的文件系统和操作系统上被支持 当把删除和更新及插入操作混合使用的时候，动态尺寸的行产生更少碎片。这要通过合并相邻被删除的块，以及若下一个块被删除，就扩展到下一块自动完成 每个MyISAM表最大索引数是64，这可以通过重新编译来改变。每个索引最大的列数是16 最大的键长度是1000字节，这也可以通过编译来改变，对于键长度超过250字节的情况，一个超过1024字节的键将被用上 BLOB和TEXT列可以被索引 NULL被允许在索引的列中，这个值占每个键的0~1个字节 所有数字键值以高字节优先被存储以允许一个更高的索引压缩 每个MyISAM类型的表都有一个AUTO_INCREMENT的内部列，当INSERT和UPDATE操作的时候该列被更新，同时AUTO_INCREMENT列将被刷新。所以说，MyISAM类型表的AUTO_INCREMENT列更新比InnoDB类型的AUTO_INCREMENT更快 可以把数据文件和索引文件放在不同目录 每个字符列可以有不同的字符集 有VARCHAR的表可以固定或动态记录长度 VARCHAR和CHAR列可以多达64KB InnoDB存储引擎 InnoDB不创建目录，使用InnoDB时，MySQL将在MySQL数据目录下创建一个名为ibdata1的10MB大小的自动扩展数据文件，以及两个名为ib_logfile0和ib_logfile1的5MB大小的日志文件 InnoDB是事务型数据库的首选引擎，支持事务安全表（ACID），支持行锁定和外键，InnoDB是默认的MySQL引擎。InnoDB主要特性有： InnoDB给MySQL提供了具有提交、回滚和崩溃恢复能力的事物安全（ACID兼容）存储引擎。InnoDB锁定在行级并且也在SELECT语句中提供一个类似Oracle的非锁定读。这些功能增加了多用户部署和性能。在SQL查询中，可以自由地将InnoDB类型的表和其他MySQL的表类型混合起来，甚至在同一个查询中也可以混合 InnoDB是为处理巨大数据量的最大性能设计。它的CPU效率可能是任何其他基于磁盘的关系型数据库引擎锁不能匹敌的 InnoDB存储引擎完全与MySQL服务器整合，InnoDB存储引擎为在主内存中缓存数据和索引而维持它自己的缓冲池。InnoDB将它的表和索引在一个逻辑表空间中，表空间可以包含数个文件（或原始磁盘文件）。这与MyISAM表不同，比如在MyISAM表中每个表被存放在分离的文件中。InnoDB表可以是任何尺寸，即使在文件尺寸被限制为2GB的操作系统上 InnoDB支持外键完整性约束，存储表中的数据时，每张表的存储都按主键顺序存放，如果没有显示在表定义时指定主键，InnoDB会为每一行生成一个6字节的ROWID，并以此作为主键 MySQL中myisam与innodb的区别 InnoDB支持事物，而MyISAM不支持事物 InnoDB支持行级锁，而MyISAM支持表级锁 InnoDB支持MVCC, 而MyISAM不支持 InnoDB支持外键，而MyISAM不支持 InnoDB不支持全文索引，而MyISAM支持（5.6版本已经支持了） MYSQL引擎的文件包含（.frm-表结构文件、.myd-表数据文件，.myi-表索引文件） InnoDB引擎包含文件（*.frm-表结构文件，ibd-数据和索引文件） 索引 聚集索引InnoDB的主键索引与行记录是存储在一起的，故叫做聚集索引（Clustered Index）： 非聚集索引MyISAM的索引与行记录是分开存储的，叫做非聚集索引（UnClustered Index）。 联合索引多个字段上建立的索引，能够加速复核查询条件的检索。所以该索引也有最左匹配原则，5.6版本延伸出来的索引下推见下文 举个说明，不妨设有表：t(id PK, name KEY, sex, flag); 画外音：id是聚集索引，name是普通索引。 mysql的索引方法btree和hash的区别 hash memory引擎才显示的支持Hash索引，innoDb默认是B+树 Hash 索引仅仅能满足”=”,”IN”和”&lt;= &amp; &gt;=”查询，不能使用范围查询。 Hash 索引无法被用来避免数据的排序操作。 Hash 索引不能利用部分索引键查询。 Hash 索引在任何时候都不能避免表扫描。 Hash 索引遇到大量Hash值相等的情况后性能并不一定就会比B-Tree索引高。 btree 与hash的缺点就是btree的特点 哈希(hash)比树(tree)更快，索引结构为什么要设计成树型？ 加速查找速度的数据结构，常见的有两类：1) 哈希，例如HashMap，查询/插入/修改/删除的平均时间复杂度都是O(1)；2) 树，例如平衡二叉搜索树，查询/插入/修改/删除的平均时间复杂度都是O(lg(n))；可以看到，不管是读请求，还是写请求，哈希类型的索引，都要比树型的索引更快一些，那为什么，索引结构要设计成树型呢？ 索引设计成树形，和SQL的需求相关。对于这样一个单行查询的SQL需求：select * from t where name=”shenjian”;确实是哈希索引更快，因为每次都只查询一条记录。画外音：所以，如果业务需求都是单行访问，例如passport，确实可以使用哈希索引但是对于排序查询的SQL需求分组：group by 排序：order by 比较：&lt;、&gt;哈希型的索引，时间复杂度会退化为O(n)，而树型的“有序”特性，依然能够保持O(log(n)) 的高效率。 数据库索引为什么使用B+树？ B+树了解 二叉搜索树 二叉搜索树，如上图，是最为大家所熟知的一种数据结构，就不展开介绍了，它为什么不适合用作数据库索引？ (1)当数据量大的时候，树的高度会比较高，数据量大的时候，查询会比较慢； (2)每个节点只存储一个记录，可能导致一次查询有很多次磁盘IO； B树 B树，如上图，它的特点是： (1)不再是二叉搜索，而是m叉搜索； (2)叶子节点，非叶子节点，都存储数据； (3)中序遍历，可以获得所有节点； 树被作为实现索引的数据结构被创造出来，是因为它能够完美的利用“局部性原理”。 什么是回表查询？ InnoDB聚集索引和普通索引有什么差异？InnoDB聚集索引的叶子节点存储行记录，因此， InnoDB必须要有，且只有一个聚集索引： 如果表定义了PK，则PK就是聚集索引； 如果表没有定义PK，则第一个not NULL unique列是聚集索引； 否则，InnoDB会创建一个隐藏的row-id作为聚集索引； 所以PK查询非常快，直接定位行记录。 InnoDB普通索引的叶子节点存储主键值。注意，不是存储行记录头指针，MyISAM的索引叶子节点存储记录指针。 回表查询过程举个栗子，不妨设有表：t(id PK, name KEY, sex, flag);表中有四条记录： 12341, shenjian, m, A3, zhangsan, m, A5, lisi, m, A9, wangwu, f, B 两个B+树索引分别如上图： （1）id为PK，聚集索引，叶子节点存储行记录； （2）name为KEY，普通索引，叶子节点存储PK值，即id；既然从普通索引无法直接定位行记录，那普通索引的查询过程是怎么样的呢？通常情况下，需要扫码两遍索引树。例如： 1select * from t where name='lisi'; 如红色路径，需要扫码两遍索引树：（1）先通过普通索引定位到主键值id=5；（2）在通过聚集索引定位到行记录；这就是回表查询 索引覆盖(Covering index)？ 什么是索引覆盖 MySQL官网，类似的说法出现在explain查询计划优化章节，即explain的输出结果Extra字段为Using index时，能够触发索引覆盖。 不管是SQL-Server官网，还是MySQL官网，都表达了：只需要在一棵索引树上就能获取SQL所需的所有列数据，无需回表，速度更快。 如何实现索引覆盖？能够命中name索引，索引叶子节点存储了主键id，通过name的索引树即可获取id和name，无需回表，符合索引覆盖，效率较高。 能够命中name索引，索引叶子节点存储了主键id，但sex字段必须回表查询才能获取到，不符合索引覆盖，需要再次通过id值扫码聚集索引获取sex字段，效率会降低。 如果把(name)单列索引升级为联合索引(name, sex)就不同了。都能够命中索引覆盖，无需回表。 哪些场景可以利用索引覆盖来优化SQL？ 全表count查询优化 场景2：列查询回表优化(同上面的例子) 非常隐蔽的全表扫描，不能命中索引 列类型与where 值类型不符合不能命中索引，会导致全表扫描 相join的两个表的字符编码不同，不能命中索引，会导致迪卡尔积的运算 数据库主键索引不宜太长？？（特指InnoDB） MyISAM引擎，无影响。原因：进行检索时，会先从索引树定位到记录指针，再通过指针定位到具体的记录 InnoDB通过主键索引查询时，能够直接定位到行记录。 原因：身份证号id_code是一个比较长的字符串，每个索引都存储这个值，在数据量大，内存珍贵的情况下，MySQL有限的缓冲区，存储的索引与数据会减少，磁盘IO的概率会增加。同时，索引占用的磁盘空间也会增加。 总结（1）MyISAM的索引与数据分开存储，索引叶子存储指针，主键索引与普通索引无太大区别；（2）InnoDB的聚集索引和数据行统一存储，聚集索引存储数据行本身，普通索引存储主键；（3）InnoDB不建议使用太长字段作为PK（此时可以加入一个自增键PK），MyISAM则无所谓； like查询一定不命中索引吗？mysql在使用like查询，%在最前面不会用到索引，中间或最后是会用到索引的，只是越靠前扫描的行数越多 索引下推 例如对于user_table表，我们现在有（username,age）联合索引，如果现在有一个需求，查出名称中以“张”开头且年龄小于等于10的用户信息，语句如下：”select * from user_table where username like ‘张%’ and age &gt; 10”. 索引下推：like ‘zhang%’and age &gt;10 检索，MySQL5.6版本之前，会对匹配的数据进行回表查询。5.6版本后，会先过滤掉age&lt;10的数据，再进行回表查询，减少回表率，提升检索速度 注意： innodb引擎的表，索引下推只能用于二级索引。 原因：innodb的主键索引树叶子结点上保存的是全行数据，所以这个时候索引下推并不会起到减少查询全行数据的效果。 索引下推一般可用于所求查询字段（select列）不是/不全是联合索引的字段，查询条件为多条件查询且查询条件子句（where/order by）字段全是联合索引。 假设表t有联合索引（a,b）,下面语句可以使用索引下推提高效率select * from t where a &gt; 2 and b &gt; 10; 日志 MySQL多少种日志 错误日志：记录mysql启动和运行的出错信息，也记录一些警告信息或者正确的信息，在my.cnf中log_error指定路径。 查询日志：记录所有对数据库请求的信息，不论这些请求是否得到了正确的执行。 慢查询日志：设置一个阈值（log_query_time），将运行时间超过该值的所有SQL语句都记录到慢查询的日志文件中。 二进制日志：又叫做bin-log日志，纪录所有的写操作(增改删)，纪录一些执行时间，执行时长，数据变更等。主要用于恢复、复制、审计，生成的文件格式mysql-bin.001..等一系列序号。 中继日志：理解上relay log很多方面都跟binary log差不多。区别是：从服务器I/O线程将主服务器的二进制日志读取过来记录到从服务器本地文件，然后SQL线程会读取relay-log日志的内容并应用到从服务器，从而使从服务器和主服务器的数据保持一致 事务日志： 事务日志文件名为ib_logfile0和ib_logfile1，默认存放在表空间所在目录 MySQL binlog的几种日志录入格式以及区别 格式：Statement,Row，Mixedlevel 区别: 基于语句纪录（Statement ）:每一条会修改数据的sql都会记录在binlog中 优点：只需要记录执行语句的细节和上下文环境，避免了记录每一行的变化，在一些修改记录较多的情况下相比ROW level能大大减少binlog日志量，节约IO，提高性能；还可以用于实时的还原； 缺点：为了保证sql语句能在slave上正确执行，必须记录上下文信息，以保证所有语句能在slave得到和在master端执行时候相同的结果；另外，主从复制时，存在部分函数（如sleep）及存储过程在slave上会出现与master结果不一致的情况，而相比Row level记录每一行的变化细节，绝不会发生这种不一致的情况. 基于行（Row）：仅保存记录被修改细节，不记录sql语句上下文相关信息。 优点： 能非常清晰的记录下每行数据的修改细节，不需要记录上下文相关信息，因此不会发生某些特定情况下的procedure、function、及trigger的调用触发无法被正确复制的问题，任何情况都可以被复制，且能加快从库重放日志的效率，保证从库数据的一致性 缺点:由于所有的执行的语句在日志中都将以每行记录的修改细节来记录，因此，可能会产生大量的日志内容，干扰内容也较多；比如一条update语句，如修改多条记录，则binlog中每一条修改都会有记录，这样造成binlog日志量会很大，特别是当执行alter table之类的语句的时候，由于表结构修改，每条记录都发生改变，那么该表每一条记录都会记录到日志中，实际等于重建了表。 混合模式（Mixedlevel）：是以上两种level的混合使用一般的语句修改使用statment格式保存binlog，如一些函数，statement无法完成主从复制的操作，则 采用row格式保存binlog,MySQL会根据执行的每一条具体的sql语句来区分对待记录的日志形式，也就是在Statement和Row之间选择 一种.新版本的MySQL中队row level模式也被做了优化，并不是所有的修改都会以row level来记录，像遇到表结构变更的时候就会以statement模式来记录。至于update或者delete等修改数据的语句，还是会记录所有行的 变更。 123456789...............................................................................# at 552#131128 17:50:46 server id 1 end_log_pos 665 Query thread_id=11 exec_time=0 error_code=0 ----&gt;执行时间:17:50:46；pos点:665SET TIMESTAMP=1385632246/*!*/;update zyyshop.stu set name=&apos;李四&apos; where id=4 ----&gt;执行的SQL/*!*/;# at 665#131128 17:50:46 server id 1 end_log_pos 692 Xid = 1454 ----&gt;执行时间:17:50:46；pos点:692 ............................................................................... 事物 数据库事务特性(ACID) 原子性：即步骤要么都成功，要么都失败 一致性：即操作的总数据量状态保证一致。例如A-&gt;B转账总数木变化是100，不多也不少 隔离性：即每个事物的操作，不影响其他的事物 持久性：即一旦提交结果永久保存 事物是如何通过日志实现的 redo_log 实现持久化和原子性，而undo_log实现一致性，二种日志均可以视为一种恢复操作，redo_log是恢复提交事务修改的页操作，而undo_log是回滚行记录到特定版本。二者记录的内容也不同，redo_log是物理日志，记录页的物理修改操作，而undo_log是逻辑日志，根据每行记录进行记录。 事务日志是通过redo(重做日志)和innodb的存储引擎日志缓冲（Innodb log buffer）来实现的， 当开始一个事务的时候，会记录该事务的lsn(log sequence number)号; 当事务执行时，会往InnoDB存储引擎的日志的日志缓存里面插入事务日志； 当事务提交时，必须将存储引擎的日志缓冲写入磁盘（通过innodb_flush_log_at_trx_commit来控制），也就是写数据前，需要先写日志。这种方式称为“预写日志方式” 事务干扰例子 读脏 1234- 事务A，先执行，处于未提交的状态：insert into t values(4, wangwu);- 事务B，后执行，也未提交：select * from t;如果事务B能够读取到(4, wangwu)这条记录，事务A就对事务B产生了影响，这个影响叫做“读脏”，读到了未提交事务操作的记录。 不可重复读 12345- 事务A，先执行：select * from t where id=1;结果集为：1, zhangsan- 事务B，后执行，并且提交：update t set name=xxoo where id=1;commit;- 事务A，再次执行相同的查询：select * from t where id=1;结果集为：1, xxoo这次是已提交事务B对事务A产生的影响，这个影响叫做“不可重复读”，一个事务内相同的查询，得到了不同的结果。 幻读 1234- 事务A，先执行：select * from t where id&gt;3; 结果为null- 事务B，后执行，并且提交：insert into t values(4, wangwu);commit;- 事务A，首次查询了id&gt;3的结果为NULL，于是想插入一条为4的记录：insert into t values(4, xxoo);结果集为：Error : duplicate key!这次是已提交事务B对事务A产生的影响，这个影响叫做“幻读”。 数据库的隔离级别 未提交读(Read Uncommitted)（S锁）: 此时，可能读取到不一致的数据，即“读脏”。这是并发最高，一致性最差的隔离级别。高并发量的场景下，几乎不会使用 串行化(Serializable)（X锁）: 这种事务的隔离级别下，所有select语句都会被隐式的转化为select … in share mode.这可能导致，如果有未提交的事务正在修改某些行，所有读取这些行的select都会被阻塞住。这是一致性最好的，但并发性最差的隔离级别。可以解决 脏读 不可重复读 和 虚读—相当于锁表,所以高并发量的场景下，几乎不会使用 可重复读(Repeated Read, RR)（X锁），这是InnoDB默认的隔离级别(1) 普通的select使用快照读(snapshot read)，这是一种不加锁的一致性读(Consistent Nonlocking Read)，底层使用MVCC来实现(2) 加锁的select(select … in share mode / select … for update), update, delete等语句，它们的锁，依赖于它们是否在唯一索引(unique index)上使用了唯一的查询条件(unique search condition)，或者范围查询条件(range-type search condition)： 在唯一索引上使用唯一的查询条件，会使用记录锁(record lock)，而不会封锁记录之间的间隔，即不会使用间隙锁(gap lock)与临键锁(next-key lock) 范围查询条件，会使用间隙锁与临键锁，锁住索引记录之间的范围，避免范围间插入记录，以避免产生幻影行记录，以及避免不可重复的读 读已提交(Read Committed, RC): 这是互联网最常用的隔离级别 普通读是快照读； 加锁的select, update, delete等语句，除了在外键约束检查(foreign-key constraint checking)以及重复键检查(duplicate-key checking)时会封锁区间，其他时刻都只使用记录锁； 此时，其他事务的插入依然可以执行，就可能导致，读取到幻影记录。 MVCC解释 MVCC (Multiversion Concurrency Control)，即多版本并发控制技术,它使得大部分支持行锁的事务引擎，不再单纯的使用行锁来进行数据库的并发控制，取而代之的是把数据库的行锁与行的多个版本结合起来，只需要很小的开销,就可以实现非锁定读，从而大大提高数据库系统的并发性能 核心原理 (1) 写任务发生时，将数据克隆一份，以版本号区分； (2) 写任务操作新克隆的数据，直至提交； (3) 并发读任务可以继续读取旧版本的数据，不至于阻塞； 如上图： 最开始数据的版本是V0； T1时刻发起了一个写任务，这是把数据clone了一份，进行修改，版本变为V1，但任务还未完成； T2时刻并发了一个读任务，依然可以读V0版本的数据； T3时刻又并发了一个读任务，依然不会阻塞；可以看到，数据多版本，通过“读取旧版本数据”能够极大提高任务的并发度。提高并发的演进思路，就在如此： 普通锁，本质是串行执行 读写锁，可以实现读读并发 数据多版本，可以实现读写并发 锁 锁机制 悲观锁：利用了数据库内部提供的锁机制；在并发过程中一旦有一个事务持有了数据库记录的锁，其他线程就不能再对数据库进行更新 乐观锁：乐观锁是一种不会阻塞其它线程并发的机制，它不会使用数据库的锁进行实现。所以就不会引起线程的频繁挂起和恢复，这样效率就提高了。它的实现关键在于CAS算法或者版本号机制。 版本号机制： 先读task表的数据（实际上这个表只有一条记录），得到version的值为versionValue update task set value = newValue,version = versionValue + 1 where version = versionValue; CAS算法： 锁粒度 行锁详解 表锁详解 页锁详解 当前读与快照读 当前读使用当前读的操作主要包括：显式加锁的读操作与插入/更新/删除等写操作，如下所示： 12345select * from table where ? lock in share mode;select * from table where ? for update;insert into table values (…);update table set ? where ?;delete from table where ?; 快照读即不加锁读，读取记录的快照版本而非最新版本，通过MVCC实现； 锁模式 锁模式 锁定内容 Record Lock 记录锁,锁定一条纪录 Gap Lock 间隙锁,锁定一个区间 Next-key Lock 记录+间隙锁,锁定一个区间+记录行 网络 主从复制原理 mysql启动以后会存在2个进程，一个是sqlThred进程一个IOThred进程 在Slave 服务器上执行sart slave命令开启主从复制开关，开始进行主从复制 Slave服务器的IO线程会通过在master上已经授权的复制用户权限请求连接master服务器，并请求从执行binlog日志文件的指定位置之后开始发送binlog日志内容 Master服务器接收到来自Slave服务器的IO线程的请求后，二进制转储IO线程会根据Slave服务器的IO线程请求的信息分批读取指定binlog日志文件指定位置之后的binlog日志信息，然后返回给Slave端的IO线程。返回的信息中除了binlog日志内容外，还有在master服务器端记录的新的binlog文件名称，以及在新的binlog中的下一个指定更新位置。 当Slave服务器的IO线程获取到Master服务器上IO线程发送的日志内容、日志文件及位置点后，会将binlog日志内容依次写到Slave端自身的Relay Log（即中继日志）文件（MySQL-relay-bin.xxx）的最末端，并将新的binlog文件名和位置记录到master-info文件中，以便下一次读取master端新binlog日志时能告诉Master服务器从新binlog日志的指定文件及位置开始读取新的binlog日志内容 Slave服务器端的SQL线程会实时检测本地Relay Log 中IO线程新增的日志内容，然后及时把Relay LOG 文件中的内容解析成sql语句，并在自身Slave服务器上按解析SQL语句的位置顺序执行应用这样sql语句，并在relay-log.info中记录当前应用中继日志的文件名和位置点 主从延迟的问题和解决办法 主从同步的延迟的原因：我们知道，一个服务器开放Ｎ个链接给客户端来连接的， 这样有会有大并发的更新操作, 但是从服务器的里面读取binlog 的线程仅有一个， 当某个SQL在从服务器上执行的时间稍长 或者由于某个SQL要进行锁表就会导致，主服务器的SQL大量积压，未被同步到从服务器里。这就导致了主从不一致， 也就是主从延迟。 解决办法：1）实际上主从同步延迟根本没有什么一招制敌的办法，因为所有的SQL必须都要在从服务器里面执行一遍，但是主服务器如果不断的有更新操作源源不断的写入，那么一旦有延迟产生，那么延迟加重的可能性就会原来越大。当然我们可以做一些缓解的措施。2）我们知道因为主服务器要负责更新操作，他对安全性的要求比从服务器高，所有有些设置可以修改，比如sync_binlog=1，innodb_flush_log_at_trx_commit=1之类的设置，而slave则不需要这么高的数据安全，完全可以讲sync_binlog设置为0或者关闭binlog，innodb_flushlog，innodb_flush_log_at_trx_commit也可以设置为0来提高sql的执行效率这个能很大程度上提高效率。另外就是使用比主库更好的硬件设备作为slave。3）就是把，一台从服务器当度作为备份使用，而不提供查询，那边他的负载下来了，执行relaylog里面的SQL效率自然就高了。4）增加从服务器喽，这个目的还是分散读的压力，从而降低服务器负载。 压力测试 https://imysql.com/tag/%E5%8E%8B%E6%B5%8B比较常用的MySQL基准压力测试工具有 tpcc-mysql、sysbench、mysqlslap 等几个。 延伸知识点MYSQL count总结 COUNT有几种用法？count(*),count(常数)，count(列名) COUNT(字段名)和COUNT()的查询结果有什么不同？为什么《阿里巴巴Java开发手册》建议使用COUNT()count()是SQL92定义的标准语法，count()会统计值为null的行，count(列明)不会统计改列为null的行 COUNT(1)和COUNT()、count(列名)之间有什么不同？COUNT(常量) 和 COUNT()表示的是直接查询符合条件的数据库表的行数。而COUNT(列名)表示的是查询符合条件的列的值不为NULL的行数。除了查询得到结果集有区别之外，COUNT()相比COUNT(常量) 和 COUNT(列名)来讲，COUNT()是SQL92定义的标准统计行数的语法，因为他是标准语法，所以MySQL数据库对他进行过很多优化。 COUNT(1)和COUNT(*)之间的效率哪个更高？ InnoDB handles SELECT COUNT(*) and SELECT COUNT(1) operations in the same way. There is no performance difference. 画重点：same way , no performance difference。所以，对于COUNT(1)和COUNT(*)，MySQL的优化是完全一样的，根本不存在谁比谁快!建议使用COUNT(*)！因为这个是SQL92定义的标准统计行数的语法，而且本文只是基于MySQL做了分析，关于Oracle中的这个问题，也是众说纷纭的呢。 MySQL的MyISAM引擎对COUNT()做了哪些优化？因为MyISAM的锁是表级锁，所以同一张表上面的操作需要串行进行，所以，MyISAM做了一个简单的优化，那就是它可以把表的总行数单独记录下来，如果从一张表中使用COUNT()进行查询的时候，可以直接返回这个记录下来的数值就可以了，当然，前提是不能有where条件。 MySQL的InnoDB引擎对COUNT()做了哪些优化？在InnoDB中，使用COUNT()查询行数的时候，不可避免的要进行扫表了，那么，就可以在扫表过程中下功夫来优化效率了。从MySQL 8.0.13开始，针对InnoDB的SELECT COUNT() FROM tbl_name语句，确实在扫表的过程中做了一些优化。前提是查询语句中不包含WHERE或GROUP BY等条件。我们知道，COUNT()的目的只是为了统计总行数，所以，他根本不关心自己查到的具体值，所以，他如果能够在扫表的过程中，选择一个成本较低的索引进行的话，那就可以大大节省时间。我们知道，InnoDB中索引分为聚簇索引（主键索引）和非聚簇索引（非主键索引），聚簇索引的叶子节点中保存的是整行记录，而非聚簇索引的叶子节点中保存的是该行记录的主键的值。所以，相比之下，非聚簇索引要比聚簇索引小很多，所以MySQL会优先选择最小的非聚簇索引来扫表。所以，当我们建表的时候，除了主键索引以外，创建一个非主键索引还是有必要的。至此，我们介绍完了MySQL数据库对于COUNT(*)的优化，这些优化的前提都是查询语句中不包含WHERE以及GROUP BY条件。 上面提到的MySQL对COUNT(*)做的优化，有一个关键的前提是什么？无where条件或者group by等条件 什么是局部性原理？局部性原理的逻辑是这样的： 内存读写块，磁盘读写慢，而且慢很多； 磁盘预读：磁盘读写并不是按需读取，而是按页预读，一次会读一页的数据，每次加载更多的数据，如果未来要读取的数据就在这一页中，可以避免未来的磁盘IO，提高效率；（通常，一页数据是4K） 局部性原理：软件设计要尽量遵循“数据读取集中”与“使用到一个数据，大概率会使用其附近的数据”，这样磁盘预读能充分提高磁盘IO； B树为何适合做索引？ 由于是m分叉的，高度能够大大降低； 每个节点可以存储j个记录，如果将节点大小设置为页大小，例如4K，能够充分的利用预读的特性，极大减少磁盘IO； B+树B树的插入及平衡化操作和2-3树很相似，这里就不介绍了。下面是往B树中依次插入6 10 4 14 5 11 15 3 2 12 1 7 8 8 6 3 6 21 5 15 15 6 32 23 45 65 7 8 6 5 4B+树，如上图，仍是m叉搜索树，在B树的基础上，做了一些改进： 非叶子节点不再存储数据，数据只存储在同一层的叶子节点上；（画外音：B+树中根到每一个节点的路径长度一样，而B树不是这样。） 叶子之间，增加了链表，获取所有节点，不再需要中序遍历；这些改进让B+树比B树有更优的特性： 范围查找，定位min与max之后，中间叶子节点，就是结果集，不用中序回溯；（画外音：范围查询在SQL中用得很多，这是B+树比B树最大的优势。） 叶子节点存储实际记录行，记录行相对比较紧密的存储，适合大数据量磁盘存储；非叶子节点存储记录的PK，用于查询加速，适合内存存储； 非叶子节点，不存储实际记录，而只存储记录的KEY的话，那么在相同内存的情况下，B+树能够存储更多索引；最后，量化说下，为什么m叉的B+树比二叉搜索树的高度大大大大降低？大概计算一下：(1)局部性原理，将一个节点的大小设为一页，一页4K，假设一个KEY有8字节，一个节点可以存储500个KEY，即j=500(2)m叉树，大概m/2&lt;= j &lt;=m，即可以差不多是1000叉树(3)那么：一层树：1个节点，1500个KEY，大小4K二层树：1000个节点，1000500=50W个KEY，大小10004K=4M三层树：10001000个节点，10001000500=5亿个KEY，大小100010004K=4G可以看到，存储大量的数据（5亿），并不需要太高树的深度（高度3），索引也不是太占内存（4G）。","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"MYSQL","slug":"后端/MYSQL","permalink":"http://xuchen.youtuc.cn/categories/后端/MYSQL/"}],"tags":[{"name":"面试","slug":"面试","permalink":"http://xuchen.youtuc.cn/tags/面试/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"MYSQL","slug":"后端/MYSQL","permalink":"http://xuchen.youtuc.cn/categories/后端/MYSQL/"}]},{"title":"HttpClient使用技巧","slug":"Java/HttpClient使用技巧","date":"2018-07-26T13:53:24.000Z","updated":"2020-05-18T05:44:55.000Z","comments":true,"path":"2018/07/26/Java/HttpClient使用技巧/","link":"","permalink":"http://xuchen.youtuc.cn/2018/07/26/Java/HttpClient使用技巧/","excerpt":"","text":"1. 规范背景1.1. http client选择 如无特殊情况（比如：单机tps上千），建议选Spring Rest Template做门面，Apache HttpClient 4.x做实现 1.2. rest template 运行环境 jdk 1.8 spring boot项目 2. 配置 rest template2.1. 引入jar包 Spring Rest Template在spring-web模块中内置了，spring boot会自动帮你引进来，因此无需再引入 引入Apache HttpClient 4.x包: 1234567891011&lt;dependency&gt; &lt;groupId&gt;org.apache.httpcomponents&lt;/groupId&gt; &lt;artifactId&gt;httpclient&lt;/artifactId&gt; &lt;version&gt;4.5.5&lt;/version&gt;&lt;/dependency&gt;&lt;!-- 如果不配异步（AsyncRestTemplate），则不需要这个依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-all&lt;/artifactId&gt; &lt;version&gt;4.1.5.Final&lt;/version&gt;&lt;/dependency&gt; 2.2. 编写 yml 文件配置（可选）1234567891011# yml配置的优先级高于java配置；如果yml配置和java配置同时存在，则yml配置会覆盖java配置####restTemplate的yml配置开始####---spring: restTemplate: maxTotalConnect: 1000 #连接池的最大连接数，0代表不限；如果取0，需要考虑连接泄露导致系统崩溃的后果 maxConnectPerRoute: 200 connectTimeout: 3000 readTimeout: 5000 charset: UTF-8####restTemplate的 yml配置开始#### 2.3. 编写java配置（必备，不可省略）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162//xxx代表你的项目，例如：//com.douyu.wsd.adx.gateway.config//com.douyu.wsd.venus.config//可以写一级，也可以写多级，具体自己随意package com.douyu.wsd.xxx.config;import java.nio.charset.Charset;import java.util.LinkedList;import java.util.List;import org.apache.http.Header;import org.apache.http.client.HttpRequestRetryHandler;import org.apache.http.impl.client.CloseableHttpClient;import org.apache.http.impl.client.DefaultHttpRequestRetryHandler;import org.apache.http.impl.client.HttpClients;import org.apache.http.impl.conn.PoolingHttpClientConnectionManager;import org.apache.http.message.BasicHeader;import org.springframework.boot.autoconfigure.condition.ConditionalOnClass;import org.springframework.boot.autoconfigure.condition.ConditionalOnMissingBean;import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.http.client.ClientHttpRequestFactory;import org.springframework.http.client.HttpComponentsClientHttpRequestFactory;import org.springframework.http.client.Netty4ClientHttpRequestFactory;import org.springframework.http.converter.HttpMessageConverter;import org.springframework.http.converter.StringHttpMessageConverter;import org.springframework.web.client.AsyncRestTemplate;import org.springframework.web.client.DefaultResponseErrorHandler;import org.springframework.web.client.RestTemplate;@Configuration@ConfigurationProperties(prefix = \"spring.restTemplate\")@ConditionalOnClass(value = &#123;RestTemplate.class, CloseableHttpClient.class&#125;)public class RestTemplateConfiguration &#123; // java配置的优先级低于yml配置；如果yml配置不存在，会采用java配置 // ####restTemplate的 java配置开始#### private int maxTotalConnection = 500; //连接池的最大连接数 private int maxConnectionPerRoute = 100; //同路由的并发数 private int connectionTimeout = 2 * 1000; //连接超时，默认2s private int readTimeout = 30 * 1000; //读取超时，默认30s private String charset = \"UTF-8\"; // ####restTemplate的 java配置结束#### public void setMaxTotalConnection(int maxTotalConnection) &#123; this.maxTotalConnection = maxTotalConnection; &#125; public void setMaxConnectionPerRoute(int maxConnectionPerRoute) &#123; this.maxConnectionPerRoute = maxConnectionPerRoute; &#125; public void setConnectionTimeout(int connectionTimeout) &#123; this.connectionTimeout = connectionTimeout; &#125; public void setReadTimeout(int readTimeout) &#123; this.readTimeout = readTimeout; &#125; public void setCharset(String charset) &#123; this.charset = charset; &#125; //创建HTTP客户端工厂 @Bean(name = \"clientHttpRequestFactory\") public ClientHttpRequestFactory clientHttpRequestFactory() &#123; return createClientHttpRequestFactory(this.connectionTimeout, this.readTimeout); &#125; //初始化RestTemplate,并加入spring的Bean工厂，由spring统一管理 @Bean(name = \"restTemplate\") @ConditionalOnMissingBean(RestTemplate.class) public RestTemplate restTemplate(ClientHttpRequestFactory factory) &#123; return createRestTemplate(factory); &#125; //初始化支持异步的RestTemplate,并加入spring的Bean工厂，由spring统一管理 //如果你用不到异步，则无须创建该对象 @Bean(name = \"asyncRestTemplate\") @ConditionalOnMissingBean(AsyncRestTemplate.class) public AsyncRestTemplate asyncRestTemplate(RestTemplate restTemplate) &#123; final Netty4ClientHttpRequestFactory factory = new Netty4ClientHttpRequestFactory(); factory.setConnectTimeout(this.connectionTimeout); factory.setReadTimeout(this.readTimeout); return new AsyncRestTemplate(factory, restTemplate); &#125; private ClientHttpRequestFactory createClientHttpRequestFactory(int connectionTimeout, int readTimeout) &#123; //maxTotalConnection 和 maxConnectionPerRoute 必须要配 if (this.maxTotalConnection &lt;= 0) &#123; throw new IllegalArgumentException(\"invalid maxTotalConnection: \" + maxTotalConnection); &#125; if (this.maxConnectionPerRoute &lt;= 0) &#123; throw new IllegalArgumentException(\"invalid maxConnectionPerRoute: \" + maxTotalConnection); &#125; //全局默认的header头配置 List&lt;Header&gt; headers = new LinkedList&lt;&gt;(); headers.add(new BasicHeader(\"Accept-Encoding\", \"gzip,deflate\")); headers.add(new BasicHeader(\"Accept-Language\", \"zh-CN,zh;q=0.8,en;q=0.6\")); //禁用自动重试，需要重试时，请自行控制 HttpRequestRetryHandler retryHandler = new DefaultHttpRequestRetryHandler(0, false); PoolingHttpClientConnectionManager cm = new PoolingHttpClientConnectionManager(); cm.setMaxTotal(maxTotalConnection); cm.setDefaultMaxPerRoute(maxConnectionPerRoute); //创建真正处理http请求的httpClient实例 CloseableHttpClient httpClient = HttpClients.custom() .setDefaultHeaders(headers) .setRetryHandler(retryHandler) .setConnectionManager(cm) .build(); HttpComponentsClientHttpRequestFactory factory = new HttpComponentsClientHttpRequestFactory( httpClient); factory.setConnectTimeout(connectionTimeout); factory.setReadTimeout(readTimeout); return factory; &#125; private RestTemplate createRestTemplate(ClientHttpRequestFactory factory) &#123; RestTemplate restTemplate = new RestTemplate(factory); //我们采用RestTemplate内部的MessageConverter //重新设置StringHttpMessageConverter字符集，解决中文乱码问题 modifyDefaultCharset(restTemplate); //设置错误处理器 restTemplate.setErrorHandler(new DefaultResponseErrorHandler()); return restTemplate; &#125; private void modifyDefaultCharset(RestTemplate restTemplate) &#123; List&lt;HttpMessageConverter&lt;?&gt;&gt; converterList = restTemplate.getMessageConverters(); HttpMessageConverter&lt;?&gt; converterTarget = null; for (HttpMessageConverter&lt;?&gt; item : converterList) &#123; if (StringHttpMessageConverter.class == item.getClass()) &#123; converterTarget = item; break; &#125; &#125; if (null != converterTarget) &#123; converterList.remove(converterTarget); &#125; Charset defaultCharset = Charset.forName(charset); converterList.add(1, new StringHttpMessageConverter(defaultCharset)); &#125;&#125; 做完上述配置，就生成了可用的RestTemplate实例 采用上述配置，可以做到开箱即用；自己配，可能会踩些坑，比如：spring boot 配置技巧 3. rest template基本用法3.1. get演示 演示代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849import com.douyu.wsd.framework.common.lang.StringUtils;import java.net.URLEncoder;import java.util.HashMap;import java.util.Map;import javax.annotation.Resource;import lombok.extern.slf4j.Slf4j;import org.springframework.http.HttpEntity;import org.springframework.http.HttpHeaders;import org.springframework.http.HttpMethod;import org.springframework.http.ResponseEntity;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestParam;import org.springframework.web.bind.annotation.RestController;import org.springframework.web.client.AsyncRestTemplate;import org.springframework.web.client.RestTemplate;@RestController@Slf4jpublic class TestController &#123; @Resource private RestTemplate restTemplate; @Resource private AsyncRestTemplate asyncRestTemplate; //最简单的get操作 @RequestMapping(\"/get\") public String testGet(String keyword) throws Exception &#123; String kw = StringUtils.defaultString(URLEncoder.encode(keyword, \"UTF-8\")); String html = restTemplate.getForObject(\"https://www.douyu.com/search/?kw=\" + kw, String.class); return html;//返回的是斗鱼主站的html &#125; //需要自定义header头的get操作 @RequestMapping(\"/get2\") public String testGet2(String keyword) throws Exception &#123; HttpHeaders headers = new HttpHeaders(); headers.set(\"MyHeaderKey\", \"MyHeaderValue\"); HttpEntity entity = new HttpEntity(headers); String kw = StringUtils.defaultString(URLEncoder.encode(keyword, \"UTF-8\")); ResponseEntity&lt;String&gt; response = restTemplate.exchange(\"https://www.douyu.com/search/?kw=\" + kw, HttpMethod.GET, entity, String.class); return response.getBody();//返回的是斗鱼主站的html &#125; &#125; 3.2. post表单演示 演示代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546import com.douyu.wsd.framework.common.lang.StringUtils;import java.util.HashMap;import java.util.Map;import javax.annotation.Resource;import com.google.common.collect.ImmutableMap;import org.springframework.http.HttpEntity;import org.springframework.http.HttpHeaders;import org.springframework.http.MediaType;import org.springframework.util.LinkedMultiValueMap;import org.springframework.util.MultiValueMap;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestParam;import org.springframework.web.bind.annotation.RestController;import org.springframework.web.client.RestTemplate;@RestControllerpublic class TestController &#123; @Resource private RestTemplate restTemplate; @RequestMapping(\"/postForm\") public String testPostForm(String posid) throws Exception &#123;//测试用例：posid=804009 String url = \"http://www.douyu.com/lapi/sign/app/getinfo?aid=android1&amp;client_sys=android&amp;mdid=phone&amp;time=1524495658&amp;token=&amp;auth=789c4f732d6aa4d0a5c8fb33765af8cf\"; MultiValueMap&lt;String, String&gt; form = new LinkedMultiValueMap&lt;String, String&gt;(); form.add(\"app\", \"&#123;\\\"aname\\\":\\\"斗鱼直播\\\",\\\"pname\\\":\\\"air.tv.douyu.android\\\"&#125;\"); form.add(\"mdid\", \"phone\"); form.add(\"cate1\", \"0\"); form.add(\"client_sys\", \"ios\"); form.add(\"cate2\", \"0\"); form.add(\"auth\", \"789c4f732d6aa4d0a5c8fb33765af8cf\"); form.add(\"roomid\", \"0\"); form.add(\"posid\", posid); form.add(\"imei\", \"863254010282712\"); HttpHeaders headers = new HttpHeaders(); headers.setContentType(MediaType.APPLICATION_FORM_URLENCODED); //headers.add(\"xx\", \"yy\");//可以加入自定义的header头 HttpEntity&lt;MultiValueMap&lt;String, String&gt;&gt; formEntity = new HttpEntity&lt;&gt;(form, headers); String json = restTemplate.postForObject(url, formEntity, String.class); return json;//返回的是广告api的json &#125;&#125; 3.3. post请求体演示 演示代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374import com.douyu.wsd.framework.common.lang.StringUtils;import java.util.HashMap;import java.util.Map;import javax.annotation.Resource;import org.springframework.http.HttpEntity;import org.springframework.http.HttpHeaders;import org.springframework.http.MediaType;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestParam;import org.springframework.web.bind.annotation.RestController;import org.springframework.web.client.RestTemplate;@RestControllerpublic class TestController &#123; @Resource private RestTemplate restTemplate; @RequestMapping(\"/postBody\") public String testPostBody() throws Exception &#123; String url = \"https://venus.dz11.com/venus/release/pc/checkUpdate\"; String jsonBody = \"&#123;\\n\" + \" \\\"channelCode\\\": \\\"official\\\",\\n\" + \" \\\"appCode\\\": \\\"Douyu_Live_PC_Client\\\",\\n\" + \" \\\"versionCode\\\": \\\"201804121\\\",\\n\" + \" \\\"versionName\\\": \\\"V5.1.9\\\",\\n\" + \" \\\"deviceUid\\\": \\\"02-15-03-59-5C-E2\\\",\\n\" + \" \\\"deviceResolution\\\": \\\"1920*1080\\\",\\n\" + \" \\\"token\\\": \\\"token\\\",\\n\" + \" \\\"webView\\\": \\\"\\\",\\n\" + \" \\\"osInfo\\\": \\\"10.0\\\",\\n\" + \" \\\"osType\\\": \\\"64\\\",\\n\" + \" \\\"cpuInfo\\\":\\n\" + \" &#123;\\n\" + \" \\\"OemId\\\": \\\"0\\\",\\n\" + \" \\\"ProcessorArchitecture\\\": \\\"0\\\",\\n\" + \" \\\"PageSize\\\": \\\"4096\\\",\\n\" + \" \\\"MinimumApplicationAddress\\\": \\\"00010000\\\",\\n\" + \" \\\"MaximumApplicationAddress\\\": \\\"7FFEFFFF\\\",\\n\" + \" \\\"ActiveProcessorMask\\\": \\\"15\\\",\\n\" + \" \\\"NumberOfProcessors\\\": \\\"4\\\",\\n\" + \" \\\"ProcessorType\\\": \\\"586\\\",\\n\" + \" \\\"AllocationGranularity\\\": \\\"65536\\\",\\n\" + \" \\\"ProcessorLevel\\\": \\\"6\\\",\\n\" + \" \\\"ProcessorRevision\\\": \\\"40457\\\"\\n\" + \" &#125;,\\n\" + \" \\\"diskInfo\\\": \\\"931.507GB\\\",\\n\" + \" \\\"memoryInfo\\\": \\\"15.8906GB\\\",\\n\" + \" \\\"driveInfo\\\": \\\"Intel(R) HD Graphics 630:23.20.16.4973;\\\",\\n\" + \" \\\"startTime\\\": \\\"-501420357\\\"\\n\" + \"&#125;\\n\"; HttpHeaders headers = new HttpHeaders(); headers.setContentType(MediaType.APPLICATION_JSON); //headers.add(\"xx\", \"yy\");//可以加入自定义的header头 HttpEntity&lt;String&gt; bodyEntity = new HttpEntity&lt;&gt;(jsonBody, headers); //1.直接拿原始json串 String json = restTemplate.postForObject(url, bodyEntity, String.class); //2.将原始的json传转成java对象，rest template可以自动完成 ResultVo resultVo = restTemplate.postForObject(url, bodyEntity, ResultVo.class); if (resultVo != null &amp;&amp; resultVo.success()) &#123; Object res = resultVo.getData();//data节点的实际类型是java.util.LinkedHashMap logger.info(\"处理成功，返回数据: &#123;&#125;\", resultVo.getData()); &#125; else &#123; logger.info(\"处理失败，响应结果: &#123;&#125;\", resultVo); &#125; return json;//返回的是分包api的json &#125;&#125; 3.4. post文件上传 场景说明：只适合小文件（20MB以内）上传 演示代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061import com.douyu.wsd.framework.common.codec.CodecUtils;import com.douyu.wsd.framework.common.lang.StringUtils;import java.io.File;import java.util.HashMap;import java.util.Map;import javax.annotation.Resource;import lombok.extern.slf4j.Slf4j;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.core.ParameterizedTypeReference;import org.springframework.core.io.FileSystemResource;import org.springframework.http.HttpEntity;import org.springframework.http.HttpHeaders;import org.springframework.http.HttpMethod;import org.springframework.http.MediaType;import org.springframework.http.ResponseEntity;import org.springframework.util.LinkedMultiValueMap;import org.springframework.util.MultiValueMap;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestParam;import org.springframework.web.bind.annotation.RestController;import org.springframework.web.client.RestTemplate;@RestController@Slf4jpublic class TestController &#123; @Resource private RestTemplate restTemplate; @RequestMapping(\"/postFile\") public String testPostBody() throws Exception &#123; String filePath = \"D:/config.png\"; //通过磁盘文件上传，如果产生了临时文件，一定要记得删除，否则，临时文件越积越多，磁盘会爆 FileSystemResource resource = new FileSystemResource(new File(filePath)); String url = \"http://dev.resuploader.dz11.com/Resource/Dss/put\"; String appId = \"***\";//测试的时候换成自己的配置 String secureKey = \"***\"; String time = String.valueOf(System.currentTimeMillis()); String pubStr = \"1\"; String tempStr = String.format(\"app_id=%s&amp;is_public=%s&amp;time=%s&amp;vframe=0%s\", appId, pubStr, time, secureKey); MultiValueMap&lt;String, Object&gt; form = new LinkedMultiValueMap&lt;&gt;(); form.add(\"is_public\", pubStr); form.add(\"vframe\", \"0\"); form.add(\"file\", resource); form.add(\"app_id\", appId); form.add(\"time\", time); form.add(\"sign\", CodecUtils.md5(tempStr)); HttpHeaders headers = new HttpHeaders(); headers.setContentType(MediaType.MULTIPART_FORM_DATA); //headers.add(\"xx\", \"yy\");//可以加入自定义的header头 HttpEntity&lt;MultiValueMap&lt;String, Object&gt;&gt; formEntity = new HttpEntity&lt;&gt;(form, headers); String json = restTemplate.postForObject(url, formEntity, String.class); return json; &#125;&#125; 3.5. 文件下载 场景说明：只适合小文件（10MB以内）下载 演示代码 1234567891011121314151617181920212223242526272829303132333435363738394041424344import com.douyu.wsd.framework.common.lang.StringUtils;import java.io.IOException;import java.io.InputStream;import java.net.URLEncoder;import java.util.Collections;import java.util.HashMap;import java.util.Map;import javax.annotation.Resource;import lombok.extern.slf4j.Slf4j;import org.springframework.core.io.InputStreamResource;import org.springframework.http.HttpEntity;import org.springframework.http.HttpHeaders;import org.springframework.http.HttpMethod;import org.springframework.http.HttpStatus;import org.springframework.http.MediaType;import org.springframework.http.ResponseEntity;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestParam;import org.springframework.web.bind.annotation.RestController;import org.springframework.web.client.RestTemplate;@RestController@Slf4jpublic class TestController &#123; @Resource private RestTemplate restTemplate; @RequestMapping(\"/downloadFile\") public ResponseEntity testDownloadFile() throws Exception &#123; String url = \"http://editor.baidu.com/editor/download/BaiduEditor(Online)_5-9-16.exe\"; HttpHeaders headers = new HttpHeaders(); headers.setAccept(Collections.singletonList(MediaType.APPLICATION_OCTET_STREAM)); HttpEntity&lt;String&gt; entity = new HttpEntity&lt;&gt;(headers); ResponseEntity&lt;byte[]&gt; response = restTemplate.exchange(url, HttpMethod.GET, entity, byte[].class); byte[] bytes = response.getBody(); long contentLength = bytes != null ? bytes.length : 0; headers.setContentLength((int) contentLength); headers.setContentDispositionFormData(\"baidu.exe\", URLEncoder.encode(\"百度安装包.exe\", \"UTF-8\")); return new ResponseEntity&lt;&gt;(response.getBody(), headers, HttpStatus.OK); &#125; &#125; 3.6. 更多API3.6.1. RestTemplate API 与http动词的对象关系： HTTP动词 对应的RestTemplate API DELETE delete(String, String…) GET getForObject(String, Class, String…) HEAD headForHeaders(String, String…) OPTIONS optionsForAllow(String, String…) POST postForLocation(String, Object, String…) PUT put(String, Object, String…) 3.6.2. (post|get)ForEntity API 和 (post|get)ForObject 的区别ForEntity API拿到的是ResponseEntity，通过ResponseEntity可以拿到状态码，response header等信息 ForObject API拿到的是java对象，用在不关心response状态码和header的场合中3.6.3. getXXX、postXXX 和 exchange 方法的区别getXXX、postXXX 用于比较简单的调用 exchange 用于比较复杂的调用4. rest template高阶用法4.1. 带泛型的响应解码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586import com.douyu.wsd.framework.common.lang.StringUtils;import java.util.HashMap;import java.util.Map;import javax.annotation.Resource;import lombok.extern.slf4j.Slf4j;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.core.ParameterizedTypeReference;import org.springframework.http.HttpEntity;import org.springframework.http.HttpHeaders;import org.springframework.http.HttpMethod;import org.springframework.http.MediaType;import org.springframework.http.ResponseEntity;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestParam;import org.springframework.web.bind.annotation.RestController;import org.springframework.web.client.RestTemplate;@RestController@Slf4jpublic class TestController &#123; private static final Logger logger = LoggerFactory.getLogger(TestController.class); @Resource private RestTemplate restTemplate; @RequestMapping(\"/postBody\") public String testPostBody() throws Exception &#123;//测试用例：posid=804009 String url = \"https://venus.dz11.com/venus/release/pc/checkUpdate\"; String jsonBody = \"&#123;\\n\" + \" \\\"channelCode\\\": \\\"official\\\",\\n\" + \" \\\"appCode\\\": \\\"Douyu_Live_PC_Client\\\",\\n\" + \" \\\"versionCode\\\": \\\"201804121\\\",\\n\" + \" \\\"versionName\\\": \\\"V5.1.9\\\",\\n\" + \" \\\"deviceUid\\\": \\\"02-15-03-59-5C-E2\\\",\\n\" + \" \\\"deviceResolution\\\": \\\"1920*1080\\\",\\n\" + \" \\\"token\\\": \\\"token\\\",\\n\" + \" \\\"webView\\\": \\\"\\\",\\n\" + \" \\\"osInfo\\\": \\\"10.0\\\",\\n\" + \" \\\"osType\\\": \\\"64\\\",\\n\" + \" \\\"cpuInfo\\\":\\n\" + \" &#123;\\n\" + \" \\\"OemId\\\": \\\"0\\\",\\n\" + \" \\\"ProcessorArchitecture\\\": \\\"0\\\",\\n\" + \" \\\"PageSize\\\": \\\"4096\\\",\\n\" + \" \\\"MinimumApplicationAddress\\\": \\\"00010000\\\",\\n\" + \" \\\"MaximumApplicationAddress\\\": \\\"7FFEFFFF\\\",\\n\" + \" \\\"ActiveProcessorMask\\\": \\\"15\\\",\\n\" + \" \\\"NumberOfProcessors\\\": \\\"4\\\",\\n\" + \" \\\"ProcessorType\\\": \\\"586\\\",\\n\" + \" \\\"AllocationGranularity\\\": \\\"65536\\\",\\n\" + \" \\\"ProcessorLevel\\\": \\\"6\\\",\\n\" + \" \\\"ProcessorRevision\\\": \\\"40457\\\"\\n\" + \" &#125;,\\n\" + \" \\\"diskInfo\\\": \\\"931.507GB\\\",\\n\" + \" \\\"memoryInfo\\\": \\\"15.8906GB\\\",\\n\" + \" \\\"driveInfo\\\": \\\"Intel(R) HD Graphics 630:23.20.16.4973;\\\",\\n\" + \" \\\"startTime\\\": \\\"-501420357\\\"\\n\" + \"&#125;\\n\"; HttpHeaders headers = new HttpHeaders(); headers.setContentType(MediaType.APPLICATION_JSON); HttpEntity&lt;String&gt; bodyEntity = new HttpEntity&lt;&gt;(jsonBody, headers); //1. 直接拿原始的json串 String json = restTemplate.postForObject(url, bodyEntity, String.class); //2. 将原始json传转java对象，跟上文不同的是，这个java对象里面有泛型（ResultVo&lt;PcUpdateRes&gt;） //大家实际使用的时候，把ResultVo&lt;PcUpdateRes&gt;换成自己的类，比如：List&lt;MemberInfo&gt; ResponseEntity&lt;ResultVo&lt;PcUpdateRes&gt;&gt; response = restTemplate .exchange(url, HttpMethod.POST, bodyEntity, new ParameterizedTypeReference&lt;ResultVo&lt;PcUpdateRes&gt;&gt;() &#123;&#125;); if (response.getStatusCode().is2xxSuccessful() &amp;&amp; response.getBody() != null &amp;&amp; response.getBody().success()) &#123; ResultVo&lt;PcUpdateRes data = &gt; resultVo = response.getBody(); PcUpdateRes data = resultVo.getData(); logger.info(\"处理成功，返回数据: &#123;&#125;\", data); &#125; else &#123; logger.info(\"处理失败，响应结果: &#123;&#125;\", response); &#125; return json; &#125;&#125; 4.2. 上传文件流123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384import com.douyu.wsd.framework.common.codec.CodecUtils;import com.douyu.wsd.framework.common.io.IOUtils;import com.douyu.wsd.framework.common.lang.StringUtils;import java.io.File;import java.io.FileInputStream;import java.io.IOException;import java.io.InputStream;import java.nio.file.Files;import java.nio.file.Paths;import java.util.HashMap;import java.util.Map;import javax.annotation.Resource;import lombok.extern.slf4j.Slf4j;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.core.ParameterizedTypeReference;import org.springframework.core.io.InputStreamResource;import org.springframework.http.HttpEntity;import org.springframework.http.HttpHeaders;import org.springframework.http.HttpMethod;import org.springframework.http.MediaType;import org.springframework.http.ResponseEntity;import org.springframework.util.LinkedMultiValueMap;import org.springframework.util.MultiValueMap;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestParam;import org.springframework.web.bind.annotation.RestController;import org.springframework.web.client.RestTemplate;@RestController@Slf4jpublic class TestController &#123; @Resource private RestTemplate restTemplate; @RequestMapping(\"/postFile\") public String testPostBody() throws Exception &#123; String filePath = \"D:/config.png\"; MultipartFileResource resource = new MultipartFileResource(new FileInputStream(new File(filePath)), \"config.png\"); String url = \"http://dev.resuploader.dz11.com/Resource/Dss/put\"; String appId = \"***\";//测试的时候换成自己的配置 String secureKey = \"***\"; String time = String.valueOf(System.currentTimeMillis()); String pubStr = \"1\"; String tempStr = String.format(\"app_id=%s&amp;is_public=%s&amp;time=%s&amp;vframe=0%s\", appId, pubStr, time, secureKey); MultiValueMap&lt;String, Object&gt; form = new LinkedMultiValueMap&lt;&gt;(); form.add(\"is_public\", pubStr); form.add(\"vframe\", \"0\"); form.add(\"file\", resource); form.add(\"app_id\", appId); form.add(\"time\", time); form.add(\"sign\", CodecUtils.md5(tempStr)); HttpHeaders headers = new HttpHeaders(); headers.setContentType(MediaType.MULTIPART_FORM_DATA); //headers.add(\"xx\", \"yy\");//可以加入自定义的header头 HttpEntity&lt;MultiValueMap&lt;String, Object&gt;&gt; formEntity = new HttpEntity&lt;&gt;(form, headers); String json = restTemplate.postForObject(url, formEntity, String.class); return json; &#125; private class MultipartFileResource extends InputStreamResource &#123; private String filename; public MultipartFileResource(InputStream inputStream, String filename) &#123; super(inputStream); this.filename = filename; &#125; @Override public String getFilename() &#123; return this.filename; &#125; @Override public long contentLength() throws IOException &#123; return -1; // we do not want to generally read the whole stream into memory ... &#125; &#125;&#125; 4.3 异步操作 AsyncRestTemplate 可支持异步，与同步API基本一致，返回的是future: 123456789101112131415161718192021222324252627import com.douyu.wsd.framework.common.lang.StringUtils;import java.util.HashMap;import java.util.Map;import java.util.concurrent.TimeUnit;import javax.annotation.Resource;import org.springframework.http.ResponseEntity;import org.springframework.util.concurrent.ListenableFuture;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestParam;import org.springframework.web.bind.annotation.RestController;import org.springframework.web.client.AsyncRestTemplate;@RestControllerpublic class TestController &#123; @Resource private AsyncRestTemplate asyncRestTemplate; @RequestMapping(\"/douyu\") public String douyu() throws Exception &#123; ListenableFuture&lt;ResponseEntity&lt;String&gt;&gt; future = asyncRestTemplate .getForEntity(\"http://www.douyu.com\", String.class); return future.get(2 * 1000, TimeUnit.SECONDS).getBody(); &#125;&#125; 4.4. 不同的超时时间假如我碰到这种场景： ServiceA | 10s ServiceB | 25s有3个套路可解决： 套路一，创建多个实例，每个实例有自己的超时时间，比如 1234567891011121314151617181920212223// 超时时间短的实例@Bean(name = \"clientHttpRequestFactoryA\")public ClientHttpRequestFactory clientHttpRequestFactoryA() &#123; return createClientHttpRequestFactory(2*1000, 10*1000);&#125;@Bean(name = \"restTemplateA\")@ConditionalOnMissingBean(RestTemplate.class)public RestTemplate restTemplateA() &#123; return createRestTemplate(clientHttpRequestFactoryA());&#125;// 超时时间长的实例@Bean(name = \"clientHttpRequestFactoryB\")public ClientHttpRequestFactory clientHttpRequestFactoryB() &#123; return createClientHttpRequestFactory(5*1000, 25*1000);&#125;@Bean(name = \"restTemplateB\")@ConditionalOnMissingBean(RestTemplate.class)public RestTemplate restTemplateB() &#123; return createRestTemplate(clientHttpRequestFactoryB());&#125; 套路二，AsyncRestTemplate 123ListenableFuture&lt;ResponseEntity&lt;String&gt;&gt; future = asyncRestTemplate .getForEntity(\"http://www.douyu.com\", String.class);return future.get(2 * 1000, TimeUnit.SECONDS).getBody(); 套路三，上 Circuit Breaker 12345678910111213141516171819202122232425262728293031323334@EnableCircuitBreakerpublic class MyApp &#123; public static void main(String[] args) &#123; SpringApplication.run(MyApp .class, args); &#125;&#125;@Servicepublic class MyService &#123; private final RestTemplate restTemplate; public BookService(RestTemplate rest) &#123; this.restTemplate = rest; &#125; @HystrixCommand( fallbackMethod = \"fooMethodFallback\", commandProperties = &#123; @HystrixProperty( name = \"execution.isolation.thread.timeoutInMilliseconds\", value=\"5000\" ) &#125; ) public String fooMethod() &#123; // Your logic here. restTemplate.exchange(...); &#125; public String fooMethodFallback(Throwable t) &#123; log.error(\"Fallback happened\", t); return \"Sensible Default Here!\" &#125;&#125; 4.5. 如何设置连接池 连接池需要服务端支持长连接，并非所有服务端都支持，因此单独开了篇文章：RestTemplate如何配置长连接 4.6. 全局统一的异常处理12345678910111213141516171819202122//实现异常处理接口public class CustomErrorHandler extends DefaultResponseErrorHandler &#123; @Override public void handleError(ClientHttpResponse response) throws IOException &#123; &#125; &#125; //将自定义的异常处理器加进去@Configuration public class RestClientConfig &#123; @Bean public RestTemplate restTemplate() &#123; RestTemplate restTemplate = new RestTemplate(); restTemplate.setErrorHandler(new CustomErrorHandler()); return restTemplate; &#125; &#125; 5. 小技巧5.1. 参数模板 数组传参 123String result = restTemplate.getForObject(\"http://example.com/hotels/&#123;hotel&#125;/bookings/&#123;booking&#125;\", String.class, \"42\", \"21\");//实际效果等同于：GET http://example.com/hotels/42/bookings/21 map传参 123456Map&lt;String, String&gt; vars = new HashMap&lt;String, String&gt;();vars.put(\"hotel\", \"42\");vars.put(\"booking\", \"21\");String result = restTemplate.getForObject(\"http://example.com/hotels/&#123;hotel&#125;/bookings/&#123;booking&#125;\", String.class, vars);//实际效果等同于：GET http://example.com/hotels/42/rooms/42 5.2. 文件上传注意点 如果使用了本地临时文件，一定要在finally代码块中删除，否则可能会撑爆磁盘 6. FAQ6.1. 获取状态码使用xxForEntity类方法调用接口，将返回ResponseEntity对象，通过它能取到状态码。 123456789101112//判断接口返回是否为200public static Boolean ping()&#123; String url = \"xxx\"; try&#123; ResponseEntity&lt;String&gt; responseEntity = restTemplate.getForEntity(url, String.class); HttpStatus status = responseEntity.getStatusCode();//获取返回状态 return status.is2xxSuccessful();//判断状态码是否为2开头的 &#125;catch(Exception e)&#123; log.error(\"处理失败: &#123;&#125;\", url, e); return false; //502 ,500是不能正常返回结果的，需要catch住，返回一个false &#125;&#125; 6.2. 我需要手工释放连接吗？ 不需要，rest template会帮我们释放，具体请看：spring-resttemplate-need-to-release-connection ? 6.2. 如何调试rest template可以在logback里单独配一个debug级别的logger，把org.apache.http下面的日志定向到控制台： 123&lt;logger name=\"org.apache.http\" level=\"DEBUG\" additivity=\"false\"&gt; &lt;appender-ref ref=\"STDOUT\" /&gt;&lt;/logger&gt;","categories":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"JAVA","slug":"后端/JAVA","permalink":"http://xuchen.youtuc.cn/categories/后端/JAVA/"}],"tags":[{"name":"JAVA类库技巧","slug":"JAVA类库技巧","permalink":"http://xuchen.youtuc.cn/tags/JAVA类库技巧/"}],"keywords":[{"name":"后端","slug":"后端","permalink":"http://xuchen.youtuc.cn/categories/后端/"},{"name":"JAVA","slug":"后端/JAVA","permalink":"http://xuchen.youtuc.cn/categories/后端/JAVA/"}]},{"title":"git命令大全","slug":"git命令大全","date":"2018-02-26T13:49:56.000Z","updated":"2021-05-04T08:26:08.000Z","comments":true,"path":"2018/02/26/git命令大全/","link":"","permalink":"http://xuchen.youtuc.cn/2018/02/26/git命令大全/","excerpt":"","text":"查看、添加、提交、删除、找回，重置修改文件git help &lt;command&gt; # 显示command的help git show # 显示某次提交的内容 git show $id git checkout -- &lt;file&gt; # 抛弃工作区修改 git checkout . # 抛弃工作区修改 git add &lt;file&gt; # 将工作文件修改提交到本地暂存区 git add . # 将所有修改过的工作文件提交暂存区 git rm &lt;file&gt; # 从版本库中删除文件 git rm &lt;file&gt; --cached # 从版本库中删除文件，但不删除文件 git reset &lt;file&gt; # 从暂存区恢复到工作文件 git reset -- . # 从暂存区恢复到工作文件 git reset --hard # 恢复最近一次提交过的状态，即放弃上次提交后的所有本次修改 git commit &lt;file&gt; git commit . git commit -a # 将git add, git rm和git ci等操作都合并在一起做 git commit -am &quot;some comments&quot; git commit --amend # 修改最后一次提交记录 git revert &lt;$id&gt; # 恢复某次提交的状态，恢复动作本身也创建次提交对象 git revert HEAD # 恢复最后一次提交的状态查看文件diffgit diff &lt;file&gt; # 比较当前文件和暂存区文件差异 git diff git diff &lt;id1&gt;&lt;id1&gt;&lt;id2&gt; # 比较两次提交之间的差异 git diff &lt;branch1&gt;..&lt;branch2&gt; # 在两个分支之间比较 git diff --staged # 比较暂存区和版本库差异 git diff --cached # 比较暂存区和版本库差异 git diff --stat # 仅仅比较统计信息查看提交记录git log # 查看分支的提交记录 git log &lt;file&gt; # 查看该文件每次提交记录 git log -p &lt;file&gt; # 查看每次详细修改内容的diff git log -p -2 # 查看最近两次详细修改内容的diff git log --stat #查看提交统计信息查看、切换、创建和删除分支git branch -r # 查看远程分支 git branch &lt;new_branch&gt; # 创建新的分支 git branch -v # 查看各个分支最后提交信息 git branch --merged # 查看已经被合并到当前分支的分支 git branch --no-merged # 查看尚未被合并到当前分支的分支 git checkout &lt;branch&gt; # 切换到某个分支 git checkout -b &lt;new_branch&gt; # 创建新的分支，并且切换过去 git checkout -b &lt;new_branch&gt; &lt;branch&gt; # 基于branch创建新的new_branch git checkout $id # 把某次历史提交记录checkout出来，但无分支信息，切换到其他分支会自动删除 git checkout $id -b &lt;new_branch&gt; # 把某次历史提交记录checkout出来，创建成一个分支 git checkout develop --patch 文件路径 #合并单个文件到当前分支 git branch -d &lt;branch&gt; # 删除某个分支 git branch -D &lt;branch&gt; # 强制删除某个分支 (未被合并的分支被删除的时候需要强制)分支合并和rebasegit merge &lt;branch&gt; # 将branch分支合并到当前分支 git merge origin/master --no-ff # 不要Fast-Foward合并，这样可以生成merge提交 git rebase master &lt;branch&gt; # 将master rebase到branch，相当于： git co &lt;branch&gt; &amp;&amp; git rebase master &amp;&amp; git co master &amp;&amp; git merge &lt;branch&gt;同步远程分支目录到本地git remote update origin --pruneGit补丁管理(方便在多台机器上开发同步时用)git diff &gt; ../sync.patch # 生成补丁 git apply ../sync.patch # 打补丁 git apply --check ../sync.patch #测试补丁能否成功Git暂存管理git stash # 暂存 git stash list # 列所有stash git stash apply # 恢复暂存的内容 git stash drop # 删除暂存区Git远程分支管理git pull # 抓取远程仓库所有分支更新并合并到本地 git pull --no-ff # 抓取远程仓库所有分支更新并合并到本地，不要快进合并 git fetch origin # 抓取远程仓库更新 git merge origin/master # 将远程主分支合并到本地当前分支 git checkout --track origin/branch # 跟踪某个远程分支创建相应的本地分支 git checkout -b &lt;local_branch&gt; origin/&lt;remote_branch&gt; # 基于远程分支创建本地分支，功能同上 git push # push所有分支 git push origin master # 将本地主分支推到远程主分支 git push -u origin master # 将本地主分支推到远程(如无远程主分支则创建，用于初始化远程仓库) git push origin &lt;local_branch&gt; # 创建远程分支， origin是远程仓库名 git push origin &lt;local_branch&gt;:&lt;remote_branch&gt; # 创建远程分支 git push origin :&lt;remote_branch&gt; #先删除本地分支(git br -d &lt;branch&gt;)，然后再push删除远程分支Git远程仓库管理git remote -v # 查看远程服务器地址和仓库名称 git remote show origin # 查看远程服务器仓库状态 git remote add origin git@ github:robbin/robbin_site.git # 添加远程仓库地址 git remote set-url origin git@ github.com:robbin/robbin_site.git # 设置远程仓库地址(用于修改远程仓库地址) git remote rm &lt;repository&gt; # 删除远程仓库创建远程仓库git clone --bare robbin_site robbin_site.git # 用带版本的项目创建纯版本仓库 scp -r my_project.git git@ git.csdn.net:~ # 将纯仓库上传到服务器上 mkdir robbin_site.git &amp;&amp; cd robbin_site.git &amp;&amp; git --bare init # 在服务器创建纯仓库 git remote add origin git@ github.com:robbin/robbin_site.git # 设置远程仓库地址 git push -u origin master # 客户端首次提交 git push -u origin develop # 首次将本地develop分支提交到远程develop分支，并且track git remote set-head origin master # 设置远程仓库的HEAD指向master分支 也可以命令设置跟踪远程库和本地库 git branch --set-upstream master origin/master git branch --set-upstream develop origin/developgit init在本地新建一个repo,进入一个项目目录,执行git init,会初始化一个repo,并在当前文件夹下创建一个.git文件夹.git clone获取一个url对应的远程Git repo, 创建一个local copy. 一般的格式是git clone [url]. clone下来的repo会以url最后一个斜线后面的名称命名,创建一个文件夹,如果想要指定特定的名称,可以git clone [url] newname指定.git status查询repo的状态. git status -s: -s表示short, -s的输出标记会有两列,第一列是对staging区域而言,第二列是对working目录而言.git log在当前分支上查看提交日志 git log --oneline --number: 每条log只显示一行,显示number条. git log --oneline --graph:可以图形化地表示出分支合并历史. git log branchname可以显示特定分支的log. git log --oneline branch1 ^branch2,可以查看在分支1,却不在分支2中的提交.^表示排除这个分支(Window下可能要给^branch2加上引号). git log --decorate会显示出tag信息. git log --author=[author name] 可以指定作者的提交历史. git log --since --before --until --after 根据提交时间筛选log. --no-merges可以将merge的commits排除在外. git log --grep 根据commit信息过滤log: git log --grep=keywords 默认情况下, git log --grep --author是OR的关系,即满足一条即被返回,如果你想让它们是AND的关系,可以加上--all-match的option. git log -S: filter by introduced diff. 比如: git log -SmethodName (注意S和后面的词之间没有等号分隔). git log -p: show patch introduced at each commit. 每一个提交都是一个快照(snapshot),Git会把每次提交的diff计算出来,作为一个patch显示给你看. 另一种方法是git show [SHA]. git log --stat: show diffstat of changes introduced at each commit. 同样是用来看改动的相对信息的,--stat比-p的输出更简单一些.git commit提交已经被add进来的改动. git commit -m “the commit message&quot; git commit -a 会先把所有已经track的文件的改动add进来,然后提交(有点像svn的一次提交,不用先暂存). 对于没有track的文件,还是需要git add一下. git commit --amend 增补提交. 会使用与当前提交节点相同的父节点进行一次新的提交,旧的提交将会被取消.git resetundo changes and commits. 这里的HEAD关键字指的是当前分支最末梢最新的一个提交.也就是版本库中该分支上的最新版本. git reset HEAD: unstage files from index and reset pointer to HEAD 这个命令用来把不小心add进去的文件从staged状态取出来,可以单独针对某一个文件操作: git reset HEAD - - filename, 这个- - 也可以不加. git reset --soft move HEAD to specific commit reference, index and staging are untouched. git reset --hard unstage files AND undo any changes in the working directory since last commit. 使用git reset —hard HEAD进行reset,即上次提交之后,所有staged的改动和工作目录的改动都会消失,还原到上次提交的状态. 这里的HEAD可以被写成任何一次提交的SHA-1. 不带soft和hard参数的git reset,实际上带的是默认参数mixed. 总结: git reset --mixed id,是将git的HEAD变了(也就是提交记录变了),但文件并没有改变，(也就是working tree并没有改变). 取消了commit和add的内容. git reset --soft id. 实际上，是git reset –mixed id 后,又做了一次git add.即取消了commit的内容. git reset --hard id.是将git的HEAD变了,文件也变了. 按改动范围排序如下: soft (commit) &lt; mixed (commit + add) &lt; hard (commit + add + local working)git revert反转撤销提交.只要把出错的提交(commit)的名字(reference)作为参数传给命令就可以了. git revert HEAD: 撤销最近的一个提交. git revert会创建一个反向的新提交,可以通过参数-n来告诉Git先不要提交.git rmgit rm file: 从staging区移除文件,同时也移除出工作目录. git rm --cached: 从staging区移除文件,但留在工作目录中. git rm --cached从功能上等同于git reset HEAD,清除了缓存区,但不动工作目录树.git cleangit clean是从工作目录中移除没有track的文件. 通常的参数是git clean -df: -d表示同时移除目录,-f表示force,因为在git的配置文件中, clean.requireForce=true,如果不加-f,clean将会拒绝执行.git rebase--rebase不会产生合并的提交,它会将本地的所有提交临时保存为补丁(patch),放在”.git/rebase”目录中,然后将当前分支更新到最新的分支尖端,最后把保存的补丁应用到分支上. rebase的过程中,也许会出现冲突,Git会停止rebase并让你解决冲突,在解决完冲突之后,用git add去更新这些内容,然后无需执行commit,只需要: git rebase --continue就会继续打余下的补丁. git rebase --abort将会终止rebase,当前分支将会回到rebase之前的状态.git refloggit reflog是对reflog进行管理的命令,reflog是git用来记录引用变化的一种机制,比如记录分支的变化或者是HEAD引用的变化. 当git reflog不指定引用的时候,默认列出HEAD的reflog. HEAD@{0}代表HEAD当前的值,HEAD@{3}代表HEAD在3次变化之前的值. git会将变化记录到HEAD对应的reflog文件中,其路径为.git/logs/HEAD, 分支的reflog文件都放在.git/logs/refs目录下的子目录中.cherry-pick它会获取某一个分支的单笔提交，并作为一个新的提交引入到你当前分支上 git cherry-pick [&lt;options&gt;] &lt;commit-ish&gt;... 常用options: --quit 退出当前的chery-pick序列 --continue 继续当前的chery-pick序列 --abort 取消当前的chery-pick序列，恢复当前分支 -n, --no-commit 不自动提交 -e, --edit 编辑提交信息","categories":[{"name":"工具","slug":"工具","permalink":"http://xuchen.youtuc.cn/categories/工具/"},{"name":"Git","slug":"工具/Git","permalink":"http://xuchen.youtuc.cn/categories/工具/Git/"}],"tags":[{"name":"Git命令","slug":"Git命令","permalink":"http://xuchen.youtuc.cn/tags/Git命令/"}],"keywords":[{"name":"工具","slug":"工具","permalink":"http://xuchen.youtuc.cn/categories/工具/"},{"name":"Git","slug":"工具/Git","permalink":"http://xuchen.youtuc.cn/categories/工具/Git/"}]},{"title":"vscode折腾","slug":"Tools/vscode折腾","date":"2017-12-25T21:49:58.000Z","updated":"2021-05-21T10:44:09.000Z","comments":true,"path":"2017/12/25/Tools/vscode折腾/","link":"","permalink":"http://xuchen.youtuc.cn/2017/12/25/Tools/vscode折腾/","excerpt":"","text":"基本设置0.使用快捷键组合【Ctrl+Shift+p】，在搜索框中输入“configure display language”，选择install 安装简体中文 Auto Close Tag ，自动添加 HTML/XML 的闭合标签，像 Visual Studio IDE 或 Sublime Text 一样。 Beautify，在 Visual Studio Code 中格式化 javascript 、JSON 、 CSS 、Sass，以及 HTML。 GitLens 可以增强 VSCode 内置 Git 的功能。例如 commits 搜索，历史记录和显示的代码作者身份具体功能可以查看Feature list Git History - 显示提交历史记录的美丽图表等等 PHP环境 php intelephense，PHP 的代码提示、补全、跳转定义、格式化插件，功能强大，无需配置；优秀，必装。 PHP DocBlocker，注释插件 PHP Snippets from PHPStrom,使用和 PHPStrom 一样的快捷代码片段，pubf + tab？ PHP Namespace Resolver,PHP 命名空间解析器；可以导入和扩展类；还可以排序。优秀，必装。 Better Align,可以实现变量和数组的等号对齐。优秀，必装。 php.validate.executablepath,配置成docker 容器中的php路径，办法 新建文件 Create a file named php in 你自己的路径 写入内容#!/bin/bash docker exec -i --user=1000:1000 php7-vscode php &quot;$@&quot; 修改可执行sudo chmod +x php php.validate.executablepath=你自己的路径/php go环境 设置代理 set GOPROXY=”https://goproxy.cn&quot; vscode添加go插件 安装go-tools，command+shift+p，输入 go:install 选择 install/update tools 设置常用代码片段，command+shift+p，选择go语言 1234\"print\":&#123; \"prefix\": \"pln\", \"body\": \"fmt.Println($0)\" &#125; 用Delve调试Go项目 go get -u go-delve/delve/delve launch.json 12345678910111213141516\"configurations\": [ &#123; \"name\": \"Golang\", \"type\": \"go\", \"request\": \"launch\", \"remotePath\": \"\", \"port\": 5546, \"host\": \"127.0.0.1\", \"program\": \"$&#123;fileDirname&#125;\", \"env\": &#123; \"GOPATH\":\"/User/abner/go\", \"GOROOT\":\"/usr/local/go\", &#125;, \"args\": [] &#125; ]","categories":[{"name":"工具","slug":"工具","permalink":"http://xuchen.youtuc.cn/categories/工具/"},{"name":"vscode","slug":"工具/vscode","permalink":"http://xuchen.youtuc.cn/categories/工具/vscode/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://xuchen.youtuc.cn/tags/Docker/"}],"keywords":[{"name":"工具","slug":"工具","permalink":"http://xuchen.youtuc.cn/categories/工具/"},{"name":"vscode","slug":"工具/vscode","permalink":"http://xuchen.youtuc.cn/categories/工具/vscode/"}]},{"title":"Docker搭建可一键部署的多域名LNMP环境","slug":"Tools/Docker/Docker-搭建可一键部署的多域名LNMP环境","date":"2017-12-25T21:49:58.000Z","updated":"2021-05-04T08:26:08.000Z","comments":true,"path":"2017/12/25/Tools/Docker/Docker-搭建可一键部署的多域名LNMP环境/","link":"","permalink":"http://xuchen.youtuc.cn/2017/12/25/Tools/Docker/Docker-搭建可一键部署的多域名LNMP环境/","excerpt":"","text":"Docker搭建可一键部署的多域名LNMP环境特点 完全开源 支持多版本PHP切换（PHP5.4、PHP5.6、PHP7.2…) 支持绑定任意多个域名 支持HTTPS和HTTP/2 PHP源代码位于host中 MySQL data位于host中 所有配置文件可在host中直接修改 所有日志文件可在host中直接查看 内置完整PHP扩展安装命令 实际使用，确保100%可行 实现一次配置，可在任何支持Docker系统使用 安装步骤1 docker(https://docs.docker.com/engine/installation/)1. Centos7安装方法12345sudo yum install -y yum-utils device-mapper-persistent-data lvm2sudo yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.reposudo yum makecache fastsudo yum -y install docker-cesudo service docker start2. Ubuntu安装方法123456sudo apt-get updatesudo apt-get -y install apt-transport-https ca-certificates curl software-properties-commoncurl -fsSL http://mirrors.aliyun.com/docker-ce/linux/ubuntu/gpg | sudo apt-key add -sudo add-apt-repository \"deb [arch=amd64] http://mirrors.aliyun.com/docker-ce/linux/ubuntu $(lsb_release -cs) stable\"sudo apt-get -y updatesudo apt-get -y install docker-ce2 docker-compose安装12sudo curl -L https://get.daocloud.io/docker/compose/releases/download/1.18.0/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-composesudo chmod +x /usr/local/bin/docker-compose3 查看版本，加入到docker组123$ docker -v$ docker-compose -v$ sudo gpasswd -a $&#123;USER&#125; docker 就不用每次启动Docker都得加sudo了，注意，执行gpasswd命令之后要重新登陆才有效。 4 使用国内镜像仓库4.1 首先注册一个阿里云账号，然后访问阿里云的Docker镜像仓库，能找到加速器地址。4.2 对于Docker 1.10+，打开配置文件 /etc/docker/daemon.json（没有时新建该文件）：1234567891011sudo mkdir -p /etc/dockersudo tee /etc/docker/daemon.json &lt;&lt;-'EOF'&#123; \"registry-mirrors\": [\"https://l714mp7z.mirror.aliyuncs.com\"]&#125;EOFsudo systemctl daemon-reloadsudo systemctl restart docker#开机启动centos7systemctl enable docker Docker 1.10以下请看：https://yq.aliyun.com/articles/29941。 5 安装容器和镜像1docker-compose up -d 6 如果是windows下基于virtualbox挂载目录到linux6.1 安装增强工具(centos7版本) 123456yum install -y gcc gcc-devel gcc-c++ gcc-c++-devel make kernel kernel-devel bzip2 vim wget sudo reboot #重启ln -s /usr/src/kernels/3.10.0（注意内核版本号自动补全） /usr/src/linux ## 增加软连接#点击虚拟机设备-&gt;安装增强mount /dev/cdrom /mnt #挂载增强光盘到系统，提示只读不用管cd /mnt &amp;&amp; ./VBoxLinuxAdditions.run 6.2 配置共享目录 6.3 手动挂载6.3.1 ubuntu12sudo mkdir /home/abner/server &amp;&amp; chmod -R 777 /home/abner/server sudo mount -t vboxsf docker /home/abner/server #手动挂载 （这里挂载的目录最好不要和共享文件夹名称一样） 6.3.2 centos712sudo mkdir /root/server &amp;&amp; chmod -R 777 /root/server sudo mount -t vboxsf docker /root/server 6.4 开机自动挂载6.4.1 ubuntu1234sudo vim /etc/rc.local##exit 0 前增加如下命令sleep 1sudo mount -t vboxsf docker /home/abner/server 6.4.2 centos7==[virbox自动挂载不能勾选]== 123456mkdir /root/server &amp;&amp; chmod -R 777 /root/servermount -t vboxsf docker /root/server #手动挂载## 此时如果提示/sbin/mount.vboxsf: mounting failed with the error: No such device，说明内核模块vboxsf未加载，可通过lsmod | grep vboxsf查看（无结果说明未加载）。执行 `modprobe vboxsf` #加载vboxsf模块#自动挂载sudo vim /etc/fstabdocker /root/server vboxsf rw,gid=100,uid=1000,auto 0 0 6.5 若走的端口转发按图如下配置 6.6 若走的桥接网卡，正常连接即可 以下部分属于知识扩展2.目录说明2.1 大致框架 2.2 目录结构123456789101112131415161718192021222324├── docker-compose.yml 容器启动配置文件├── Dockerfile PHP-FPM构建配置文件├── conf 配置目录│ ├── mysql MySQL配置文件目录│ │ └── my.cnf MySQL配置文件│ ├── nginx Nginx配置文件目录│ │ ├── conf.d 站点配置文件目录│ │ │ ├── certs SSL认证文件、密钥和加密文件目录│ │ │ │ └── site2 站点2的认证文件目录│ │ │ ├── site1.conf 站点1 Nginx配置文件│ │ │ └── site2.conf 站点2 Nginx配置文件│ │ └── nginx.conf Nginx通用配置文件│ └── php PHP配置目录│ ├── php-fpm.d PHP-FPM配置目录│ │ └── www.conf PHP-FPM配置文件│ └── php.ini PHP配置文件├── log 日志目录│ ├── mysql MySQL日志目录│ ├── nginx Nginx日志目录│ └── php-fpm PHP-FPM日志目录├── mysql MySQL数据文件目录└── www 站点根目录 ├── site1 站点1根目录 └── site2 站点2根目录 2.2.1 nginx配置123456789101112131415161718192021222324252627server &#123; listen 80; server_name www.site1.com; root /var/www/html/site1; index index.shtml index.php index.html; location ~* \\.(css|js)$ &#123; sendfile off; break; &#125; expires off; client_max_body_size 2M; client_body_temp_path /var/www/html; location / &#123; index index.shtml index.php index.html; if (!-e $request_filename)&#123; rewrite ^/(.+)$ /index.php?_url=/$1 last; &#125; &#125; location ~ ^/.+\\.php(/|$) &#123; fastcgi_pass [容器的ip或者名称]:9000; include fastcgi_params; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; fastcgi_read_timeout 600; &#125;&#125; 2.3 站点部署本文有默认加了两个站点：www.site1.com（同localhost）和www.site2.com。要在本地访问这两个域名，需要修改你的hosts文件，添加以下两行：127.0.0.1 www.site1.com127.0.0.1 www.site2.com其中，www.site2.com为支持SSL/https和HTTP/2的示例站点。因为站点2的SSL采用自签名方式，所以浏览器有安全提示，继续访问就可以了，自己的站点用第三方SSL认证证书替换即可。如果只用到站点1，把站点2相关的目录和配置文件删除：./conf/nginx/conf.d/certs/site2/./conf/nginx/conf.d/site2.conf./www/site2/重启容器内的Nginx生效：docker exec -it dlnmp_nginx_1 nginx -s reload 2.4 HTTPS使用./conf/nginx/conf.d/site2.conf如果是自签名，可以用廖雪峰提供的一个自动生成认证文件、私钥脚本：gencert.sh，这个脚本已经放在项目中，在这个目录下：./conf/nginx/conf.d/certs/site2/在Bash中输入：$ ./gencert.sh输入一次域名，和几次密码（内容随意）后，就会生成几个认证文件。其中自签名情况不需要.csr和.origin.key后缀的文件。然后修改Nginx配置文件，配置SSL支持就可以了。 2.5 docker-compose.yml文件如下是docker容器的运行配置docker-compose.yml的内容： 1234567891011121314151617181920212223242526272829303132333435363738394041nginx: image: nginx:alpine ports: - \"80:80\" - \"443:443\" volumes: - ./www/:/var/www/html/:rw - ./conf/nginx/conf.d:/etc/nginx/conf.d/:ro - ./conf/nginx/nginx.conf:/etc/nginx/nginx.conf:ro - ./log/nginx/:/var/log/nginx/:rw links: - php-fpm:fpmphp-fpm: build: . expose: - \"9000\" volumes: - ./www/:/var/www/html/:rw - ./conf/php/php.ini:/usr/local/etc/php/php.ini:ro - ./conf/php/php-fpm.d/www.conf:/usr/local/etc/php-fpm.d/www.conf:rw - ./log/php-fpm/:/var/log/php-fpm/:rw links: - mysql:mysql - redis:redismysql: image: mysql:latest ports: - \"3306:3306\" volumes: - ./conf/mysql/my.cnf:/etc/mysql/my.cnf:ro - ./mysql/:/var/lib/mysql/:rw - ./log/mysql/:/var/log/mysql/:rw environment: MYSQL_ROOT_PASSWORD: \"123456\"redis: image: redis:latest ports: - \"6379:6379\" 2.6 站点根目录写权限默认的，容器中的/var/www/html目录属于root，我们需要修改为www-data，PHP才能正常写目录。先进入到容器中：$ docker exec -it dlnmp_php-fpm_1 /bin/bash然后修改目录权限：$ chown -R www-data:www-data /var/www/html 2.7 MYSQL连接 $ mysql -h 127.0.0.1 -u root -p 说明：这里MySQL的连接主机不能用localhost，因为MySQL客户端默认使用unix socket方式连接，应该直接用本地IP。 $pdo = new PDO(‘mysql:host=mysql;dbname=site1’, ‘root’, ‘123456’); 说明：，host的值就是在指定的MySQL容器的名称。 redis,memcaced等类似 一键安装脚本12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576#!/bin/bashfunction getVersionNum()&#123; version=`cat /proc/version` cut=$&#123;version%%(*&#125; dd=$&#123;cut:14&#125;&#125;function dockerAlis() &#123; dps=\"\\$(docker ps -aq)\" dcup=\"ztth='docker-compose -f /root/docker/ztth.yml up -d'\" dcrs=\"ztth-rs='docker-compose -f /root/docker/ztth.yml restart'\" dcrm=\"ztth-rm='docker-compose -f /root/docker/ztth.yml stop &amp;&amp; docker-compose -f /root/docker/ztth.yml rm'\" dcps=\"ztth-ps='docker-compose -f /root/docker/ztth.yml ps'\" dcip=\"docker-ips='docker inspect --format='\\\"'\\\"'&#123;&#123;.Name&#125;&#125; - &#123;&#123;range .NetworkSettings.Networks&#125;&#125;&#123;&#123;.IPAddress&#125;&#125;&#123;&#123;end&#125;&#125;'\\\"'\\\"' $dps'\"&#125;function main()&#123; while [ True ];do echo -e \"\\033[33m CentOs7 docker安装步骤: \\033[0m\" echo -e \"\\033[33m The #1 docker服务安装 \\033[0m\" echo -e \"\\033[33m The #2 virtual box挂载安装，请保证安装增加工具和挂载目录已经添加 \\033[0m\" echo -e \"\\033[33m q键退出 \\033[0m\" read -p '选择安装: ' number case $number in 1) echo -e \"\\033[31m docker install starting \\033[0m\" \\ &amp;&amp; yum install -y wget \\ &amp;&amp; mv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup \\ &amp;&amp; wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo \\ &amp;&amp; yum install -y yum-utils \\ &amp;&amp; yum-config-manager --add-repo http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo \\ &amp;&amp; yum install -y gcc gcc-devel gcc-c++ gcc-c++-devel make kernel kernel-devel bzip2 vim wget device-mapper-persistent-data lvm2 docker-ce \\ &amp;&amp; yum makecache fast \\ &amp;&amp; service docker start \\ &amp;&amp; curl -L https://get.daocloud.io/docker/compose/releases/download/1.18.0/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose \\ &amp;&amp; chmod +x /usr/local/bin/docker-compose\\ &amp;&amp; gpasswd -a $USER docker \\ &amp;&amp; mkdir -p /etc/docker \\ &amp;&amp; echo '&#123;\"registry-mirrors\":[\"https://l714mp7z.mirror.aliyuncs.com\"]&#125;'&gt;&gt; /etc/docker/daemon.json \\ &amp;&amp; systemctl daemon-reload \\ &amp;&amp; systemctl restart docker \\ &amp;&amp; systemctl enable docker \\ &amp;&amp; echo -e \"\\033[31m docker安装完成，请重启电脑，执行步骤2 \\033[0m\" &amp;&amp; exit ;; 2) echo -e \"\\033[31m virtual box增强工具 install starting \\033[0m\" \\ &amp;&amp; getVersionNum &amp;&amp; rm -rf /usr/src/linux &amp;&amp; ln -s /usr/src/kernels/$dd /usr/src/linux \\ &amp;&amp; mount /dev/cdrom /mnt \\ &amp;&amp; cd /mnt &amp;&amp; ./VBoxLinuxAdditions.run \\ &amp;&amp; mkdir -p /root/docker &amp;&amp; chmod -R 777 /root/docker \\ &amp;&amp; echo 'docker /root/docker vboxsf rw,gid=100,uid=1000,auto 0 0'&gt;&gt; /etc/fstab \\ &amp;&amp; dockerAlis \\ &amp;&amp; echo \"alias $dcup\"&gt;&gt; /root/.bashrc \\ &amp;&amp; echo \"alias $dcrs\"&gt;&gt; /root/.bashrc \\ &amp;&amp; echo \"alias $dcrm\"&gt;&gt; /root/.bashrc \\ &amp;&amp; echo \"alias $dcps\"&gt;&gt; /root/.bashrc \\ &amp;&amp; echo \"alias $dcip\"&gt;&gt; /root/.bashrc \\ &amp;&amp; source /root/.bashrc \\ &amp;&amp; echo -e \"\\033[31m 请服务器重启 \\033[0m\"] &amp;&amp; exit ;; \"q\"|\"quit\") exit ;; *) echo \"Input error!!\" ;; esac done&#125;main 常用操作批量删除容器 1docker rm $(docker ps -a -q) 批量删除镜像 1docker rmi $(docker images -q) 删除挂载目录 1docker volume rm $(docker volume ls -qf dangling=true) 删除所有关闭的容器 1docker ps -a | grep Exit | cut -d &apos; &apos; -f 1 | xargs docker rm 删除所有dangling镜像（即无tag的镜像） 1docker rmi $(docker images | grep &quot;^&lt;none&gt;&quot; | awk &quot;&#123;print $3&#125;&quot;) 查看所有容器IP 1234docker inspect --format=&apos;&#123;&#123;.Name&#125;&#125; - &#123;&#123;range .NetworkSettings.Networks&#125;&#125;&#123;&#123;.IPAddress&#125;&#125;&#123;&#123;end&#125;&#125;&apos; $(docker ps -aq) shell别名用法alias docker-ips=&apos;docker inspect --format=&apos;&quot;&apos;&quot;&apos;&#123;&#123;.Name&#125;&#125; - &#123;&#123;range .NetworkSettings.Networks&#125;&#125;&#123;&#123;.IPAddress&#125;&#125;&#123;&#123;end&#125;&#125;&apos;&quot;&apos;&quot;&apos; $(docker ps -aq)&apos; 别名配置 12345alias docker-ips=&apos;docker inspect --format=&apos;&quot;&apos;&quot;&apos;&#123;&#123;.Name&#125;&#125; - &#123;&#123;range .NetworkSettings.Networks&#125;&#125;&#123;&#123;.IPAddress&#125;&#125;&#123;&#123;end&#125;&#125;&apos;&quot;&apos;&quot;&apos; $(docker ps -aq)&apos;alias ztth=&apos;docker-compose --compatibility -f /root/docker/ztth.yml up -d&apos;alias ztth-rs=&apos;docker-compose --compatibility -f /root/docker/ztth.yml restart&apos;alias ztth-rm=&apos;docker-compose --compatibility -f /root/docker/ztth.yml stop &amp;&amp; docker-compose -f /root/docker/ztth.yml rm&apos;alias ztth-ps=&apos;docker-compose --compatibility -f /root/docker/ztth.yml ps&apos;","categories":[{"name":"工具","slug":"工具","permalink":"http://xuchen.youtuc.cn/categories/工具/"},{"name":"Docker","slug":"工具/Docker","permalink":"http://xuchen.youtuc.cn/categories/工具/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://xuchen.youtuc.cn/tags/Docker/"}],"keywords":[{"name":"工具","slug":"工具","permalink":"http://xuchen.youtuc.cn/categories/工具/"},{"name":"Docker","slug":"工具/Docker","permalink":"http://xuchen.youtuc.cn/categories/工具/Docker/"}]},{"title":"window下基于virtual-box的 docker LNMP环境搭建","slug":"Tools/Docker/Window-virtualbox","date":"2017-12-25T21:49:58.000Z","updated":"2021-05-04T08:26:08.000Z","comments":true,"path":"2017/12/25/Tools/Docker/Window-virtualbox/","link":"","permalink":"http://xuchen.youtuc.cn/2017/12/25/Tools/Docker/Window-virtualbox/","excerpt":"","text":"windows下工具安装 centos下载：下载 virtual-box下载: 下载 git下载:下载 拉取安装目录 地址1：http://gitlab.kerlala.com:8888/xuchen/docker 或者 地址2：git@gitlab.kerlala.com:xuchen/docker.git 例如拉取到E盘work目录 1git clone git@gitlab.kerlala.com:xuchen/docker.git 虚拟机安装操作系统 新建虚拟机 新建注意事项这里建议选80G动态空间，因为一旦虚拟机磁盘满了，迁移非常容易崩 操作系统安装，选择安装磁盘，安装过程（略） 进入系统，开启centos网卡 root用户进入虚拟机开启网卡，vi /etc/sysconfig/network-scripts/ifcfg-enp0s3 ,部分网卡可能不是enp0s3，使用table键补全，查看即可 进入后，修改ONBOOT=no为yes,保存退出,重启虚拟机 配置端口 安装docker 使用git bash上传本地docker文件夹中的shell脚本。scp install.sh root@127.0.0.1:/root 登录虚拟机ssh root@127.0.0.1 安装 vi install :set ff=unix 保存退出 ./install 根据提示 输入 1，完成后关闭虚拟机软件 重新打开虚拟机软件，进行如下图操作设置启动虚拟机，选择如下配置 登录虚拟机， ./install 根据提示 输入 2，完成步骤2安装,重启虚拟机 启动docker docker-composer up -d容器启动 host配置www.site1.com，查看phpinfo()输出正常即可","categories":[{"name":"工具","slug":"工具","permalink":"http://xuchen.youtuc.cn/categories/工具/"},{"name":"Docker","slug":"工具/Docker","permalink":"http://xuchen.youtuc.cn/categories/工具/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://xuchen.youtuc.cn/tags/Docker/"}],"keywords":[{"name":"工具","slug":"工具","permalink":"http://xuchen.youtuc.cn/categories/工具/"},{"name":"Docker","slug":"工具/Docker","permalink":"http://xuchen.youtuc.cn/categories/工具/Docker/"}]},{"title":"Ubuntu开机优化","slug":"Linux/Linux-Ubuntu优化","date":"2017-02-25T22:06:52.000Z","updated":"2020-05-18T05:44:55.000Z","comments":true,"path":"2017/02/25/Linux/Linux-Ubuntu优化/","link":"","permalink":"http://xuchen.youtuc.cn/2017/02/25/Linux/Linux-Ubuntu优化/","excerpt":"","text":"安装openssh-server sudo apt-get install openssh-server vim git 替换国内源 sudo cp /etc/apt/sources.list /etc/apt/sources.list.backup sudo vim /etc/apt/sources.list 12345678910deb http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ trusty main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ trusty-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ trusty-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ trusty-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ trusty-backports main restricted universe multiverse 删除libreoffice sudo apt-get remove libreoffice 删除Amazon的链接 sudo apt-get remove unity-webapps-common 删掉基本不用的自带软件（用的时候再装也来得及） sudo apt-get remove libreoffice-common unity-webapps-common thunderbird totem rhythmbox simple-scan gnome-mahjongg aisleriot gnome-mines cheese transmission-common gnome-orca gnome-sudoku webbrowser-app onboard deja-dup 删除自带的软件中心 sudo apt-get remove software-center 删除自带的图片编辑软件 sudo apt-get remove imagemagick 关闭dash在线资源搜索 gsettings set com.canonical.Unity.Lenses remote-content-search ‘none’ gdebi安装deb包更好的软件 sudo apt-get install gdebi rpm安装 sudo apt-get install alien ##alien默认没有安装，所以首先要安装它 sudo alien xxxx.rpm ##将rpm转换位deb，完成后会生成一个同名的xxxx.deb sudo dpkg -i xxxx.deb ##安装 安装App Grid软件中心 sudo add-apt-repository ppa:appgrid/stable sudo apt-get update &amp;&amp; sudo apt-get install appgrid 微信微信客户端 设置时间使用UTC sudo vim /etc/default/rcS ###将UTC=no改为UTC=yes 安装Chrome sudo add-apt-repository ppa:chromium-daily/stable sudo apt-get install chromium-browser chromium-browser-l10n 安装搜狗输入法 vim /etc/apt/sources.list.d/ubuntukylin.list文件，加入ubuntu kylin的apt源 deb http://archive.ubuntukylin.com:10006/ubuntukylin trusty main sudo apt-get update sudo apt-get install sogoupinyin 安装WPS Office sudo apt-get install wps-office Java123456sudo vim ~/.bashrcexport JAVA_HOME=/home/abner/jdk1.8.0export JRE_HOME=$&#123;JAVA_HOME&#125;/jre export CLASSPATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/lib export PATH=$&#123;JAVA_HOME&#125;/bin:$PATHsource ~/.bashrc 安装Sublime Text 3 sudo add-apt-repository ppa:webupd8team/sublime-text-3 sudo apt-get update sudo apt-get install sublime-text 安装经典菜单指示器 sudo add-apt-repository ppa:diesch/testing sudo apt-get update sudo apt-get install classicmenu-indicator 安装系统指示器SysPeek sudo add-apt-repository ppa:nilarimogard/webupd8 sudo apt-get update sudo apt-get install syspeek 自定义DHCP网络的DNS Server IP地址 sudo vim /etc/dhcp/dhclient.conf文件，在第21行#prepend domain-name-servers 127.0.0.1;下一行添加如下2行使用aliyun和114的DNS prepend domain-name-servers 114.114.114.114; prepend domain-name-servers 223.5.5.5; 这样可以优先使用aliyun的dns，次要使用114的DNS。 安装axel(多线程下载工具) sudo apt-get install axel 1234567#常见用法直接下载这个文件axel http://www.baidu.com/img/bdlogo.gif多线程下载这个文件（10个线程）：axel -n 10 http://www.baidu.com/img/bdlogo.gif指定输出目录：axel -o ~/Pictures/ http://www.baidu.com/img/bdlogo.gif 安装ExFat文件系统驱动 sudo apt-get install exfat-fuse 安装unrar sudo apt-get install unrar 使用方法：unrar x test.rar 安装美化主题 sudo apt-get install unity-tweak-tool sudo apt-get install unity-webapps-common 下载主题包https://github.com/anmoljagetia/Flatabulous/archive/master.zip 解压到/usr/share/themes目录下。 sudo add-apt-repository ppa:noobslab/icons &amp;&amp; sudo apt-get update &amp;&amp; sudo apt-get install ultra-flat-icon 安装好之后，打开Ubuntu Tweak 工具，主题选择Flatabulous，icons主题选择ultra-flat-icons ZSH_OHMYZSH sudo apt-get install zsh wget –no-check-certificate https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh -O - | sh chsh -s /bin/zsh sudo reboot node.js curl -sL https://deb.nodesource.com/setup_8.x | sudo -E bash - sudo apt-get install -y nodejs 双击软件都无法打开 sudo rm /home/sophie/.gnome2 -rf","categories":[{"name":"工具","slug":"工具","permalink":"http://xuchen.youtuc.cn/categories/工具/"},{"name":"Linux","slug":"工具/Linux","permalink":"http://xuchen.youtuc.cn/categories/工具/Linux/"}],"tags":[{"name":"Ubuntu","slug":"Ubuntu","permalink":"http://xuchen.youtuc.cn/tags/Ubuntu/"}],"keywords":[{"name":"工具","slug":"工具","permalink":"http://xuchen.youtuc.cn/categories/工具/"},{"name":"Linux","slug":"工具/Linux","permalink":"http://xuchen.youtuc.cn/categories/工具/Linux/"}]},{"title":"Centos7开机优化","slug":"Linux/Linux-Centos7优化","date":"2017-02-13T22:01:12.000Z","updated":"2020-05-18T05:44:55.000Z","comments":false,"path":"2017/02/13/Linux/Linux-Centos7优化/","link":"","permalink":"http://xuchen.youtuc.cn/2017/02/13/Linux/Linux-Centos7优化/","excerpt":"","text":"1.替换源123yum install -y wgetmv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backupwget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo 2.安装增强123456yum install -y gcc gcc-devel gcc-c++ gcc-c++-devel make kernel kernel-devel bzip2 vim wget #需要的安装包shutdown -r now #重启电脑ln -s /usr/src/kernels/3.10.0(内核版本号/ /usr/src/linux ## 增加软连接#点击虚拟机设备-&gt;安装增强mount /dev/cdrom /mnt #挂载增强光盘到系统，提示只读不用管cd /mnt &amp;&amp; ./VBoxLinuxAdditions.run 3.挂载1234567mkdir /root/www &amp;&amp; chmod -R 777 /root/wwwmount -t vboxsf docker /root/www #手动挂载### 此时如果提示/sbin/mount.vboxsf: mounting failed with the error: No such device，说明内核模块vboxsf未加载，可通过lsmod | grep vboxsf查看（无结果说明未加载）。modprobe vboxsf #加载vboxsf模块#自动挂载vim /etc/fstabdocker /root/www vboxsf rw,gid=100,uid=1000,auto /0 0 4.修改主机名1234vim /etc/sysconfig/networkvim ~/.bash_profileexport PS1='[\\u@\\H \\W]$'source ~/.bash_profile 5.永久关闭防火墙123chkconfig iptables off 关闭chkconfig iptables on 开启service iptables status 7.selinux关闭123修改/etc/selinux/config将SELINUX=enforcing改为SELINUX=disabled,状态 /usr/sbin/sestatus -v 8.SSH客户端超时123456cd /etc/sshcp sshd_config sshd_config.baksed -i \"s/#ClientAliveInterval 0/ClientAliveInterval 60/g\" sshd_configsed -i \"s/#ClientAliveCountMax 3/ClientAliveCountMax 3/g\" sshd_configgrep ClientAlive sshd_configdiff sshd_config sshd_config.bak 9.yum install 不可用情况1234567- rpm -q epel-release- rpm -ivh http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpm 报错[--force --nodeps]- rpm -q epel-release- rpm -qR epel-release - rpm --import /etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-6- yum install yum-priorities- ls /etc/yum.repos.d/ | grep epel 10. FTP安装- 安装 123yum -y install vsftpduseradd ftpuserpasswd ftpuser (RwxM7yCV) - 无法访问问题 123456789101112[root@bogon ~]## getsebool -a | grep ftp allow_ftpd_anon_write --&gt; off&lt;!--这里无法访问--&gt;allow_ftpd_full_access --&gt; offallow_ftpd_use_cifs --&gt; offallow_ftpd_use_nfs --&gt; off&lt;!--这里无法访问--&gt;ftp_home_dir --&gt; offftpd_connect_db --&gt; offftpd_use_passive_mode --&gt; offhttpd_enable_ftp_server --&gt; offtftp_anon_write --&gt; off - 开启外网访问 12setsebool -P allow_ftpd_full_access onsetsebool -P ftp_home_dir on - 关闭匿名和开启被动模式 1234修改/etc/vsftpd/vsftpd.conf 中的改成 anonymous_enable=NOpasv_min_port=30000pasv_max_port=30999service vsftpd stop11.mysql5.7安装1234567891011121314151617cd /usr/local/src/wget http://repo.mysql.com/mysql57-community-release-el7-8.noarch.rpm rpm -ivh mysql57-community-release-el7-8.noarch.rpm yum -y install mysql-server #设置密码和远程访问grep &quot;password&quot; /var/log/mysqld.log //查看默认密码set password=password(&quot;xxxx&quot;);FLUSH PRIVILEGES;use mysql;set global validate_password_policy=0;update user set authentication_string = password(&apos;xxxx&apos;), password_expired = &apos;N&apos;, password_last_changed = now() where user = &apos;root&apos;;GRANT ALL ON *.* TO root@&apos;localhost&apos; IDENTIFIED BY &apos;xxxx&apos; WITH GRANT OPTION; update user set host = &apos;%&apos; where user =&apos;root&apos;;FLUSH PRIVILEGES; 如果容器需要访问物理机ip，先查看容器的ip地址，直接配置host为物理机mysql,ip即可 12.SSRssr安装1234yum -y install wgetwget -N --no-check-certificate https://raw.githubusercontent.com/ToyoDAdoubi/doubi/master/ssr.shchmod +x ssr.sh./ssr.sh SSR客户端下载 Windows客户端：下载地址 Mac客户端：下载地址 安卓客户端：下载地址 iPhone客户端：需要切换北美账号商店，ssr或者potatso Lite客户端等 docker搭建：地址","categories":[{"name":"工具","slug":"工具","permalink":"http://xuchen.youtuc.cn/categories/工具/"},{"name":"Linux","slug":"工具/Linux","permalink":"http://xuchen.youtuc.cn/categories/工具/Linux/"}],"tags":[{"name":"Centos","slug":"Centos","permalink":"http://xuchen.youtuc.cn/tags/Centos/"}],"keywords":[{"name":"工具","slug":"工具","permalink":"http://xuchen.youtuc.cn/categories/工具/"},{"name":"Linux","slug":"工具/Linux","permalink":"http://xuchen.youtuc.cn/categories/工具/Linux/"}]},{"title":"githubPages+hexo搭建个人博客","slug":"githubPages-hexo搭建个人博客","date":"2017-01-25T22:07:58.000Z","updated":"2020-05-18T05:44:56.000Z","comments":true,"path":"2017/01/25/githubPages-hexo搭建个人博客/","link":"","permalink":"http://xuchen.youtuc.cn/2017/01/25/githubPages-hexo搭建个人博客/","excerpt":"","text":"githubPages+hexo搭建个人博客 安装git和nodejs npm安装慢 12sudo npm config set registry http://registry.npm.taobao.orgnpm install -g cnpm --registry=https://registry.npm.taobao.org MACOS Permission denied 1sudo chown -R $(whoami):admin /usr/local/lib/node_modules/ 由于npm安装失败，使用cnpm 1cnpm install -g hexo-cli 选定磁盘路 新建日志博客,并给项目起名称 1hexo init abner-xu.github.io 进入目录安装依赖 123cnpm install #安装依赖hexo generate #形成部署文件hexo server 启动服务 编辑_config.yml 修改deploy 1234deploy: type: git repository: git@github.com:abner-xu/abner-xu.github.io.git branch: master 部署到gitpage上首先配置github ssh信息 123cnpm install hexo-deployer-git –savehexo clean hexo generator #格式化文件hexo d #部署到git hexo关键配置1234567891011121314151617# Site title: 博客标题 #网站的标题 subtitle: life is struggle #副标题 description: life is struggle #描述 author: examble #作者信息 avatar: /images/avatar.png #头像，图片位置在相应主题目录下的images language: zh-Hans #中文简体 email: xxxx@qq.com timezone: # Extensions theme: next #配置主题，这里使用next主题 stylus: compress: true #自适应布局 # Deployment deploy: type: git #部署环境，基于hexo+githubpage,所以这里使用git。注意：不同版本的hexo，type有可能不同，3.x以后应使用git,具体参看官方文档 repository: git@github.com:username/username.github.io.git #git仓库地址，替换成你的username即可，其他保持不变，后面会提到如何创建git仓库 branch: master 添加关于页面使用：hexo new page “about” 新建一个 关于我 页面。主题的 _config.yml 文件中的 menu 中进行匹配 123456menu: home: / //主页 categories: /categories //分类 archives: /archives //归档 tags: /tags //标签 about: /about //关于 （添加此行即可 添加标签页面使用： hexo new page tags 新建一个 标签 页面。 123title: tagsdate: 2017-12-02 21:01:24type: &quot;tags&quot; 主题的 _config.yml 文件中的 menu 中进行匹配 123456menu: home: / //主页 categories: /categories //分类 archives: /archives //归档 tags: /tags //标签 about: /about //关于 （添加此行即可 添加分类页面使用： hexo new page categories 新建一个 分类 页面。 123title: categoriesdate: 2017-12-02 21:01:24type: &quot;categories&quot; 主题的 _config.yml 文件中的 menu 中进行匹配 123456menu: home: / //主页 categories: /categories //分类 archives: /archives //归档 tags: /tags //标签 about: /about //关于 （添加此行即可 底下代码是一篇包含 分类 文章的例子： 1234title: 分类测试categories:- hexo （这个就是文章的分类了）--- 添加归档页面 或者自定义页面主题的 _config.yml 文件中的 menu 中进行匹配 使用： hexo new page “guestbook” 新建一个 自定义 页面。主题的 _config.yml 文件中的 menu 中进行匹配 1234567menu: home: / //主页 categories: /categories //分类 archives: /archives //归档 tags: /tags //标签 about: /about //关于 guestbook: /guestbook //自定义 （添加此行即可） 添加文章1hexo new &quot;文章名称&quot; title: CentOS7下Tomcat启动慢的原因及解决方案date: 2017-12-02 21:01:24comments: true #是否可评论toc: true #是否显示文章目录categories: “云服务器” #分类tags: #标签 - centOS - tomcat","categories":[{"name":"前端","slug":"前端","permalink":"http://xuchen.youtuc.cn/categories/前端/"},{"name":"Hexo","slug":"前端/Hexo","permalink":"http://xuchen.youtuc.cn/categories/前端/Hexo/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://xuchen.youtuc.cn/tags/Hexo/"}],"keywords":[{"name":"前端","slug":"前端","permalink":"http://xuchen.youtuc.cn/categories/前端/"},{"name":"Hexo","slug":"前端/Hexo","permalink":"http://xuchen.youtuc.cn/categories/前端/Hexo/"}]}]}